{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### PyTorch Tensor Creation, Shape, Dimension, and Type\n\n* A torch Tensor can be created from a scalar value, a Python list, a NumPy array, or an existing tensor.\n* The shape of a tensor can be checked using the `shape` attribute or the `size()` method.\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\n\nlist_01 = [1, 2, 3]\nts_01 = torch.tensor(list_01)\nts_02 = torch.tensor([[1, 2, 3],\n                      [2, 3, 4]\n                     ])\nts_03 = torch.tensor([\n                      [[1, 2, 3],\n                       [2, 3, 4]],\n                      [[3, 4, 5],\n                       [4, 5, 6]]\n                     ]) \nprint('ts_01:', ts_01.shape, 'ts_02 shape:', ts_02.shape, 'ts_03 shape:', ts_03.shape) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:38:52.396899Z","iopub.execute_input":"2025-08-29T18:38:52.397229Z","iopub.status.idle":"2025-08-29T18:38:57.403985Z","shell.execute_reply.started":"2025-08-29T18:38:52.397203Z","shell.execute_reply":"2025-08-29T18:38:57.403124Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.array([1, 2, 3]).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:39:39.869475Z","iopub.execute_input":"2025-08-29T18:39:39.870223Z","iopub.status.idle":"2025-08-29T18:39:39.876342Z","shell.execute_reply.started":"2025-08-29T18:39:39.870192Z","shell.execute_reply":"2025-08-29T18:39:39.875432Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Tensor Shape/Size and Dimensions\n\n* A PyTorch tensor provides its shape through the `shape` attribute or the `size()` method, both of which return a `torch.Size` object.\n* The `shape` attribute and `size()` method are almost identical; the main difference is that `shape` supports indexing.\n* If you only want to know the number of dimensions, you can use the `ndim` attribute.\n","metadata":{}},{"cell_type":"code","source":"print(ts_02.shape, ts_02.size())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:40:31.277918Z","iopub.execute_input":"2025-08-29T18:40:31.278214Z","iopub.status.idle":"2025-08-29T18:40:31.284909Z","shell.execute_reply.started":"2025-08-29T18:40:31.278191Z","shell.execute_reply":"2025-08-29T18:40:31.283854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_02.shape[-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:41:05.787296Z","iopub.execute_input":"2025-08-29T18:41:05.787909Z","iopub.status.idle":"2025-08-29T18:41:05.792886Z","shell.execute_reply.started":"2025-08-29T18:41:05.787882Z","shell.execute_reply":"2025-08-29T18:41:05.792142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ts_02.shape[0], ts_02.shape[1], ts_02.size(0), ts_02.size(1), ts_02.size()[0]) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:41:25.835370Z","iopub.execute_input":"2025-08-29T18:41:25.836008Z","iopub.status.idle":"2025-08-29T18:41:25.840509Z","shell.execute_reply.started":"2025-08-29T18:41:25.835981Z","shell.execute_reply":"2025-08-29T18:41:25.839745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_02.ndim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:41:29.305956Z","iopub.execute_input":"2025-08-29T18:41:29.306731Z","iopub.status.idle":"2025-08-29T18:41:29.311243Z","shell.execute_reply.started":"2025-08-29T18:41:29.306699Z","shell.execute_reply":"2025-08-29T18:41:29.310594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Tensor Data Type\n\n* All values in a tensor share the same data type, which can be checked using the `dtype` attribute.\n* The data type can be specified at creation or converted later using the `type()` or `to()` methods.\n","metadata":{}},{"cell_type":"code","source":"ts_01 = torch.tensor([1.0, 2, 3])\nprint(ts_01.dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:42:14.257711Z","iopub.execute_input":"2025-08-29T18:42:14.258021Z","iopub.status.idle":"2025-08-29T18:42:14.262686Z","shell.execute_reply.started":"2025-08-29T18:42:14.257996Z","shell.execute_reply":"2025-08-29T18:42:14.261816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01 = torch.tensor([1, 2, 3], dtype=torch.float32)\nprint(ts_01.dtype)  # torch.float32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:42:24.423285Z","iopub.execute_input":"2025-08-29T18:42:24.424061Z","iopub.status.idle":"2025-08-29T18:42:24.428794Z","shell.execute_reply.started":"2025-08-29T18:42:24.424026Z","shell.execute_reply":"2025-08-29T18:42:24.428030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01_1 = ts_01.int() #convert to int32\nprint(ts_01_1.dtype)\n\nts_01_2 = ts_01.float() #convert to float32\nprint(ts_01_2.dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:42:34.347935Z","iopub.execute_input":"2025-08-29T18:42:34.348192Z","iopub.status.idle":"2025-08-29T18:42:34.364799Z","shell.execute_reply.started":"2025-08-29T18:42:34.348174Z","shell.execute_reply":"2025-08-29T18:42:34.363989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01_1 = ts_01.type(torch.int64)\nprint(ts_01_1.dtype)\n\nts_01_2 = ts_01.type(torch.int8) # float32/float64\nprint(ts_01_2.dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:42:44.012325Z","iopub.execute_input":"2025-08-29T18:42:44.012614Z","iopub.status.idle":"2025-08-29T18:42:44.019364Z","shell.execute_reply.started":"2025-08-29T18:42:44.012584Z","shell.execute_reply":"2025-08-29T18:42:44.018584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01_1 = ts_01.to(torch.int64)\nprint(ts_01_1.dtype)\n\nts_01_2 = ts_01.to(torch.int8) # float32/float64\nprint(ts_01_2.dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:43:46.350051Z","iopub.execute_input":"2025-08-29T18:43:46.350618Z","iopub.status.idle":"2025-08-29T18:43:46.355804Z","shell.execute_reply.started":"2025-08-29T18:43:46.350589Z","shell.execute_reply":"2025-08-29T18:43:46.354854Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Interconversion Between NumPy Arrays and PyTorch Tensors","metadata":{}},{"cell_type":"code","source":"arr_01 = np.array([1, 2])\nts_01 = torch.tensor(arr_01)\nts_02 = torch.from_numpy(arr_01)\nprint(type(arr_01), ts_01, ts_02)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:44:43.466234Z","iopub.execute_input":"2025-08-29T18:44:43.466666Z","iopub.status.idle":"2025-08-29T18:44:43.493066Z","shell.execute_reply.started":"2025-08-29T18:44:43.466613Z","shell.execute_reply":"2025-08-29T18:44:43.492387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"arr_01_1 = ts_01.numpy()\nlist_01 = ts_01.tolist()\nprint(arr_01_1, type(arr_01_1), list_01, type(list_01))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:45:02.918030Z","iopub.execute_input":"2025-08-29T18:45:02.918297Z","iopub.status.idle":"2025-08-29T18:45:02.923398Z","shell.execute_reply.started":"2025-08-29T18:45:02.918278Z","shell.execute_reply":"2025-08-29T18:45:02.922514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import numpy as np\n# import torch\n\n# ts_01 = torch.tensor([1, 2])\n# ts_01_1 = ts_01.to('cuda')\n# # The following will raise an error. You cannot directly call the numpy() method on a tensor that is on the CUDA device.\n# arr_01_1 = ts_01_1.numpy()  # You need to call ts_01_1.cpu().numpy() instead.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:45:46.944289Z","iopub.execute_input":"2025-08-29T18:45:46.944968Z","iopub.status.idle":"2025-08-29T18:45:46.980933Z","shell.execute_reply.started":"2025-08-29T18:45:46.944941Z","shell.execute_reply":"2025-08-29T18:45:46.979817Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"NumPy runs only on the CPU, so calling `numpy()` on a tensor moved to the GPU will cause an error. CUDA is a library that enables NVIDIA GPUs.\n","metadata":{}},{"cell_type":"code","source":"arr_01_1 = ts_01_1.cpu().numpy()\nprint(arr_01_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:46:54.781873Z","iopub.execute_input":"2025-08-29T18:46:54.782186Z","iopub.status.idle":"2025-08-29T18:46:54.787605Z","shell.execute_reply.started":"2025-08-29T18:46:54.782164Z","shell.execute_reply":"2025-08-29T18:46:54.786817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# When performing tensor.from_numpy(array), the created tensor shares memory with the input array.\n# If the input array is modified, the tensor will also change accordingly.\narr_01 = np.array([1, 2])\nts_01 = torch.from_numpy(arr_01)\nprint('arr_01:', arr_01, 'ts_01:', ts_01)\n\narr_01[0] = 0\nprint('arr_01:', arr_01, 'ts_01:', ts_01)\n\n# Use clone() to create a copy of the tensor\nts_02 = ts_01.clone()\narr_01[0] = 100\nprint('arr_01:', arr_01, 'ts_01:', ts_01, 'ts_02:', ts_02)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:47:26.347823Z","iopub.execute_input":"2025-08-29T18:47:26.348140Z","iopub.status.idle":"2025-08-29T18:47:26.358527Z","shell.execute_reply.started":"2025-08-29T18:47:26.348117Z","shell.execute_reply":"2025-08-29T18:47:26.357629Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Convenient Tensor Creation – `arange`, `zeros`, `ones`\n","metadata":{}},{"cell_type":"code","source":"torch.arange(2,10,2, dtype=torch.int32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:47:48.867982Z","iopub.execute_input":"2025-08-29T18:47:48.868693Z","iopub.status.idle":"2025-08-29T18:47:48.880047Z","shell.execute_reply.started":"2025-08-29T18:47:48.868665Z","shell.execute_reply":"2025-08-29T18:47:48.879322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq_ts = torch.arange(10)\nprint(seq_ts)\nprint(seq_ts.dtype, seq_ts.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:48:44.293998Z","iopub.execute_input":"2025-08-29T18:48:44.294252Z","iopub.status.idle":"2025-08-29T18:48:44.299861Z","shell.execute_reply.started":"2025-08-29T18:48:44.294233Z","shell.execute_reply":"2025-08-29T18:48:44.299123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.zeros(size=(3, 2), dtype=torch.int32).dtype","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:48:55.735829Z","iopub.execute_input":"2025-08-29T18:48:55.736137Z","iopub.status.idle":"2025-08-29T18:48:55.744364Z","shell.execute_reply.started":"2025-08-29T18:48:55.736113Z","shell.execute_reply":"2025-08-29T18:48:55.743608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"zero_ts = torch.zeros(size=(3, 2), dtype=torch.int32) \nprint(zero_ts)\nprint(zero_ts.dtype, zero_ts.shape)\n\none_ts = torch.ones(3, 2, dtype=torch.int16) # no need to use tuple\nprint(one_ts)\nprint(one_ts.dtype, one_ts.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:49:45.846238Z","iopub.execute_input":"2025-08-29T18:49:45.846809Z","iopub.status.idle":"2025-08-29T18:49:45.859541Z","shell.execute_reply.started":"2025-08-29T18:49:45.846781Z","shell.execute_reply":"2025-08-29T18:49:45.858691Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Generating Random Values\n\n* `rand()` generates random values from a uniform distribution between 0 and 1 (1 excluded) by default.\n* `randint()` generates random integer values.\n* `randn()` generates random values from a normal (Gaussian) distribution.\n","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(2025)  # Set a seed to generate the same random values each time\n\nts_01 = torch.rand(size=(3, 4))  # Random float32 values between 0 and 1 (1 excluded)\nprint('ts_01:\\n', ts_01, ts_01.dtype)\nprint(ts_01.min(), ts_01.max())\n\nts_01 = torch.randint(low=0, high=100, size=(3, 4))  # Random integer values from 0 to 99\nprint('ts_01:\\n', ts_01, ts_01.dtype)\nprint(ts_01.min(), ts_01.max())\n\nts_01 = torch.randn(size=(3, 4))  # Random values from a normal distribution with mean 0 and variance 1\nprint('ts_01:\\n', ts_01, ts_01.dtype)\nprint(ts_01.min(), ts_01.max(), ts_01.mean(), ts_01.var())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:50:58.800058Z","iopub.execute_input":"2025-08-29T18:50:58.800324Z","iopub.status.idle":"2025-08-29T18:50:58.853627Z","shell.execute_reply.started":"2025-08-29T18:50:58.800304Z","shell.execute_reply":"2025-08-29T18:50:58.852819Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Changing Tensor Shape with `reshape()` and `view()`\n\n* Both `reshape()` and `view()` change the shape of a tensor, but `view()` works only on tensors with a contiguous memory layout. Even if the shape is `(2, 5)`, the data is stored as a single contiguous block in memory.\n* When a tensor is created, it is usually in a contiguous memory layout. However, operations like `permute` that reorder dimensions can break contiguity, and in that case, `view()` should not be used.\n* PyTorch generally recommends using `view()` over `reshape()` to encourage maintaining a contiguous memory layout in tensors.\n","metadata":{}},{"cell_type":"code","source":"import torch \n\nts_01 = torch.arange(10)\nprint('ts_01:\\n', ts_01)\n\nts_02 = ts_01.reshape((2, 5))\nprint('ts_02:\\n',ts_02)\n\nts_03 = ts_01.reshape(5, 2)\nprint('ts_03:\\n',ts_03)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:52:23.710395Z","iopub.execute_input":"2025-08-29T18:52:23.710855Z","iopub.status.idle":"2025-08-29T18:52:23.718055Z","shell.execute_reply.started":"2025-08-29T18:52:23.710828Z","shell.execute_reply":"2025-08-29T18:52:23.717246Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ### this will raise an error\n# ts_01.reshape(3, 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:53:34.851745Z","iopub.execute_input":"2025-08-29T18:53:34.852088Z","iopub.status.idle":"2025-08-29T18:53:34.899911Z","shell.execute_reply.started":"2025-08-29T18:53:34.852062Z","shell.execute_reply":"2025-08-29T18:53:34.898744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_02 = ts_01.view((2, 5))\nprint('ts_02:\\n', ts_02, ts_02.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:53:44.768565Z","iopub.execute_input":"2025-08-29T18:53:44.769331Z","iopub.status.idle":"2025-08-29T18:53:44.774576Z","shell.execute_reply.started":"2025-08-29T18:53:44.769307Z","shell.execute_reply":"2025-08-29T18:53:44.773866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(2025) \n\nts_01 = torch.rand(size=(16, 3, 32, 32))\nts_02 = ts_01.view(16, -1)\nprint(ts_02.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:54:13.709278Z","iopub.execute_input":"2025-08-29T18:54:13.709566Z","iopub.status.idle":"2025-08-29T18:54:13.716630Z","shell.execute_reply.started":"2025-08-29T18:54:13.709535Z","shell.execute_reply":"2025-08-29T18:54:13.715909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nts_01 = torch.arange(10)\nts_02 = ts_01.view(2, -1)\nts_03 = ts_01.reshape(2, -1)\n\nprint(ts_01.is_contiguous(), ts_02.is_contiguous(), ts_03.is_contiguous())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:54:27.405511Z","iopub.execute_input":"2025-08-29T18:54:27.406167Z","iopub.status.idle":"2025-08-29T18:54:27.411777Z","shell.execute_reply.started":"2025-08-29T18:54:27.406139Z","shell.execute_reply":"2025-08-29T18:54:27.410922Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Rearranging Tensor Dimensions with `permute()`, `t()`, and `transpose()`\n\n* `permute()` allows you to freely change the order of all dimensions.\n* `t()` swaps the rows and columns of a 2-dimensional tensor.\n* `transpose()` can swap only two specified dimensions.\n* Performing `permute()`, `t()`, or `transpose()` breaks the contiguous memory layout, so caution is needed when applying `view()` afterward.\n","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(2025)\n\nts_01 = torch.rand(size=(64, 64, 3))\nprint(ts_01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:00.481212Z","iopub.execute_input":"2025-08-29T18:55:00.481490Z","iopub.status.idle":"2025-08-29T18:55:00.494454Z","shell.execute_reply.started":"2025-08-29T18:55:00.481468Z","shell.execute_reply":"2025-08-29T18:55:00.493557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(2025)\n\nts_01 = torch.rand(size=(64, 64, 3))\nprint(ts_01.shape)\n\nts_02 = ts_01.permute(dims=(2, 0, 1)) # torch.permute(ts_01, dims=(2, 0, 1))\nprint(ts_02.shape)\n\nts_03 = ts_02.permute(dims=(1, 2, 0)) # torch.permute(ts_02, dims=(1, 2, 0))\nprint(ts_03.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:12.507123Z","iopub.execute_input":"2025-08-29T18:55:12.507845Z","iopub.status.idle":"2025-08-29T18:55:12.515507Z","shell.execute_reply.started":"2025-08-29T18:55:12.507810Z","shell.execute_reply":"2025-08-29T18:55:12.514721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01 = torch.rand(size=(16, 32, 32, 3))\nts_02 = ts_01.permute(dims=(0, 3, 1, 2))\nprint(ts_02.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:55:39.041212Z","iopub.execute_input":"2025-08-29T18:55:39.041505Z","iopub.status.idle":"2025-08-29T18:55:39.047066Z","shell.execute_reply.started":"2025-08-29T18:55:39.041482Z","shell.execute_reply":"2025-08-29T18:55:39.046122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01 = torch.rand(size=(3, 64, 64))\nts_02 = torch.permute(ts_01, dims=(1, 2, 0)) #Continuous memory structure can be broken when dimensional movement to permute.\nprint('ts_02 shape:', ts_02.shape)\nprint('is ts_02 contiguous? ', ts_02.is_contiguous())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:56:26.553445Z","iopub.execute_input":"2025-08-29T18:56:26.553798Z","iopub.status.idle":"2025-08-29T18:56:26.561152Z","shell.execute_reply.started":"2025-08-29T18:56:26.553774Z","shell.execute_reply":"2025-08-29T18:56:26.560435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # the following will raise an error\n# #  continuous memory structure is broken so view cannot be used.\n# ts_02_1 = ts_02.view(64, -1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:57:44.962591Z","iopub.execute_input":"2025-08-29T18:57:44.963508Z","iopub.status.idle":"2025-08-29T18:57:44.975123Z","shell.execute_reply.started":"2025-08-29T18:57:44.963475Z","shell.execute_reply":"2025-08-29T18:57:44.973996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01 = torch.rand(size=(3, 64, 64))\nts_02 = torch.permute(ts_01, dims=(1, 2, 0))\n\nts_02_1 = ts_02.reshape(64, -1) # reshape can be used regardless of continuous memory layout\nprint('ts_02_1 shape:', ts_02_1.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:59:13.220565Z","iopub.execute_input":"2025-08-29T18:59:13.220931Z","iopub.status.idle":"2025-08-29T18:59:13.230020Z","shell.execute_reply.started":"2025-08-29T18:59:13.220906Z","shell.execute_reply":"2025-08-29T18:59:13.229057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01 = torch.rand(size=(3, 4))\nts_02 = ts_01.t()\nprint('ts_02 shape:', ts_02.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:59:43.282995Z","iopub.execute_input":"2025-08-29T18:59:43.283797Z","iopub.status.idle":"2025-08-29T18:59:43.289017Z","shell.execute_reply.started":"2025-08-29T18:59:43.283768Z","shell.execute_reply":"2025-08-29T18:59:43.288084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01 = torch.rand(size=(64, 3, 128, 248))\nts_02 = ts_01.transpose(2, 3)\nprint('ts_02 shape:', ts_02.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T18:59:57.276441Z","iopub.execute_input":"2025-08-29T18:59:57.277060Z","iopub.status.idle":"2025-08-29T18:59:57.339879Z","shell.execute_reply.started":"2025-08-29T18:59:57.277031Z","shell.execute_reply":"2025-08-29T18:59:57.339137Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Applying Aggregations like `sum`, `max`, `min`, `mean` on Tensors\n\n* Aggregation methods such as `sum`, `max`, `min`, and `mean` have a `dim` argument. If `dim` is `None`, the aggregation is applied over all elements.\n* The `dim` argument specifies the dimension (axis) along which the aggregation is performed.\n* When aggregation is applied along a single dimension, the resulting tensor has one fewer dimension than the original tensor.\n* When aggregation is applied along multiple dimensions, the resulting tensor’s number of dimensions is reduced by the number of dimensions specified in `dim`.\n","metadata":{}},{"cell_type":"code","source":"import torch\nts_01 = torch.arange(10).view(2, 5)\nts_01.max()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:04:55.015778Z","iopub.execute_input":"2025-08-29T19:04:55.016432Z","iopub.status.idle":"2025-08-29T19:04:55.022784Z","shell.execute_reply.started":"2025-08-29T19:04:55.016406Z","shell.execute_reply":"2025-08-29T19:04:55.021945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch \n\nts_01 = torch.arange(10).view(2, 5)\nprint(ts_01)\n\nprint('total sum:', ts_01.sum())\nprint('sum along dim=0:', ts_01.sum(dim=0))\nprint('sum along dim=1:', ts_01.sum(dim=1))\n\nprint('max overall:', ts_01.max())\nprint('max along dim=0:', ts_01.max(dim=0))# it returns max value and the index \nprint('max along dim=1:', ts_01.max(dim=1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:05:22.786904Z","iopub.execute_input":"2025-08-29T19:05:22.787208Z","iopub.status.idle":"2025-08-29T19:05:22.800571Z","shell.execute_reply.started":"2025-08-29T19:05:22.787184Z","shell.execute_reply":"2025-08-29T19:05:22.799447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ts_01)\nprint('overall mean:', ts_01.mean(dtype=torch.float64))\nprint('mean along dim=0:', ts_01.mean(dim=0, dtype=torch.float64))\nprint('mean along dim=1:', ts_01.mean(dim=1, dtype=torch.float64))\n\nprint('min overall:', ts_01.min())\nprint('min along dim=0:', ts_01.min(dim=0))\nprint('min along dim=1:', ts_01.min(dim=1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:07:23.237328Z","iopub.execute_input":"2025-08-29T19:07:23.237696Z","iopub.status.idle":"2025-08-29T19:07:23.248457Z","shell.execute_reply.started":"2025-08-29T19:07:23.237670Z","shell.execute_reply":"2025-08-29T19:07:23.247695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntorch.arange(24).reshape(2, 3, 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:07:40.882836Z","iopub.execute_input":"2025-08-29T19:07:40.883102Z","iopub.status.idle":"2025-08-29T19:07:40.889312Z","shell.execute_reply.started":"2025-08-29T19:07:40.883082Z","shell.execute_reply":"2025-08-29T19:07:40.888710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_02 = torch.arange(24).reshape(2, 3, 4)\nprint(ts_02)\n\nprint('total sum:', ts_02.sum())\nprint('sum along dim=0:\\n', ts_02.sum(dim=0))\nprint('sum along dim=1:\\n', ts_02.sum(dim=1))\nprint('sum along dim=2:\\n', ts_02.sum(dim=2))\nprint('sum along dim=-1:\\n', ts_02.sum(dim=-1))\n\nprint('max overall:', ts_02.max())\nprint('max along dim=0:', ts_02.max(dim=0))# # Returns both the maximum value and the index where the maximum occurs.\nprint('max along dim=1:', ts_02.max(dim=1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:07:45.211725Z","iopub.execute_input":"2025-08-29T19:07:45.212423Z","iopub.status.idle":"2025-08-29T19:07:45.224445Z","shell.execute_reply.started":"2025-08-29T19:07:45.212398Z","shell.execute_reply":"2025-08-29T19:07:45.223663Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ts_02)\nprint('sum along dim=(1, 2):\\n', ts_02.sum(dim=(1, 2)))\nprint('sum along dim=(2, 1):\\n', ts_02.sum(dim=(2, 1)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:07:58.530387Z","iopub.execute_input":"2025-08-29T19:07:58.531127Z","iopub.status.idle":"2025-08-29T19:07:58.536954Z","shell.execute_reply.started":"2025-08-29T19:07:58.531101Z","shell.execute_reply":"2025-08-29T19:07:58.536236Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ts_02)\nprint('sum along dim=(0, 1):\\n', ts_02.sum(dim=(0, 1)))\nprint('sum along dim=(1, 0):\\n', ts_02.sum(dim=(1, 0)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:08:08.126963Z","iopub.execute_input":"2025-08-29T19:08:08.127243Z","iopub.status.idle":"2025-08-29T19:08:08.134672Z","shell.execute_reply.started":"2025-08-29T19:08:08.127220Z","shell.execute_reply":"2025-08-29T19:08:08.133711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ts_02)\nprint('sum along dim=(-1):\\n', ts_02.sum(dim=(-1)))\nprint('sum along dim=(-2, -1):\\n', ts_02.sum(dim=(-2, -1)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:08:15.869954Z","iopub.execute_input":"2025-08-29T19:08:15.870428Z","iopub.status.idle":"2025-08-29T19:08:15.876997Z","shell.execute_reply.started":"2025-08-29T19:08:15.870404Z","shell.execute_reply":"2025-08-29T19:08:15.876157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Performing `argmax()`\n\n* While `max()` returns the largest value in a tensor, `argmax()` returns the index of the largest value.\n","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(2025)  # Set a seed to generate the same random values each time\n\nts_01 = torch.rand(size=(10,))\nprint(ts_01)\nprint(ts_01.max(), ts_01.argmax())  # Print the maximum value and its corresponding index\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:11:01.365892Z","iopub.execute_input":"2025-08-29T19:11:01.366197Z","iopub.status.idle":"2025-08-29T19:11:01.374522Z","shell.execute_reply.started":"2025-08-29T19:11:01.366175Z","shell.execute_reply":"2025-08-29T19:11:01.373784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\ntorch.manual_seed(2025)\n\nts_01 = torch.rand(size=(4, 5))\nprint(ts_01)\nprint(ts_01.argmax(dim=-1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:11:45.828763Z","iopub.execute_input":"2025-08-29T19:11:45.829415Z","iopub.status.idle":"2025-08-29T19:11:45.836990Z","shell.execute_reply.started":"2025-08-29T19:11:45.829387Z","shell.execute_reply":"2025-08-29T19:11:45.836177Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ts_01.max(dim=-1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:13:06.263598Z","iopub.execute_input":"2025-08-29T19:13:06.263935Z","iopub.status.idle":"2025-08-29T19:13:06.269439Z","shell.execute_reply.started":"2025-08-29T19:13:06.263911Z","shell.execute_reply":"2025-08-29T19:13:06.268692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_val, val_index = ts_01.max(dim=-1)\nprint(max_val, val_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:13:20.078442Z","iopub.execute_input":"2025-08-29T19:13:20.079161Z","iopub.status.idle":"2025-08-29T19:13:20.085171Z","shell.execute_reply.started":"2025-08-29T19:13:20.079130Z","shell.execute_reply":"2025-08-29T19:13:20.084293Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"_, val_index = ts_01.max(dim=-1)\nprint( val_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:13:36.433064Z","iopub.execute_input":"2025-08-29T19:13:36.433335Z","iopub.status.idle":"2025-08-29T19:13:36.438451Z","shell.execute_reply.started":"2025-08-29T19:13:36.433313Z","shell.execute_reply":"2025-08-29T19:13:36.437704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ts_01.argmax(dim=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:13:44.600022Z","iopub.execute_input":"2025-08-29T19:13:44.600573Z","iopub.status.idle":"2025-08-29T19:13:44.605789Z","shell.execute_reply.started":"2025-08-29T19:13:44.600548Z","shell.execute_reply":"2025-08-29T19:13:44.605078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### `squeeze()` and `unsqueeze()`\n\n* `squeeze()` returns a tensor with dimensions of size 1 removed, while `unsqueeze()` increases the tensor’s dimensions by 1 at the specified position.\n* Specifying a dimension like `squeeze(dim=0)` removes only that dimension if its size is 1, returning a restructured tensor.\n* `squeeze(dim=None)` removes all dimensions of size 1 in the tensor.\n* `unsqueeze()` requires the `dim` argument (e.g., `dim=0`) to specify where to add the new dimension. It is also recommended to provide the `dim` argument when using `squeeze()`.\n","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(2025)\n\nts_01 = torch.rand(size=(1, 4, 5))\nprint(ts_01)\n\nts_01_1 = ts_01.squeeze()\nprint('ts_01 shape:', ts_01.shape, 'ts_01 squeezed shape:', ts_01_1.shape)\nprint(ts_01_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:14:25.812941Z","iopub.execute_input":"2025-08-29T19:14:25.813208Z","iopub.status.idle":"2025-08-29T19:14:25.821416Z","shell.execute_reply.started":"2025-08-29T19:14:25.813187Z","shell.execute_reply":"2025-08-29T19:14:25.820595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nts_01 = torch.rand(size=(1, 4, 1))\nts_01_1 = ts_01.squeeze(dim=0)\nts_01_2 = ts_01.squeeze(dim=-1)\nts_01_3 = ts_01.squeeze(dim=(0, -1))\n\nprint(ts_01.shape, ts_01_1.shape, ts_01_2.shape, ts_01_3.shape)\nprint(ts_01_2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:15:00.185380Z","iopub.execute_input":"2025-08-29T19:15:00.185700Z","iopub.status.idle":"2025-08-29T19:15:00.193188Z","shell.execute_reply.started":"2025-08-29T19:15:00.185675Z","shell.execute_reply":"2025-08-29T19:15:00.192391Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Commonly used to convert a 4D image tensor with a batch dimension of 1 into a 3D single image tensor\nts_01 = torch.rand(size=(1, 3, 64, 64))\nts_01_1 = ts_01.squeeze(dim=0)\nprint('ts_01 shape:', ts_01.shape, 'ts_01 squeezed shape:', ts_01_1.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:15:33.261429Z","iopub.execute_input":"2025-08-29T19:15:33.261785Z","iopub.status.idle":"2025-08-29T19:15:33.267849Z","shell.execute_reply.started":"2025-08-29T19:15:33.261759Z","shell.execute_reply":"2025-08-29T19:15:33.267002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(2025)\n\nts_01 = torch.rand(size=(4, 5))\nprint(ts_01)\n\nts_01_1 = ts_01.unsqueeze(dim=0) # dim argument should be set\nprint('ts_01 shape:', ts_01.shape, 'ts_01 unsqueezed shape:', ts_01_1.shape)\nprint(ts_01_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:15:53.338761Z","iopub.execute_input":"2025-08-29T19:15:53.339052Z","iopub.status.idle":"2025-08-29T19:15:53.348716Z","shell.execute_reply.started":"2025-08-29T19:15:53.339029Z","shell.execute_reply":"2025-08-29T19:15:53.347917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Commonly used to convert a 3D single image tensor into a 4D image tensor with a batch dimension\nts_01 = torch.rand(size=(3, 64, 64))\nts_01_1 = ts_01.unsqueeze(dim=0)\nprint('ts_01 shape:', ts_01.shape, 'ts_01 unsqueezed shape:', ts_01_1.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:16:39.050581Z","iopub.execute_input":"2025-08-29T19:16:39.051009Z","iopub.status.idle":"2025-08-29T19:16:39.056853Z","shell.execute_reply.started":"2025-08-29T19:16:39.050984Z","shell.execute_reply":"2025-08-29T19:16:39.055906Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### `item()`\n\n* Used to return the value of a tensor rather than the tensor itself. If the tensor contains only a single value, it returns that value as a Python scalar.\n* `item()` can only be used when a 1D tensor has a single element or the tensor is a scalar.\n","metadata":{}},{"cell_type":"code","source":"import torch\nts_01 = torch.tensor([1])\nprint(ts_01.dtype, ts_01.shape, ts_01.ndim)\nprint('ts_01 item():', ts_01.item())\n\nts_02 = torch.tensor(1)\nprint(ts_02.dtype, ts_02.shape, ts_02.ndim)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:17:47.283023Z","iopub.execute_input":"2025-08-29T19:17:47.283851Z","iopub.status.idle":"2025-08-29T19:17:47.288955Z","shell.execute_reply.started":"2025-08-29T19:17:47.283785Z","shell.execute_reply":"2025-08-29T19:17:47.288115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Although this is a 1D tensor, it has more than one value, so calling item() will raise an error.\n# ts_01 = torch.tensor([1, 2])\n# print(ts_01.dtype, ts_01.shape, ts_01.ndim)\n# print('ts_01 item():', ts_01.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:18:06.004036Z","iopub.execute_input":"2025-08-29T19:18:06.004322Z","iopub.status.idle":"2025-08-29T19:18:06.021317Z","shell.execute_reply.started":"2025-08-29T19:18:06.004300Z","shell.execute_reply":"2025-08-29T19:18:06.020248Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Indexing\n\n* Tensor indexing is very similar to NumPy array indexing.\n* In addition to single integer indexing, slicing (`:`), fancy (list) indexing, and boolean indexing, PyTorch supports various other indexing methods.\n* Using single integer indexing returns a tensor with one less dimension than the original tensor (same as NumPy arrays).\n* Unlike NumPy, PyTorch boolean indexing returns a 1D tensor, whereas NumPy preserves the original dimensions.\n","metadata":{}},{"cell_type":"code","source":"ts_01 = torch.arange(0, 10).view(2, 5)\nprint(ts_01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:19:20.015569Z","iopub.execute_input":"2025-08-29T19:19:20.016513Z","iopub.status.idle":"2025-08-29T19:19:20.021770Z","shell.execute_reply.started":"2025-08-29T19:19:20.016474Z","shell.execute_reply":"2025-08-29T19:19:20.020901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint('ts_01[0, 0]:', ts_01[0, 0], 'ts_01[0, 1]:', ts_01[0, 1])\nprint('ts_01[1, 0]:', ts_01[1, 0], 'ts_01[1, 2]:', ts_01[1, 2])\nprint(ts_01[0, 0].shape, ts_01[0, 0].ndim, ts_01[0, :].shape, ts_01[0, :].ndim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:19:35.076189Z","iopub.execute_input":"2025-08-29T19:19:35.076460Z","iopub.status.idle":"2025-08-29T19:19:35.085558Z","shell.execute_reply.started":"2025-08-29T19:19:35.076437Z","shell.execute_reply":"2025-08-29T19:19:35.084869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01[0,:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:21:41.478440Z","iopub.execute_input":"2025-08-29T19:21:41.479698Z","iopub.status.idle":"2025-08-29T19:21:41.485865Z","shell.execute_reply.started":"2025-08-29T19:21:41.479555Z","shell.execute_reply":"2025-08-29T19:21:41.484907Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(ts_01)\nprint('ts_01[0, :] is', ts_01[0, :], 'ts_01[:, 0] is', ts_01[:, 0])\nprint('ts_01[0, 0:3] is', ts_01[0, 0:3], 'ts_01[1, 1:4] is', ts_01[1, 1:4])\nprint('ts_01[:, :]\\n', ts_01[:, :])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:22:05.993251Z","iopub.execute_input":"2025-08-29T19:22:05.993539Z","iopub.status.idle":"2025-08-29T19:22:06.000783Z","shell.execute_reply.started":"2025-08-29T19:22:05.993514Z","shell.execute_reply":"2025-08-29T19:22:06.000052Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(2025)\n\nrandom_indexes = torch.randint(0, 5, size=(4,))\nprint('random_indexes:', random_indexes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:22:15.785780Z","iopub.execute_input":"2025-08-29T19:22:15.786580Z","iopub.status.idle":"2025-08-29T19:22:15.793385Z","shell.execute_reply.started":"2025-08-29T19:22:15.786549Z","shell.execute_reply":"2025-08-29T19:22:15.792701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.manual_seed(2025)\n\nrandom_indexes = torch.randint(0, 5, size=(4,))\nprint('random_indexes:', random_indexes)\n\nts_01 = torch.rand(size=(10, 5))\nprint('ts_01:\\n', ts_01)\n\nts_01_1 = ts_01[random_indexes] # fancy indexing \nprint('ts_01_1:\\n', ts_01_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:22:56.245001Z","iopub.execute_input":"2025-08-29T19:22:56.245289Z","iopub.status.idle":"2025-08-29T19:22:56.258244Z","shell.execute_reply.started":"2025-08-29T19:22:56.245266Z","shell.execute_reply":"2025-08-29T19:22:56.257330Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01 = torch.arange(0, 10).view(2, 5)\nprint(ts_01)\n\nmask = ts_01 > 3\nprint(mask)\nprint(ts_01[mask])  # Boolean indexing on a PyTorch tensor returns a 1D tensor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:24:07.557971Z","iopub.execute_input":"2025-08-29T19:24:07.558495Z","iopub.status.idle":"2025-08-29T19:24:07.565542Z","shell.execute_reply.started":"2025-08-29T19:24:07.558471Z","shell.execute_reply":"2025-08-29T19:24:07.564778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# `where` preserves the original tensor's dimensions\ntorch.where(ts_01 > 4, input=ts_01, other=torch.tensor(999))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:24:39.658553Z","iopub.execute_input":"2025-08-29T19:24:39.658873Z","iopub.status.idle":"2025-08-29T19:24:39.665554Z","shell.execute_reply.started":"2025-08-29T19:24:39.658850Z","shell.execute_reply":"2025-08-29T19:24:39.664877Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Dot Product and Matrix Multiplication – `dot()` and `matmul()`\n\n* PyTorch’s `dot()` operation works only on 1D tensors (vector dot product).\n* PyTorch’s `matmul()` operation performs matrix multiplication between 1D–2D tensors or between 2D tensors (matrices).\n* For `matmul()`, if tensors with 3 or more dimensions are input, the last two dimensions are treated as matrices, and the preceding dimensions are treated as batch dimensions for batch matrix multiplication.\n  ![Matrix Multiplication](https://github.com/chulminkw/CNN_PG_Torch/blob/main/image/matmul.png?raw=true)\n","metadata":{}},{"cell_type":"code","source":"import torch \n\nts_01 = torch.arange(1, 4)\nts_02 = torch.arange(4, 7)\nprint('ts_01:', ts_01, 'ts_02:', ts_02)\n\nts_03 = torch.dot(ts_01, ts_02) # dot() can be done with 1-d tensors. \nprint('ts_03:', ts_03)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:26:12.190547Z","iopub.execute_input":"2025-08-29T19:26:12.191445Z","iopub.status.idle":"2025-08-29T19:26:12.201979Z","shell.execute_reply.started":"2025-08-29T19:26:12.191406Z","shell.execute_reply":"2025-08-29T19:26:12.201082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_01 = torch.arange(1, 7).view(2, 3)\nts_02 = torch.arange(7, 13).view(3, 2)\nprint('ts_01:\\n', ts_01, '\\n', 'ts_02:\\n', ts_02)\n\nts_03 = torch.matmul(ts_01, ts_02) # 2-d matrix multiplication\nprint('ts_03:\\n', ts_03)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:27:36.188632Z","iopub.execute_input":"2025-08-29T19:27:36.189435Z","iopub.status.idle":"2025-08-29T19:27:36.199416Z","shell.execute_reply.started":"2025-08-29T19:27:36.189406Z","shell.execute_reply":"2025-08-29T19:27:36.198468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Matrix multiplication with tensors of 3 or more dimensions. Batch sizes must match, but if one has batch size 1, it’s allowed.\nts_01 = torch.arange(0, 24).view(2, 3, 4)  # 3x4 matrices with batch size 2\nts_02 = torch.arange(0, 40).view(2, 4, 5)  # 4x5 matrices with batch size 2\nprint('ts_01:\\n', ts_01, '\\n', 'ts_02:\\n', ts_02)\n\nts_03 = torch.matmul(ts_01, ts_02)  # The first dimension is treated as batch; the last two dimensions are multiplied as matrices\nprint('ts_03:\\n', ts_03)\nprint(ts_03.shape)  # Output shape is (2, 3, 5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:27:41.677821Z","iopub.execute_input":"2025-08-29T19:27:41.678351Z","iopub.status.idle":"2025-08-29T19:27:41.687027Z","shell.execute_reply.started":"2025-08-29T19:27:41.678327Z","shell.execute_reply":"2025-08-29T19:27:41.686130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.matmul(\ntorch.tensor(\n[[ 0,  1,  2,  3],\n[ 4,  5,  6,  7],\n[ 8,  9, 10, 11]]), \ntorch.tensor(\n[[ 0,  1,  2,  3,  4],\n[ 5,  6,  7,  8,  9],\n[10, 11, 12, 13, 14],\n[15, 16, 17, 18, 19]]\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:27:54.284534Z","iopub.execute_input":"2025-08-29T19:27:54.285310Z","iopub.status.idle":"2025-08-29T19:27:54.292777Z","shell.execute_reply.started":"2025-08-29T19:27:54.285282Z","shell.execute_reply":"2025-08-29T19:27:54.292080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Batch sizes must match, but if one has batch size 1, it is allowed.\nts_01 = torch.arange(0, 24).view(2, 3, 4)  # 3x4 matrices with batch size 2\nts_02 = torch.arange(0, 60).view(3, 4, 5)  # 4x5 matrices with batch size 3\nprint('ts_01:\\n', ts_01, '\\n', 'ts_02:\\n', ts_02)\n\nts_03 = torch.matmul(ts_01, ts_02)  # The first dimension is treated as batch; the last two dimensions are multiplied as matrices\nprint(ts_03)\nprint(ts_03.shape)  # Output shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T19:28:32.668227Z","iopub.execute_input":"2025-08-29T19:28:32.668540Z","iopub.status.idle":"2025-08-29T19:28:32.728865Z","shell.execute_reply.started":"2025-08-29T19:28:32.668516Z","shell.execute_reply":"2025-08-29T19:28:32.727689Z"}},"outputs":[],"execution_count":null}]}