{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32df99a2",
   "metadata": {
    "papermill": {
     "duration": 0.009668,
     "end_time": "2025-08-30T17:32:57.253014",
     "exception": false,
     "start_time": "2025-08-30T17:32:57.243346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating and Training a Model on Fashion MNIST Data\n",
    "\n",
    "* Create the FashionMNIST dataset, apply transformations, and set up the DataLoader.\n",
    "* Build a neural network model using layers, functions, and `Sequential`.\n",
    "* Understand the loss function and optimizer.\n",
    "* Implement the training loop:\n",
    "\n",
    "  * In PyTorch, the model creation and training logic are loosely coupled.\n",
    "  * The model focuses on transforming input tensors (batch-wise) according to the network structure and returning output tensors, which implicitly builds the computational graph.\n",
    "  * The training loop uses the output tensors along with a loss function and optimizer to perform backpropagation and update the model’s weight parameters. This process is repeated for each batch of training data and iterated over the entire dataset for the number of epochs specified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acedd8c7",
   "metadata": {
    "papermill": {
     "duration": 0.007812,
     "end_time": "2025-08-30T17:32:57.269278",
     "exception": false,
     "start_time": "2025-08-30T17:32:57.261466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Creating the Fashion MNIST Dataset\n",
    "\n",
    "* Download the FashionMNIST dataset from `torchvision.datasets`.\n",
    "* Setting `train=True` creates the training dataset, while `train=False` creates the test dataset.\n",
    "* The image data is in PIL format, so you need to convert it to a tensor using `torchvision.transforms.ToTensor()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56600b09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:32:57.287726Z",
     "iopub.status.busy": "2025-08-30T17:32:57.287160Z",
     "iopub.status.idle": "2025-08-30T17:33:17.332208Z",
     "shell.execute_reply": "2025-08-30T17:33:17.331272Z"
    },
    "papermill": {
     "duration": 20.055261,
     "end_time": "2025-08-30T17:33:17.333431",
     "exception": false,
     "start_time": "2025-08-30T17:32:57.278170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:03<00:00, 7.60MB/s]\n",
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 113kB/s]\n",
      "100%|██████████| 4.42M/4.42M [00:02<00:00, 1.83MB/s]\n",
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor  # Important class to convert images to tensors\n",
    "\n",
    "# Download the FashionMNIST training dataset\n",
    "train_data = datasets.FashionMNIST(root='data', train=True, download=True)  # , transform=ToTensor()\n",
    "\n",
    "# Download the test dataset (used here for testing/validation purposes — though ideally should not be used for validation)\n",
    "test_data = datasets.FashionMNIST(root='data', train=False, download=True)  # , transform=ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d669415",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:17.354202Z",
     "iopub.status.busy": "2025-08-30T17:33:17.353797Z",
     "iopub.status.idle": "2025-08-30T17:33:17.359033Z",
     "shell.execute_reply": "2025-08-30T17:33:17.358319Z"
    },
    "papermill": {
     "duration": 0.016733,
     "end_time": "2025-08-30T17:33:17.360134",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.343401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df810209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:17.380199Z",
     "iopub.status.busy": "2025-08-30T17:33:17.379756Z",
     "iopub.status.idle": "2025-08-30T17:33:17.384427Z",
     "shell.execute_reply": "2025-08-30T17:33:17.383680Z"
    },
    "papermill": {
     "duration": 0.015908,
     "end_time": "2025-08-30T17:33:17.385551",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.369643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1907350b",
   "metadata": {
    "papermill": {
     "duration": 0.009658,
     "end_time": "2025-08-30T17:33:17.405798",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.396140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PIL: Python Imaging Library**\n",
    "\n",
    "* Provides useful functions for image processing, such as opening images, cropping, rotating, applying filters, and saving.\n",
    "* `PIL.Image.Image` is the image object type used by the Pillow (PIL) library.\n",
    "  → In other words, it can be thought of as a **Python object representing an image file in memory**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215ec9e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:17.426336Z",
     "iopub.status.busy": "2025-08-30T17:33:17.425765Z",
     "iopub.status.idle": "2025-08-30T17:33:17.433292Z",
     "shell.execute_reply": "2025-08-30T17:33:17.432456Z"
    },
    "papermill": {
     "duration": 0.019047,
     "end_time": "2025-08-30T17:33:17.434486",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.415439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x796067542E10>, 9)\n",
      "<class 'tuple'>\n",
      "<class 'PIL.Image.Image'>\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "# Each Fashion MNIST data point consists of a tuple containing a PIL Image and its corresponding label/target\n",
    "print(train_data[0])\n",
    "print(type(train_data[0]))\n",
    "print(type(train_data[0][0]))\n",
    "print(len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ff012f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:17.454841Z",
     "iopub.status.busy": "2025-08-30T17:33:17.454396Z",
     "iopub.status.idle": "2025-08-30T17:33:17.491433Z",
     "shell.execute_reply": "2025-08-30T17:33:17.490685Z"
    },
    "papermill": {
     "duration": 0.048239,
     "end_time": "2025-08-30T17:33:17.492569",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.444330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+tbw1oNx4m8QWmkWx2yXD4LkZCADJJ+gFbviL4a63oc7COE3MW4hdn38duD976jNc9daDqllIsc9lKrMu4YGeMkdR7gj8KzcV7H8BtEvV16+1iWCeG1Wz8mOV02pIzupwCeuAp6Z98cZ90aIzLIlw0c0ZJ4KgjHoeOa+evjS9n/wnMcNxBPCYLKONFhA2FNzMpGenDcgd816V4K03wefC+m3NlpVhP+5QSXBiR5fMx825iMg5zwce3FdbOzTwgW90lu6uCm8eYrL02soIyCPQgggEdMGQ3cluiPNK0rJwrRQBNueuMkt+teNfGKxsdY8WWdxNqcNo66eieXMwVsb5DnH415Hp2rajpE5n02/urOUjBe3laMkehIPIrVm8eeLrhNknibVivoLtx/I1UPinxC3XXtUP1vJP8ay5JZJpGkldnduSzHJP41//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACD0lEQVR4AbWRz2sTQRTH38zszm42k6Q2TU2ixURstRdRasWC9FCsUE9SpIKnKl48+x94UOjNiyf/h4KgKN7TYgNKK+agjZS0wZDYbND90dn54VqxIWfxXebBB97nfecB/P9CAKkFAGT8ViEEh+9fLZZn7gde+E4AwkgAGYBEzl3btZz55y0tgSl/AHKYLhH85uJKdat2ebqyFmuOCun5laFIwcYXjvLRxq1nfRh3er0ESHAI1fvPYqF8oj9WxxO6hcAyWZhQV2fw6OvBbcEh2O/tlxTCjlRjgPtGAqwYcpN7GWUlPbppXepDTeB2AduQHONWpOzsi09GHxocPobUccZPh8RhcvfOy/V4IUQwigMIgFdeQHWb2BFEipzvxU6iBT9QALNPq8F3oYTnSRt8oN4iHOYcLk4UFs+GOEo0TZrlToXNqp7ZmkQw8yg3JIkrHI6C2lI1dawE9dQPP8HSDiJrRSF9IAFAZmT5+oNm+LU+nuVmispT6N6TbcYsMDONZg7nb9rl5NQU5pgCMq8YrUY6bDCa3t9hQShWt0rD3I0kNxWiE8aebiRH3E7bsEw7hTuTXqNrdSIRJfK9C8aH1bvNesioTcmB1P43JY2QcdeNRLkVR7nx8HjblYQaBGnTpCYC1AKq8ptLCMf55x6PZjAxJGrpPfWTgI58/LZW+fMJ8WXO5bond/j20Y3+sfkFaCTYdrBYeB0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0]  # PIL Image can be visualized directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f6dfc0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:17.514533Z",
     "iopub.status.busy": "2025-08-30T17:33:17.513783Z",
     "iopub.status.idle": "2025-08-30T17:33:17.518149Z",
     "shell.execute_reply": "2025-08-30T17:33:17.517516Z"
    },
    "papermill": {
     "duration": 0.016023,
     "end_time": "2025-08-30T17:33:17.519213",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.503190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data.data), train_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99dd95eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:17.540143Z",
     "iopub.status.busy": "2025-08-30T17:33:17.539807Z",
     "iopub.status.idle": "2025-08-30T17:33:17.546095Z",
     "shell.execute_reply": "2025-08-30T17:33:17.545461Z"
    },
    "papermill": {
     "duration": 0.017984,
     "end_time": "2025-08-30T17:33:17.547206",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.529222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_data.targets.shape) #label "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81fb554",
   "metadata": {
    "papermill": {
     "duration": 0.009683,
     "end_time": "2025-08-30T17:33:17.566994",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.557311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`train_data.data`:\n",
    "This attribute directly accesses the raw image tensors inside the `datasets.FashionMNIST` class.\n",
    "\n",
    "In other words, it contains the unprocessed, raw data before any transforms are applied, and PyTorch stores it internally as `torch.Tensor`.\n",
    "\n",
    "`train_data[0][0]` → accessed externally via `__getitem__()` and converted to a `PIL.Image`.\n",
    "\n",
    "`train_data.data` → internal storage, already stored as tensors for all images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b08d338",
   "metadata": {
    "papermill": {
     "duration": 0.009619,
     "end_time": "2025-08-30T17:33:17.586316",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.576697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Visualizing Fashion MNIST Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3611d826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:17.607077Z",
     "iopub.status.busy": "2025-08-30T17:33:17.606435Z",
     "iopub.status.idle": "2025-08-30T17:33:17.813682Z",
     "shell.execute_reply": "2025-08-30T17:33:17.812933Z"
    },
    "papermill": {
     "duration": 0.218995,
     "end_time": "2025-08-30T17:33:17.815039",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.596044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '9')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_image = train_data[0][0]\n",
    "train_label = train_data[0][1]\n",
    "\n",
    "#visualize PIL Image\n",
    "plt.imshow(train_image, cmap='gray') # Set the colormap to 'gray' to display the image in grayscale\n",
    "\n",
    "plt.title(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ef61fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:17.836786Z",
     "iopub.status.busy": "2025-08-30T17:33:17.836564Z",
     "iopub.status.idle": "2025-08-30T17:33:19.957294Z",
     "shell.execute_reply": "2025-08-30T17:33:19.956470Z"
    },
    "papermill": {
     "duration": 2.132887,
     "end_time": "2025-08-30T17:33:19.958752",
     "exception": false,
     "start_time": "2025-08-30T17:33:17.825865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = [image for image, _ in train_data]\n",
    "train_labels = [label for _, label in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf2a8ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:20.030534Z",
     "iopub.status.busy": "2025-08-30T17:33:20.030266Z",
     "iopub.status.idle": "2025-08-30T17:33:20.034908Z",
     "shell.execute_reply": "2025-08-30T17:33:20.034356Z"
    },
    "papermill": {
     "duration": 0.017052,
     "end_time": "2025-08-30T17:33:20.035902",
     "exception": false,
     "start_time": "2025-08-30T17:33:20.018850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93e09013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:20.057275Z",
     "iopub.status.busy": "2025-08-30T17:33:20.057035Z",
     "iopub.status.idle": "2025-08-30T17:33:21.938370Z",
     "shell.execute_reply": "2025-08-30T17:33:21.937671Z"
    },
    "papermill": {
     "duration": 1.893245,
     "end_time": "2025-08-30T17:33:21.939505",
     "exception": false,
     "start_time": "2025-08-30T17:33:20.046260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class_names=['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "def show_images(images, labels, ncols=8):\n",
    "    figure, axs = plt.subplots(figsize=(22,6), nrows=1, ncols=ncols)\n",
    "    for i in range(ncols):\n",
    "        axs[i].imshow(images[i], cmap='gray')\n",
    "        axs[i].set_title(class_names[labels[i]])\n",
    "\n",
    "show_images(train_images[:8], train_labels[:8], ncols=8)\n",
    "show_images(train_images[8:16], train_labels[8:16], ncols=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933c443",
   "metadata": {
    "papermill": {
     "duration": 0.011025,
     "end_time": "2025-08-30T17:33:21.962438",
     "exception": false,
     "start_time": "2025-08-30T17:33:21.951413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating a DataLoader to Fetch the Dataset in Batches\n",
    "\n",
    "* A `DataLoader` efficiently feeds a dataset to the model in batches.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* **dataset**: The dataset object to load.\n",
    "* **batch\\_size**: Number of samples to load per batch.\n",
    "* **shuffle**: Whether to shuffle the data at the end of each epoch.\n",
    "* **num\\_workers**: Number of parallel worker processes for loading data.\n",
    "\n",
    "  * CPU handles data preparation (e.g., opening images, applying transforms) while GPU performs computations.\n",
    "  * If data is not prepared quickly enough, the GPU waits idly.\n",
    "  * Loading data in parallel across multiple CPU processes significantly speeds up training.\n",
    "\n",
    "- It is recommended that the DataLoader outputs data in tensor form.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f126abda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:21.986190Z",
     "iopub.status.busy": "2025-08-30T17:33:21.985661Z",
     "iopub.status.idle": "2025-08-30T17:33:21.990172Z",
     "shell.execute_reply": "2025-08-30T17:33:21.989470Z"
    },
    "papermill": {
     "duration": 0.017779,
     "end_time": "2025-08-30T17:33:21.991337",
     "exception": false,
     "start_time": "2025-08-30T17:33:21.973558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create DataLoader \n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ffa52f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:22.015227Z",
     "iopub.status.busy": "2025-08-30T17:33:22.014549Z",
     "iopub.status.idle": "2025-08-30T17:33:22.017691Z",
     "shell.execute_reply": "2025-08-30T17:33:22.017206Z"
    },
    "papermill": {
     "duration": 0.015969,
     "end_time": "2025-08-30T17:33:22.018645",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.002676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # The following error occurs because DataLoader cannot batch PIL images directly.\n",
    "# # TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>\n",
    "# images, labels = next(iter(train_loader))\n",
    "# print(images.shape, images.dtype, labels.shape, labels.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dae33478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:22.042370Z",
     "iopub.status.busy": "2025-08-30T17:33:22.041699Z",
     "iopub.status.idle": "2025-08-30T17:33:22.277064Z",
     "shell.execute_reply": "2025-08-30T17:33:22.276174Z"
    },
    "papermill": {
     "duration": 0.248392,
     "end_time": "2025-08-30T17:33:22.278362",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.029970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data image, label type: <class 'torch.Tensor'> <class 'int'>\n",
      "torch.Size([32, 1, 28, 28]) torch.float32 torch.Size([32]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Apply torchvision.transforms.ToTensor() during dataset download so DataLoader returns tensors\n",
    "train_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=ToTensor())\n",
    "val_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=ToTensor())\n",
    "# ToTensor() converts images to tensors and normalizes pixel values to [0, 1]\n",
    "# Each time a dataset item is accessed via indexing, ToTensor() is applied\n",
    "print('train_data image, label type:', type(train_data[0][0]), type(train_data[0][1]))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape, images.dtype, labels.shape, labels.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d93dbf",
   "metadata": {
    "papermill": {
     "duration": 0.011992,
     "end_time": "2025-08-30T17:33:22.301952",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.289960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating a Linear Model\n",
    "\n",
    "* A Linear Model takes a 4-dimensional image batch tensor as input and outputs 10 classification logits.\n",
    "* Since a Linear layer expects a 2D input (batch size × features), each individual 3D image (grayscale images are originally 2D, but represented as 3D with channel dimension) must be flattened into a 1D tensor using `nn.Flatten()`.\n",
    "* Model construction can be done in several ways:\n",
    "\n",
    "  * Declare all Linear layers and activation functions as separate `Layer` objects, then chain them in `forward()`.\n",
    "  * Declare only weight-bearing layers (e.g., Linear) as `Layer` objects and use functional APIs for activation, pooling, etc., in `forward()`.\n",
    "  * Use `nn.Sequential` to stack layers and functions in a single, ordered container.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5ce58bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:22.326199Z",
     "iopub.status.busy": "2025-08-30T17:33:22.325434Z",
     "iopub.status.idle": "2025-08-30T17:33:22.331162Z",
     "shell.execute_reply": "2025-08-30T17:33:22.330296Z"
    },
    "papermill": {
     "duration": 0.019308,
     "end_time": "2025-08-30T17:33:22.332323",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.313015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32, 784])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# apply Flatten\n",
    "flatten = nn.Flatten()\n",
    "flatten_output = flatten(images) # start_dim = 1 , end_dim = -1\n",
    "print(images.shape, flatten_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "465ffba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:22.355996Z",
     "iopub.status.busy": "2025-08-30T17:33:22.355710Z",
     "iopub.status.idle": "2025-08-30T17:33:22.361176Z",
     "shell.execute_reply": "2025-08-30T17:33:22.360604Z"
    },
    "papermill": {
     "duration": 0.018573,
     "end_time": "2025-08-30T17:33:22.362293",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.343720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleLinearModel_01(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_01 = nn.Linear(in_features=input_size*input_size, out_features=200 )\n",
    "        self.act_01 = nn.ReLU()\n",
    "        self.linear_02 = nn.Linear(in_features=200, out_features=100)\n",
    "        self.act_02 = nn.ReLU()\n",
    "        self.linear_03 = nn.Linear(in_features=100, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_01(x)\n",
    "        x = self.act_01(x)\n",
    "        x = self.linear_02(x)\n",
    "        x = self.act_02(x)\n",
    "        output = self.linear_03(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9591c98c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:22.386233Z",
     "iopub.status.busy": "2025-08-30T17:33:22.385964Z",
     "iopub.status.idle": "2025-08-30T17:33:22.392623Z",
     "shell.execute_reply": "2025-08-30T17:33:22.391781Z"
    },
    "papermill": {
     "duration": 0.019792,
     "end_time": "2025-08-30T17:33:22.393752",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.373960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLinearModel_01(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_01): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (act_01): ReLU()\n",
      "  (linear_02): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (act_02): ReLU()\n",
      "  (linear_03): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 28\n",
    "NUM_CLASSES = 10 \n",
    "\n",
    "model_01 = SimpleLinearModel_01(input_size=INPUT_SIZE, num_classes=NUM_CLASSES)\n",
    "print(model_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80bad5c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:22.418443Z",
     "iopub.status.busy": "2025-08-30T17:33:22.418177Z",
     "iopub.status.idle": "2025-08-30T17:33:22.443313Z",
     "shell.execute_reply": "2025-08-30T17:33:22.442530Z"
    },
    "papermill": {
     "duration": 0.038913,
     "end_time": "2025-08-30T17:33:22.444503",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.405590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "#임의의 tensor를 입력\n",
    "input_tensor = torch.randn(4, 1, 28, 28)\n",
    "output = model_01(input_tensor)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dc77ad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:22.468739Z",
     "iopub.status.busy": "2025-08-30T17:33:22.468488Z",
     "iopub.status.idle": "2025-08-30T17:33:22.608036Z",
     "shell.execute_reply": "2025-08-30T17:33:22.607145Z"
    },
    "papermill": {
     "duration": 0.152706,
     "end_time": "2025-08-30T17:33:22.609241",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.456535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 10])\n",
      "tensor([ 0.0507,  0.0429, -0.0194,  0.0462,  0.0921, -0.0505, -0.0254, -0.0186,\n",
      "         0.0820, -0.0631], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_data, batch_size = BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "\n",
    "print(images.shape)\n",
    "output = model_01(images)\n",
    "print(output.shape)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daaaff1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:22.634019Z",
     "iopub.status.busy": "2025-08-30T17:33:22.633387Z",
     "iopub.status.idle": "2025-08-30T17:33:22.976699Z",
     "shell.execute_reply": "2025-08-30T17:33:22.975935Z"
    },
    "papermill": {
     "duration": 0.357108,
     "end_time": "2025-08-30T17:33:22.978045",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.620937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name):depth-idx)             Input Shape               Output Shape              Param #\n",
       "========================================================================================================================\n",
       "SimpleLinearModel_01 (SimpleLinearModel_01)   [1, 1, 28, 28]            [1, 10]                   --\n",
       "├─Flatten (flatten): 1-1                      [1, 1, 28, 28]            [1, 784]                  --\n",
       "├─Linear (linear_01): 1-2                     [1, 784]                  [1, 200]                  157,000\n",
       "├─ReLU (act_01): 1-3                          [1, 200]                  [1, 200]                  --\n",
       "├─Linear (linear_02): 1-4                     [1, 200]                  [1, 100]                  20,100\n",
       "├─ReLU (act_02): 1-5                          [1, 100]                  [1, 100]                  --\n",
       "├─Linear (linear_03): 1-6                     [1, 100]                  [1, 10]                   1,010\n",
       "========================================================================================================================\n",
       "Total params: 178,110\n",
       "Trainable params: 178,110\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.18\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.71\n",
       "Estimated Total Size (MB): 0.72\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model_01, input_size=(1,1,28,28),\n",
    "        col_names=['input_size', 'output_size', 'num_params'],\n",
    "        row_settings=['var_names', 'depth'],\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ea86d",
   "metadata": {
    "papermill": {
     "duration": 0.011688,
     "end_time": "2025-08-30T17:33:23.001997",
     "exception": false,
     "start_time": "2025-08-30T17:33:22.990309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating a Model Using Linear Layers Only and Applying Activation with `F.relu()` Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96bb8fc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.026362Z",
     "iopub.status.busy": "2025-08-30T17:33:23.025789Z",
     "iopub.status.idle": "2025-08-30T17:33:23.031393Z",
     "shell.execute_reply": "2025-08-30T17:33:23.030658Z"
    },
    "papermill": {
     "duration": 0.019108,
     "end_time": "2025-08-30T17:33:23.032566",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.013458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleLinearModel_02(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=10):\n",
    "        super().__init__()\n",
    "        # Use nn.Linear layers only. Linear layers internally have learnable parameters like weight and bias.\n",
    "        # This approach makes the model more flexible and easier to construct.\n",
    "        self.linear_01 = nn.Linear(input_size * input_size, 200)\n",
    "        self.linear_02 = nn.Linear(200, 100)\n",
    "        self.linear_03 = nn.Linear(100, num_classes)\n",
    "\n",
    "    # Forward pass: input tensor → processed through layers → output tensor returned\n",
    "    def forward(self, x):\n",
    "        # Unlike nn.Flatten(), torch.flatten() defaults start_dim=0. Set start_dim=1 to preserve batch dimension.\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = F.relu(self.linear_01(x))\n",
    "        x = F.relu(self.linear_02(x))\n",
    "        output = self.linear_03(x)\n",
    "\n",
    "        # Alternatively, it could be written in a single line, but it's less readable:\n",
    "        # x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        # output = self.linear_03(F.relu(self.linear_02(F.relu(self.linear_01(x)))))\n",
    "\n",
    "        # Return the final tensor after passing through all layers\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3c8d167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.057126Z",
     "iopub.status.busy": "2025-08-30T17:33:23.056429Z",
     "iopub.status.idle": "2025-08-30T17:33:23.065111Z",
     "shell.execute_reply": "2025-08-30T17:33:23.064248Z"
    },
    "papermill": {
     "duration": 0.022043,
     "end_time": "2025-08-30T17:33:23.066242",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.044199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "print(images.shape)\n",
    "model_02 = SimpleLinearModel_02(input_size=INPUT_SIZE, num_classes=NUM_CLASSES)\n",
    "\n",
    "output = model_02(images)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d51f85d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.093444Z",
     "iopub.status.busy": "2025-08-30T17:33:23.092976Z",
     "iopub.status.idle": "2025-08-30T17:33:23.100637Z",
     "shell.execute_reply": "2025-08-30T17:33:23.099930Z"
    },
    "papermill": {
     "duration": 0.021132,
     "end_time": "2025-08-30T17:33:23.101775",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.080643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name):depth-idx)             Input Shape               Output Shape              Param #\n",
       "========================================================================================================================\n",
       "SimpleLinearModel_02 (SimpleLinearModel_02)   [1, 1, 28, 28]            [1, 10]                   --\n",
       "├─Linear (linear_01): 1-1                     [1, 784]                  [1, 200]                  157,000\n",
       "├─Linear (linear_02): 1-2                     [1, 200]                  [1, 100]                  20,100\n",
       "├─Linear (linear_03): 1-3                     [1, 100]                  [1, 10]                   1,010\n",
       "========================================================================================================================\n",
       "Total params: 178,110\n",
       "Trainable params: 178,110\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.18\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.71\n",
       "Estimated Total Size (MB): 0.72\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model_02, input_size=(1, 1, 28, 28), \n",
    "        col_names=['input_size', 'output_size', 'num_params'],\n",
    "        row_settings=['var_names', 'depth'],\n",
    "        #verbose=2\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3c2013",
   "metadata": {
    "papermill": {
     "duration": 0.011423,
     "end_time": "2025-08-30T17:33:23.125023",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.113600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating a Model Using `Sequential`\n",
    "\n",
    "* `nn.Sequential` allows you to modularly chain layers or modules passed as arguments into a single sequential block.\n",
    "* This approach eliminates the need to explicitly define the layer connections inside `forward()`, enabling efficient creation of repeated or ordered layer blocks.\n",
    "* Documentation: [PyTorch nn.Sequential](https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential)\n",
    "* For more complex layer arrangements, consider using `nn.ModuleList`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b06158c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.149071Z",
     "iopub.status.busy": "2025-08-30T17:33:23.148699Z",
     "iopub.status.idle": "2025-08-30T17:33:23.153746Z",
     "shell.execute_reply": "2025-08-30T17:33:23.153072Z"
    },
    "papermill": {
     "duration": 0.018297,
     "end_time": "2025-08-30T17:33:23.154788",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.136491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleLinearModel_03(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.linear_block_01 = nn.Sequential(nn.Linear(in_features=input_size*input_size, out_features=200),\n",
    "                                              nn.ReLU(), \n",
    "                                              nn.Linear(200, 100),\n",
    "                                              nn.ReLU(),\n",
    "                                              nn.Linear(100, num_classes)\n",
    "                                            )\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        output = self.linear_block_01(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04bf236f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.179092Z",
     "iopub.status.busy": "2025-08-30T17:33:23.178581Z",
     "iopub.status.idle": "2025-08-30T17:33:23.186146Z",
     "shell.execute_reply": "2025-08-30T17:33:23.185322Z"
    },
    "papermill": {
     "duration": 0.021071,
     "end_time": "2025-08-30T17:33:23.187387",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.166316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = 28\n",
    "NUM_CLASSES = 10 \n",
    "\n",
    "model_03 = SimpleLinearModel_03(input_size=INPUT_SIZE, num_classes=NUM_CLASSES)\n",
    "output = model_03(images)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5824ae6f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.211753Z",
     "iopub.status.busy": "2025-08-30T17:33:23.211511Z",
     "iopub.status.idle": "2025-08-30T17:33:23.219213Z",
     "shell.execute_reply": "2025-08-30T17:33:23.218593Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.021096,
     "end_time": "2025-08-30T17:33:23.220304",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.199208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name):depth-idx)             Input Shape               Output Shape              Param #\n",
       "========================================================================================================================\n",
       "SimpleLinearModel_03 (SimpleLinearModel_03)   [1, 1, 28, 28]            [1, 10]                   --\n",
       "├─Sequential (linear_block_01): 1-1           [1, 784]                  [1, 10]                   --\n",
       "│    └─Linear (0): 2-1                        [1, 784]                  [1, 200]                  157,000\n",
       "│    └─ReLU (1): 2-2                          [1, 200]                  [1, 200]                  --\n",
       "│    └─Linear (2): 2-3                        [1, 200]                  [1, 100]                  20,100\n",
       "│    └─ReLU (3): 2-4                          [1, 100]                  [1, 100]                  --\n",
       "│    └─Linear (4): 2-5                        [1, 100]                  [1, 10]                   1,010\n",
       "========================================================================================================================\n",
       "Total params: 178,110\n",
       "Trainable params: 178,110\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.18\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.71\n",
       "Estimated Total Size (MB): 0.72\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model_03, input_size=(1, 1, 28, 28), \n",
    "        col_names=['input_size', 'output_size', 'num_params'],\n",
    "        row_settings=['var_names', 'depth'],\n",
    "        #verbose=2\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492665d9",
   "metadata": {
    "papermill": {
     "duration": 0.011558,
     "end_time": "2025-08-30T17:33:23.243975",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.232417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Declare a function to create a SimpleLinearModel\n",
    "\n",
    "* Create and return the model using the create_simple_linear_model() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25bec9ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.268639Z",
     "iopub.status.busy": "2025-08-30T17:33:23.268379Z",
     "iopub.status.idle": "2025-08-30T17:33:23.272254Z",
     "shell.execute_reply": "2025-08-30T17:33:23.271529Z"
    },
    "papermill": {
     "duration": 0.017686,
     "end_time": "2025-08-30T17:33:23.273415",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.255729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "def create_simple_linear_model(input_size, num_classes=10):\n",
    "    model = SimpleLinearModel_02(input_size=input_size, num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fda6d863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.298371Z",
     "iopub.status.busy": "2025-08-30T17:33:23.298129Z",
     "iopub.status.idle": "2025-08-30T17:33:23.505704Z",
     "shell.execute_reply": "2025-08-30T17:33:23.504658Z"
    },
    "papermill": {
     "duration": 0.221414,
     "end_time": "2025-08-30T17:33:23.506905",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.285491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "tensor([1, 7, 4, 4, 3, 2, 1, 6, 4, 7, 2, 4, 4, 1, 1, 2, 0, 7, 1, 7, 4, 4, 6, 6,\n",
      "        0, 4, 2, 2, 8, 5, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='data',train= True, download=True, transform=ToTensor())\n",
    "val_data = datasets.FashionMNIST(root='data',train= False, download=True, transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4 )\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55b0da",
   "metadata": {
    "papermill": {
     "duration": 0.01176,
     "end_time": "2025-08-30T17:33:23.531181",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.519421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loss Function (Class)\n",
    "\n",
    "* For prediction models in multiclass classification, the loss function used is **Cross Entropy Loss**. PyTorch provides this through the `CrossEntropyLoss` class.\n",
    "* `CrossEntropyLoss` takes as input **logit predictions without softmax applied** and integer-type labels (class indices). You must **not** provide one-hot encoded labels.\n",
    "* Since the class internally applies softmax to the input logits, the model outputs must be raw logits without softmax applied.\n",
    "* For labels (targets), you should input the class index values (from 0 to C). If needed, the class internally applies one-hot encoding, so you must not use one-hot encoded labels as input.\n",
    "* Therefore, the input arguments are: (1) model outputs without softmax applied, and (2) target labels without one-hot encoding.\n",
    "* The `CrossEntropyLoss` class is essentially a combination of **LogSoftmax** and **NLLLoss**. `LogSoftmax` improves numerical stability when computing cross entropy by avoiding instability that can occur when applying softmax followed by log separately.\n",
    "* The output of `CrossEntropyLoss` is a tensor containing the computed loss value. Calling the `backward()` method on this loss tensor performs backpropagation and computes the gradients. The gradients are stored in the `grad` attribute of the model parameters, but the parameters themselves are **not updated automatically**. The actual update is carried out by the **optimizer**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "367f45a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.556803Z",
     "iopub.status.busy": "2025-08-30T17:33:23.555996Z",
     "iopub.status.idle": "2025-08-30T17:33:23.567578Z",
     "shell.execute_reply": "2025-08-30T17:33:23.566527Z"
    },
    "papermill": {
     "duration": 0.025778,
     "end_time": "2025-08-30T17:33:23.568743",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.542965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0397, -0.0897,  0.0843,  0.1433,  0.0938, -0.0330, -0.0900, -0.0608,\n",
      "         -0.0505, -0.0291],\n",
      "        [-0.0486, -0.0218,  0.0644,  0.1265,  0.0538, -0.0402, -0.1010, -0.0595,\n",
      "         -0.0431,  0.0023],\n",
      "        [ 0.0108, -0.0274,  0.0312,  0.2554,  0.0165, -0.0268, -0.0698,  0.0245,\n",
      "         -0.0078,  0.0273],\n",
      "        [ 0.0196,  0.0019,  0.0266,  0.2268,  0.0019, -0.0140, -0.0759,  0.0232,\n",
      "         -0.0205,  0.0575],\n",
      "        [-0.0503, -0.0420,  0.0587,  0.2080,  0.0405, -0.0207, -0.0865, -0.0286,\n",
      "         -0.0189, -0.0113],\n",
      "        [ 0.0028, -0.0469,  0.0500,  0.1534,  0.0384, -0.0246, -0.1096, -0.0490,\n",
      "         -0.0502,  0.0123],\n",
      "        [-0.0612, -0.0640,  0.1078,  0.0948,  0.0634, -0.0198, -0.0941, -0.0934,\n",
      "         -0.0681, -0.0066],\n",
      "        [-0.0199, -0.0887,  0.0808,  0.0810,  0.0746, -0.0380, -0.0896, -0.0570,\n",
      "         -0.0502, -0.0157],\n",
      "        [-0.0306, -0.0847,  0.0866,  0.1063,  0.0659, -0.0309, -0.0814, -0.0668,\n",
      "         -0.0499, -0.0197],\n",
      "        [-0.0146, -0.0291,  0.0578,  0.1506,  0.0269, -0.0356, -0.1083, -0.0412,\n",
      "         -0.0301,  0.0385],\n",
      "        [ 0.0383, -0.0207,  0.0443,  0.2138,  0.0345, -0.0053, -0.0947,  0.0118,\n",
      "          0.0164,  0.0550],\n",
      "        [-0.0010, -0.0542,  0.0307,  0.1752, -0.0201, -0.0307, -0.0897, -0.0340,\n",
      "         -0.0419,  0.0329],\n",
      "        [ 0.0413, -0.0158,  0.0072,  0.2045,  0.0016, -0.0177, -0.0920, -0.0134,\n",
      "         -0.0020,  0.0377],\n",
      "        [-0.0555, -0.0836,  0.1048,  0.1065,  0.0593, -0.0376, -0.0884, -0.0748,\n",
      "         -0.0440, -0.0225],\n",
      "        [-0.0477, -0.0808,  0.0923,  0.1406,  0.0786, -0.0264, -0.0889, -0.0621,\n",
      "         -0.0822, -0.0203],\n",
      "        [ 0.0084, -0.0692,  0.0470,  0.1960,  0.0488, -0.0185, -0.1019, -0.0047,\n",
      "         -0.0218,  0.0040],\n",
      "        [ 0.0010, -0.0564,  0.0678,  0.2059,  0.0011, -0.0366, -0.0563, -0.0031,\n",
      "         -0.0070,  0.0340],\n",
      "        [-0.0273, -0.0277,  0.0568,  0.1224,  0.0386, -0.0266, -0.1254, -0.0583,\n",
      "         -0.0284, -0.0066],\n",
      "        [-0.0464, -0.0762,  0.1006,  0.1388,  0.0718, -0.0294, -0.0829, -0.0454,\n",
      "         -0.0446, -0.0068],\n",
      "        [-0.0310, -0.0483,  0.0642,  0.1273,  0.0258, -0.0126, -0.0892, -0.0441,\n",
      "         -0.0903,  0.0399],\n",
      "        [ 0.0283, -0.0377,  0.0385,  0.2109, -0.0054, -0.0140, -0.0737, -0.0181,\n",
      "          0.0083,  0.0385],\n",
      "        [ 0.0133,  0.0154,  0.0197,  0.2203,  0.0009, -0.0231, -0.0703,  0.0352,\n",
      "         -0.0429,  0.0573],\n",
      "        [ 0.0036, -0.0355,  0.0617,  0.1802,  0.0152, -0.0250, -0.0946, -0.0362,\n",
      "         -0.0257,  0.0179],\n",
      "        [-0.0308, -0.0481,  0.0580,  0.1762,  0.0188, -0.0151, -0.1031, -0.0568,\n",
      "          0.0048, -0.0045],\n",
      "        [-0.0297, -0.0573,  0.0611,  0.1588,  0.0262, -0.0652, -0.0837, -0.0127,\n",
      "          0.0126,  0.0087],\n",
      "        [ 0.0597, -0.0062, -0.0056,  0.2318, -0.0128,  0.0047, -0.1156, -0.0068,\n",
      "         -0.0073,  0.0612],\n",
      "        [ 0.0043, -0.0626,  0.0512,  0.1560,  0.0379, -0.0292, -0.0798, -0.0308,\n",
      "         -0.0199,  0.0136],\n",
      "        [ 0.0005, -0.0519,  0.0432,  0.1556,  0.0050, -0.0454, -0.0926, -0.0944,\n",
      "          0.0219,  0.0195],\n",
      "        [-0.0177, -0.0372,  0.0471,  0.1973, -0.0337, -0.0379, -0.1145, -0.0127,\n",
      "         -0.0432,  0.0185],\n",
      "        [-0.0156, -0.1040,  0.0837,  0.0881,  0.0560, -0.0347, -0.0656, -0.0834,\n",
      "         -0.0560, -0.0220],\n",
      "        [ 0.0149, -0.0258,  0.0309,  0.1711,  0.0211, -0.0239, -0.1011, -0.0275,\n",
      "         -0.0332,  0.0183],\n",
      "        [ 0.0291, -0.0366,  0.0102,  0.2336, -0.0196, -0.0239, -0.1063, -0.0259,\n",
      "          0.0303,  0.0214]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "model = create_simple_linear_model(input_size=28, num_classes=10)\n",
    "# output is logit\n",
    "output = model(images)\n",
    "print(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54c1a4e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.596538Z",
     "iopub.status.busy": "2025-08-30T17:33:23.596269Z",
     "iopub.status.idle": "2025-08-30T17:33:23.609799Z",
     "shell.execute_reply": "2025-08-30T17:33:23.608959Z"
    },
    "papermill": {
     "duration": 0.027563,
     "end_time": "2025-08-30T17:33:23.611182",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.583619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2752, grad_fn=<NllLossBackward0>) 2.275200128555298\n"
     ]
    }
   ],
   "source": [
    "model = create_simple_linear_model(input_size=28, num_classes=10)\n",
    "# Model output (logit values)\n",
    "output = model(images)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "# Create CrossEntropyLoss object\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Pass model outputs as the first argument and labels as the second argument\n",
    "loss = loss_fn(output, labels)\n",
    "print(loss, loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bce7ce76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.639580Z",
     "iopub.status.busy": "2025-08-30T17:33:23.639086Z",
     "iopub.status.idle": "2025-08-30T17:33:23.643542Z",
     "shell.execute_reply": "2025-08-30T17:33:23.642932Z"
    },
    "papermill": {
     "duration": 0.018396,
     "end_time": "2025-08-30T17:33:23.644528",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.626132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward():\n",
      "linear_01.weight.grad: None\n",
      "linear_01.bias.grad: None\n",
      "linear_02.weight.grad: None\n",
      "linear_02.bias.grad: None\n",
      "linear_03.weight.grad: None\n",
      "linear_03.bias.grad: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Before backward():\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}.grad: {param.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426e43f",
   "metadata": {
    "papermill": {
     "duration": 0.011837,
     "end_time": "2025-08-30T17:33:23.668529",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.656692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "before calling .backward(), only the forward pass is executed — no gradients are computed yet.\n",
    "\n",
    "That’s why param.grad is still None right after computing the loss.\n",
    "\n",
    "PyTorch does this to save memory and computation until you explicitly ask for gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97b2f179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.694607Z",
     "iopub.status.busy": "2025-08-30T17:33:23.693923Z",
     "iopub.status.idle": "2025-08-30T17:33:23.708754Z",
     "shell.execute_reply": "2025-08-30T17:33:23.708202Z"
    },
    "papermill": {
     "duration": 0.029005,
     "end_time": "2025-08-30T17:33:23.709975",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.680970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08a4607e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.735949Z",
     "iopub.status.busy": "2025-08-30T17:33:23.735673Z",
     "iopub.status.idle": "2025-08-30T17:33:23.740440Z",
     "shell.execute_reply": "2025-08-30T17:33:23.739803Z"
    },
    "papermill": {
     "duration": 0.019075,
     "end_time": "2025-08-30T17:33:23.741451",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.722376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2752, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b84be8d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.767184Z",
     "iopub.status.busy": "2025-08-30T17:33:23.766564Z",
     "iopub.status.idle": "2025-08-30T17:33:23.781770Z",
     "shell.execute_reply": "2025-08-30T17:33:23.781217Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.029676,
     "end_time": "2025-08-30T17:33:23.783318",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.753642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After backward():\n",
      "linear_01.weight.grad: tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.6187e-04,\n",
      "          1.8093e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.4004e-04,\n",
      "         -1.7412e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.0344e-04,\n",
      "          1.2162e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.4172e-04,\n",
      "          1.5355e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.3644e-05,\n",
      "          1.2023e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "linear_01.bias.grad: tensor([ 2.4805e-04,  1.0653e-03,  5.3265e-03,  9.6255e-04, -5.5003e-03,\n",
      "        -4.2995e-03,  7.4225e-04,  7.4289e-04,  9.2936e-05,  1.9171e-03,\n",
      "         8.7435e-04,  1.3535e-03, -4.9459e-03, -3.1119e-03, -2.0364e-03,\n",
      "        -8.6476e-04,  4.6851e-03, -6.2901e-04,  2.7562e-03,  5.0241e-03,\n",
      "         1.7802e-03, -1.5972e-03, -2.9427e-03, -1.0593e-03, -1.3590e-03,\n",
      "        -7.8258e-03, -4.3191e-03, -1.8579e-03, -5.5259e-03,  1.5009e-03,\n",
      "         2.0324e-03, -3.4565e-04,  2.5802e-03,  5.6651e-04, -1.7647e-03,\n",
      "         4.9995e-04,  1.7436e-04, -1.7115e-04,  1.7744e-03, -5.6357e-04,\n",
      "         2.9788e-03,  8.7631e-03,  1.0915e-03, -2.6929e-03,  9.1608e-05,\n",
      "        -1.2774e-03,  5.9426e-03,  1.4983e-03,  7.8218e-04, -8.2267e-03,\n",
      "         1.4496e-03,  9.4051e-04,  1.2869e-03, -1.0056e-03,  1.3412e-03,\n",
      "        -1.1957e-03,  7.2587e-03,  5.3095e-04, -7.9337e-04, -3.0731e-04,\n",
      "        -4.9577e-04,  8.1354e-06, -9.6130e-04, -9.5170e-04,  2.4122e-04,\n",
      "        -6.8953e-03,  0.0000e+00, -3.5698e-03,  3.8382e-03,  2.0588e-03,\n",
      "         7.5371e-04, -2.7016e-03, -5.0169e-04,  5.4285e-03,  2.5846e-03,\n",
      "        -2.3845e-04, -2.9994e-03,  2.1355e-03, -2.4857e-03,  2.2646e-03,\n",
      "         1.8621e-03,  7.9104e-04,  1.1566e-03,  7.5046e-04, -2.0869e-03,\n",
      "        -2.8594e-03,  5.4374e-04,  1.2688e-03,  1.3113e-03,  1.2958e-03,\n",
      "         1.0083e-03,  4.1578e-04,  1.5939e-04,  5.4622e-03, -2.3997e-03,\n",
      "        -1.1101e-03, -7.4280e-03, -2.4048e-03, -8.2058e-04, -3.3485e-04,\n",
      "        -1.2207e-03, -2.3960e-03, -1.1775e-03,  2.5061e-03,  1.9421e-03,\n",
      "        -3.2907e-03,  6.3344e-04, -3.3680e-03, -8.3697e-04,  2.3239e-03,\n",
      "        -2.7382e-04,  9.1144e-04, -2.8020e-03, -1.8430e-03,  0.0000e+00,\n",
      "         2.8766e-04, -7.1964e-04, -1.5396e-03,  6.2656e-04,  4.4696e-03,\n",
      "         3.6761e-04, -4.7780e-03, -1.7197e-03, -1.6716e-03, -4.5865e-03,\n",
      "         5.0498e-03,  4.8462e-04,  1.4796e-03,  2.1977e-04,  2.3746e-03,\n",
      "         6.2759e-03, -6.2458e-04,  0.0000e+00, -4.5649e-03,  9.2702e-04,\n",
      "        -4.8423e-03,  6.8799e-04,  2.7248e-03,  1.1286e-03, -1.7077e-04,\n",
      "         1.3071e-03, -2.3780e-04,  6.9122e-04,  4.4266e-04,  4.4962e-04,\n",
      "        -1.5973e-03,  1.5166e-04,  0.0000e+00, -3.2152e-04,  3.4896e-04,\n",
      "        -2.3088e-04,  0.0000e+00,  2.7318e-03,  5.3099e-03,  3.8198e-03,\n",
      "         1.2580e-03,  1.7618e-04, -1.8657e-04,  1.2423e-03,  3.0276e-03,\n",
      "        -4.4187e-03, -2.8459e-03, -8.3649e-04, -7.6218e-04,  1.3194e-03,\n",
      "        -3.2622e-03, -3.5827e-03,  2.4434e-05, -2.3419e-03, -6.6651e-03,\n",
      "        -2.3829e-03,  1.8496e-04,  1.3817e-03, -2.7813e-04,  1.3927e-04,\n",
      "         3.6134e-03, -8.5820e-04, -1.7352e-04,  7.1814e-06,  7.4171e-04,\n",
      "        -1.2579e-03,  2.0738e-03, -2.6369e-03, -4.6089e-04, -2.1663e-03,\n",
      "        -3.6999e-04, -1.3429e-04, -4.7514e-04, -1.1579e-05,  0.0000e+00,\n",
      "         3.3667e-04,  0.0000e+00, -1.2709e-03, -1.2641e-04,  2.3410e-03,\n",
      "         2.2620e-03, -2.2848e-03,  7.7574e-05, -8.5938e-03,  4.2495e-04])\n",
      "linear_02.weight.grad: tensor([[-1.6484e-06, -3.6676e-04, -4.3283e-04,  ..., -9.9565e-05,\n",
      "         -1.7747e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.3101e-05, -6.2864e-04, -9.4928e-04,  ..., -6.2196e-04,\n",
      "         -2.2313e-05,  0.0000e+00],\n",
      "        ...,\n",
      "        [-9.3186e-04, -7.4238e-03, -9.0564e-03,  ..., -5.4499e-03,\n",
      "         -3.7255e-03,  3.2534e-04],\n",
      "        [ 4.7844e-04, -1.3270e-03, -3.3662e-03,  ..., -2.8048e-03,\n",
      "          2.1234e-03, -2.4774e-04],\n",
      "        [ 1.0192e-04,  2.8115e-03,  3.4552e-03,  ...,  2.2617e-03,\n",
      "          4.2005e-04, -2.8894e-05]])\n",
      "linear_02.bias.grad: tensor([-0.0013,  0.0000, -0.0011,  0.0014,  0.0056, -0.0030,  0.0226, -0.0135,\n",
      "         0.0011,  0.0000,  0.0004, -0.0119,  0.0000, -0.0065,  0.0000, -0.0002,\n",
      "        -0.0231, -0.0016,  0.0022,  0.0014, -0.0032,  0.0000, -0.0163,  0.0280,\n",
      "        -0.0202,  0.0101, -0.0109,  0.0145, -0.0016,  0.0030,  0.0005, -0.0148,\n",
      "         0.0033, -0.0124, -0.0058, -0.0101,  0.0048, -0.0016,  0.0000, -0.0101,\n",
      "        -0.0235,  0.0019, -0.0060,  0.0092, -0.0230, -0.0027,  0.0025,  0.0048,\n",
      "        -0.0028, -0.0069, -0.0033, -0.0216,  0.0018,  0.0012,  0.0029, -0.0098,\n",
      "        -0.0006, -0.0066,  0.0118,  0.0168, -0.0074, -0.0021,  0.0000,  0.0003,\n",
      "        -0.0031,  0.0074,  0.0037, -0.0054, -0.0234,  0.0016,  0.0016, -0.0049,\n",
      "        -0.0046,  0.0091,  0.0007,  0.0054,  0.0085, -0.0035,  0.0163,  0.0000,\n",
      "        -0.0003, -0.0137,  0.0075, -0.0027,  0.0167,  0.0020,  0.0017, -0.0024,\n",
      "        -0.0002,  0.0002,  0.0007,  0.0015,  0.0069, -0.0068,  0.0004,  0.0005,\n",
      "         0.0000, -0.0222, -0.0004,  0.0049])\n",
      "linear_03.weight.grad: tensor([[ 9.4312e-05,  0.0000e+00, -3.1357e-04,  1.8546e-03,  1.8896e-04,\n",
      "          3.2926e-04,  5.0943e-03,  2.1186e-04,  6.5595e-03,  0.0000e+00,\n",
      "          1.5689e-04,  7.8073e-04,  0.0000e+00,  8.8015e-04,  0.0000e+00,\n",
      "          5.2674e-03,  1.1146e-03,  1.8873e-05,  5.3003e-04,  4.6533e-03,\n",
      "          3.3596e-04,  0.0000e+00,  1.3729e-03,  6.1998e-03,  1.3805e-03,\n",
      "          1.9901e-03,  1.9471e-04,  1.8813e-03,  1.2224e-03,  4.9083e-03,\n",
      "          1.4728e-03,  4.4414e-03,  2.0423e-04,  8.2689e-04,  4.3892e-03,\n",
      "          4.2909e-04,  1.7296e-03,  3.2535e-03,  0.0000e+00,  4.9398e-04,\n",
      "          6.2694e-03, -3.2178e-04,  2.4477e-03,  7.1646e-04,  8.2995e-04,\n",
      "          1.1281e-03,  2.7856e-04,  3.1150e-05,  3.5635e-04,  1.3559e-03,\n",
      "         -4.5100e-05,  4.3046e-03,  1.8921e-04,  2.4221e-06,  2.7334e-03,\n",
      "          4.5367e-04, -1.1230e-04,  3.6705e-03,  8.3117e-03,  6.7962e-03,\n",
      "          2.3463e-03,  1.1670e-04,  0.0000e+00,  5.0888e-04, -1.9012e-04,\n",
      "          1.2566e-03,  1.3857e-03,  2.0529e-03,  5.4221e-04,  2.3009e-04,\n",
      "          1.6003e-04,  2.7931e-03,  4.6676e-04,  3.4026e-03,  1.2938e-04,\n",
      "          8.9065e-04,  5.7192e-04,  6.9889e-06, -2.9566e-04,  0.0000e+00,\n",
      "          3.2474e-03,  2.7828e-03,  2.4024e-03,  1.5476e-03,  2.2585e-03,\n",
      "          9.5517e-04,  5.2867e-04,  3.3694e-03,  5.3887e-04,  9.3716e-05,\n",
      "          4.1313e-05,  3.3223e-05,  7.0977e-03,  8.2010e-03, -2.6435e-04,\n",
      "          5.5860e-04,  0.0000e+00,  8.0878e-03,  6.7466e-04,  3.2477e-03],\n",
      "        [-7.7506e-04,  0.0000e+00,  1.3577e-04, -6.8861e-03, -1.5197e-03,\n",
      "         -9.8639e-05, -1.1785e-02,  6.6916e-03, -1.9980e-03,  0.0000e+00,\n",
      "         -1.3604e-03, -4.8234e-03,  0.0000e+00, -1.6428e-03,  0.0000e+00,\n",
      "         -4.6413e-03, -3.2197e-03,  1.9416e-05,  2.0803e-03,  6.6450e-03,\n",
      "         -5.3365e-04,  0.0000e+00,  1.0030e-05,  3.3940e-03, -1.7215e-03,\n",
      "         -7.7212e-03, -5.8915e-03, -6.4064e-03,  1.5935e-04,  8.0808e-03,\n",
      "         -6.8074e-03,  5.0917e-03,  2.0854e-04, -1.5462e-03, -7.5192e-03,\n",
      "          2.4151e-04,  9.6432e-04, -1.0611e-03,  0.0000e+00, -4.0174e-03,\n",
      "          6.9217e-03,  8.9578e-05, -1.1588e-03, -1.3501e-05, -7.6294e-03,\n",
      "         -2.0968e-03, -1.0929e-03, -5.9365e-04,  3.5207e-04,  1.4284e-03,\n",
      "          1.0945e-03,  5.8846e-03,  1.8930e-04,  2.4918e-06,  6.8639e-04,\n",
      "          2.9277e-03,  3.7944e-04,  6.3702e-03,  3.8717e-03, -6.5520e-03,\n",
      "         -1.0078e-02,  1.1734e-04,  0.0000e+00,  4.2739e-03,  3.2403e-03,\n",
      "          1.2676e-03, -4.4381e-03, -7.3476e-03, -4.3573e-03, -1.9950e-03,\n",
      "         -2.4876e-04,  9.1354e-04, -3.7906e-04,  4.6262e-03,  1.3002e-04,\n",
      "          4.3917e-03,  3.9420e-04,  7.1097e-06,  1.2674e-03,  0.0000e+00,\n",
      "         -7.8153e-04, -1.0967e-02,  5.7958e-03, -1.7212e-03,  2.2482e-03,\n",
      "          1.3089e-03,  4.0880e-04,  3.5995e-03,  4.0421e-04,  8.8712e-05,\n",
      "         -3.5411e-04,  3.2769e-05,  2.4576e-03,  1.8716e-04,  5.8552e-05,\n",
      "         -1.8003e-03,  0.0000e+00, -1.1090e-02, -1.0914e-03,  6.7191e-03],\n",
      "        [ 9.1404e-05,  0.0000e+00,  1.3514e-04, -1.0423e-03,  7.3962e-05,\n",
      "          1.3255e-03, -1.8851e-03, -6.7413e-03, -2.6067e-03,  0.0000e+00,\n",
      "          1.5138e-04,  4.3530e-04,  0.0000e+00,  2.0911e-04,  0.0000e+00,\n",
      "         -1.0539e-02, -1.1590e-02,  1.7964e-05, -3.9798e-04, -6.5759e-03,\n",
      "          3.2099e-04,  0.0000e+00, -3.0886e-03, -1.4973e-02, -4.0530e-03,\n",
      "         -3.4916e-03, -1.1332e-03, -3.9991e-03, -3.1992e-03, -9.3488e-03,\n",
      "         -2.2351e-04, -2.7510e-03,  1.9496e-04,  1.1796e-03, -1.3006e-02,\n",
      "         -2.2085e-03, -1.8728e-03, -4.7729e-03,  0.0000e+00,  4.7631e-04,\n",
      "         -1.3458e-02, -3.8636e-04, -1.3289e-02,  3.1049e-05, -1.7716e-03,\n",
      "          1.0663e-03,  1.1279e-03, -6.4414e-04,  3.3743e-04,  2.3659e-03,\n",
      "         -1.6910e-03, -6.0906e-03,  1.8707e-04,  2.3054e-06,  2.5274e-04,\n",
      "         -5.5510e-03,  3.7361e-04, -8.9513e-03, -1.5732e-02, -9.3122e-03,\n",
      "         -2.0095e-03, -8.2304e-04,  0.0000e+00, -6.9667e-03, -3.5877e-03,\n",
      "          1.2271e-03,  8.1820e-04, -1.2656e-03, -4.4792e-03,  2.2080e-04,\n",
      "          1.5259e-04, -1.2329e-02,  4.4715e-04, -3.7213e-03, -9.5921e-04,\n",
      "         -6.6801e-03, -1.0549e-03,  6.7659e-06, -1.3400e-03,  0.0000e+00,\n",
      "         -6.5468e-03, -2.1510e-03, -6.9725e-03,  1.9281e-04,  9.9695e-04,\n",
      "         -2.4287e-03,  1.6266e-04, -1.5532e-03,  4.9325e-04, -7.8340e-04,\n",
      "          3.9034e-05,  3.3465e-05, -9.3600e-03, -7.5903e-03,  5.6665e-05,\n",
      "          5.4476e-04,  0.0000e+00, -1.3427e-02,  2.1521e-03, -8.8179e-03],\n",
      "        [ 8.5834e-05,  0.0000e+00,  1.2631e-04,  1.7805e-03,  1.6922e-04,\n",
      "          3.1085e-03,  3.1973e-03,  4.4025e-03,  6.9088e-03,  0.0000e+00,\n",
      "          1.4252e-04,  3.5462e-05,  0.0000e+00, -7.3781e-04,  0.0000e+00,\n",
      "          1.1237e-02,  2.8135e-03,  1.6688e-05,  2.2358e-03,  1.0236e-02,\n",
      "          2.9664e-04,  0.0000e+00,  6.0745e-03,  1.1926e-02,  2.5420e-03,\n",
      "          5.9037e-04,  4.0902e-03,  3.7936e-03,  1.1511e-03,  9.3692e-03,\n",
      "          1.3201e-03,  5.1130e-03,  1.7945e-04, -5.6056e-04,  6.5712e-03,\n",
      "          3.7948e-04,  1.5043e-03,  1.9741e-03,  0.0000e+00,  4.4708e-04,\n",
      "          1.2971e-02,  8.2198e-05,  7.9536e-03, -9.7332e-04,  2.9131e-03,\n",
      "          7.4029e-04,  1.0552e-03,  3.1362e-04,  3.2246e-04,  6.0652e-03,\n",
      "          9.8651e-04,  9.5073e-03, -1.1208e-04,  2.1417e-06,  2.7852e-03,\n",
      "          2.2047e-03,  3.2900e-04,  7.6102e-03,  1.7044e-02,  8.6742e-03,\n",
      "          3.9908e-03,  1.0643e-04,  0.0000e+00,  3.9331e-03,  3.4987e-04,\n",
      "          1.1100e-03,  1.5447e-03,  2.2658e-03,  2.4561e-03,  2.0758e-04,\n",
      "          1.4223e-04,  5.8194e-03,  4.1359e-04,  4.2695e-03,  1.1837e-04,\n",
      "          3.0414e-03,  5.1127e-04,  6.3193e-06,  1.4402e-03,  0.0000e+00,\n",
      "          4.0804e-03,  4.8475e-03,  8.4636e-03,  2.3887e-03,  2.0160e-03,\n",
      "          1.6539e-03, -4.9437e-04,  3.0811e-03,  4.7564e-04,  8.1497e-05,\n",
      "          3.6727e-05,  2.8536e-05,  9.0778e-03,  1.0373e-02,  5.0956e-05,\n",
      "          4.8949e-04,  0.0000e+00,  1.2702e-02,  1.7775e-03,  4.7591e-03],\n",
      "        [ 9.5431e-05,  0.0000e+00, -7.6084e-04,  2.1478e-03,  1.8851e-04,\n",
      "         -1.0407e-03, -1.3835e-02, -3.1184e-02, -1.0200e-02,  0.0000e+00,\n",
      "          1.5748e-04,  2.1730e-04,  0.0000e+00, -4.6631e-03,  0.0000e+00,\n",
      "         -4.0339e-02, -1.3881e-02,  1.9163e-05, -7.0790e-03, -4.2526e-02,\n",
      "         -8.3635e-04,  0.0000e+00, -2.5704e-02, -5.7782e-02, -1.1156e-02,\n",
      "         -1.1852e-02, -6.9294e-03, -2.4566e-02, -5.4156e-03, -3.8142e-02,\n",
      "         -2.2566e-04, -2.5847e-02, -5.5831e-04, -1.6082e-04, -2.9077e-02,\n",
      "         -5.1713e-04, -5.1609e-04, -1.1764e-02,  0.0000e+00,  2.3125e-04,\n",
      "         -5.4113e-02,  9.2970e-05, -3.4532e-02, -3.0149e-03, -3.1286e-03,\n",
      "         -3.8888e-03, -4.3567e-03,  4.5651e-04, -1.7464e-03, -2.1625e-02,\n",
      "         -1.0664e-03, -2.7381e-02,  1.8068e-04,  2.4593e-06,  2.3824e-04,\n",
      "         -7.7080e-03,  3.6993e-04, -2.8041e-02, -7.4199e-02, -3.7749e-02,\n",
      "         -3.8140e-04,  1.1690e-04,  0.0000e+00, -2.1334e-02, -9.3220e-03,\n",
      "          7.4237e-04,  1.3345e-03, -5.3259e-03, -1.8982e-03,  2.3214e-04,\n",
      "          1.6257e-04, -3.4211e-02, -7.7654e-04, -1.9158e-02,  1.2975e-04,\n",
      "         -1.7480e-02, -2.4484e-03,  6.5947e-06, -2.0839e-03,  0.0000e+00,\n",
      "         -1.0404e-02, -9.4783e-03, -3.9237e-02, -8.8069e-04, -4.4287e-03,\n",
      "         -2.0237e-03,  5.1842e-04, -2.4431e-02,  3.0776e-05,  8.8824e-05,\n",
      "          4.1130e-05,  3.1310e-05, -4.1800e-02, -2.9711e-02, -1.7917e-04,\n",
      "          1.5394e-04,  0.0000e+00, -4.9668e-02, -1.3366e-02, -2.7321e-02],\n",
      "        [ 8.9447e-05,  0.0000e+00,  1.3513e-04,  1.1827e-03,  1.8097e-04,\n",
      "          1.3280e-03,  5.6403e-03,  7.4110e-03,  7.2419e-03,  0.0000e+00,\n",
      "          1.4894e-04,  7.5299e-04,  0.0000e+00,  7.5884e-04,  0.0000e+00,\n",
      "          1.5010e-02,  8.4638e-03, -1.6371e-04,  2.3519e-03,  1.3517e-02,\n",
      "         -8.5615e-04,  0.0000e+00,  7.8519e-03,  1.9821e-02,  3.5012e-03,\n",
      "          4.5964e-03,  3.3518e-03,  7.2980e-03,  1.7113e-03,  1.0786e-02,\n",
      "         -1.0104e-04,  5.6776e-03, -1.0029e-03,  1.1515e-03,  1.2278e-02,\n",
      "          4.1417e-04,  1.7050e-05,  3.7320e-03,  0.0000e+00,  4.7080e-04,\n",
      "          1.7677e-02,  8.8617e-05,  1.0047e-02,  3.4585e-04,  3.5385e-03,\n",
      "          1.0693e-03, -3.6814e-05, -1.3429e-03,  3.2982e-04,  5.8335e-03,\n",
      "          1.0514e-03,  8.8338e-03,  1.7282e-04, -2.1010e-05,  2.7751e-03,\n",
      "          2.3405e-03, -7.9798e-04,  7.5404e-03,  2.5762e-02,  1.1711e-02,\n",
      "          1.7704e-03,  1.1350e-04,  0.0000e+00,  4.2472e-03,  3.2755e-03,\n",
      "          7.2889e-04,  3.4037e-04,  2.6837e-03,  2.2798e-03,  2.2124e-04,\n",
      "         -9.7553e-04,  1.1494e-02, -1.1088e-03,  4.5358e-03,  1.2572e-04,\n",
      "          4.2282e-03,  5.4999e-04,  6.1413e-06,  1.5200e-03,  0.0000e+00,\n",
      "          3.3188e-03,  8.0890e-03,  1.1830e-02,  1.8943e-03,  2.0942e-03,\n",
      "          1.1311e-03,  2.2291e-04,  5.2519e-03, -9.1418e-04,  8.8767e-05,\n",
      "          3.9817e-05,  2.9443e-05,  1.3775e-02,  1.4068e-02,  5.5754e-05,\n",
      "          5.2032e-04,  0.0000e+00,  1.5990e-02,  6.0339e-03,  6.4800e-03],\n",
      "        [ 9.6544e-05,  0.0000e+00,  1.4504e-04, -8.9749e-04,  1.8992e-04,\n",
      "         -4.0198e-04,  1.1246e-04, -3.8610e-03,  3.3713e-03,  0.0000e+00,\n",
      "          1.5976e-04,  4.0425e-04,  0.0000e+00,  1.3705e-03,  0.0000e+00,\n",
      "         -4.0476e-03, -4.3492e-03,  1.8677e-05,  6.3741e-04, -2.7495e-03,\n",
      "          3.3180e-04,  0.0000e+00, -2.9549e-03, -6.0845e-03, -1.5476e-03,\n",
      "          3.9034e-03, -4.9298e-03, -6.1929e-03,  7.7617e-04,  4.2348e-04,\n",
      "          1.4786e-03,  1.2757e-03,  2.0079e-04, -1.4463e-03, -8.1852e-04,\n",
      "          7.3318e-05, -6.2686e-06, -3.8572e-03,  0.0000e+00,  5.0208e-04,\n",
      "         -6.0321e-03,  9.3007e-05,  1.4913e-03,  1.1054e-03,  1.3254e-03,\n",
      "         -1.1733e-03,  1.4814e-04,  4.6967e-04,  2.0514e-04, -6.0030e-03,\n",
      "         -2.4799e-05, -3.9743e-03,  1.8192e-04,  2.3970e-06,  1.4968e-03,\n",
      "          9.5214e-04,  3.6830e-04, -3.4472e-03, -4.2797e-03,  2.1095e-03,\n",
      "          2.2817e-03,  1.1832e-04,  0.0000e+00,  3.7415e-03, -2.2785e-03,\n",
      "          4.6340e-04,  1.1323e-03,  9.2290e-05, -1.3005e-04,  2.3353e-04,\n",
      "          1.5910e-04, -9.5207e-04,  4.6023e-04,  2.6070e-03,  1.3140e-04,\n",
      "         -4.0333e-03,  5.4526e-05,  6.6308e-06,  1.6186e-03,  0.0000e+00,\n",
      "          1.1983e-03,  2.0712e-03, -4.8710e-03,  6.2390e-04, -5.6055e-04,\n",
      "         -1.3933e-03, -2.3244e-04,  2.0025e-03, -1.3976e-03,  9.2589e-05,\n",
      "          4.1112e-05,  3.1644e-05,  2.2279e-03, -3.0935e-03,  5.8247e-05,\n",
      "          5.4539e-04,  0.0000e+00, -7.4356e-03, -3.4315e-03,  1.0712e-03],\n",
      "        [ 4.7834e-05,  0.0000e+00,  1.4066e-04,  3.7635e-04,  1.8330e-04,\n",
      "         -6.0297e-03, -5.9017e-04,  7.9380e-03, -2.1435e-02,  0.0000e+00,\n",
      "          1.5418e-04,  7.6524e-04,  0.0000e+00,  1.3507e-03,  0.0000e+00,\n",
      "          1.6017e-04,  3.0561e-03,  1.8337e-05, -4.2677e-03, -3.2457e-03,\n",
      "          3.2640e-04,  0.0000e+00,  7.1533e-03,  1.0097e-02,  3.9085e-03,\n",
      "          4.7046e-03,  2.1823e-03,  8.9733e-03,  3.8716e-04, -1.1374e-03,\n",
      "          4.0111e-04, -3.7785e-03,  1.9899e-04, -1.6717e-03,  3.2904e-03,\n",
      "          4.1821e-04, -4.9758e-03,  4.4230e-03,  0.0000e+00,  4.8607e-04,\n",
      "         -2.8549e-03,  9.3999e-05,  7.9900e-03,  5.7989e-04, -4.5930e-03,\n",
      "          1.1095e-03,  7.3479e-04,  4.5521e-04, -8.0112e-04, -1.1342e-03,\n",
      "         -8.1413e-04, -5.2700e-03, -1.3311e-03,  2.3534e-06, -1.3022e-02,\n",
      "          2.0047e-04, -1.5945e-03,  2.9318e-03, -2.0878e-04,  3.0486e-03,\n",
      "         -7.3589e-03, -8.1014e-05,  0.0000e+00,  3.9050e-03,  3.3847e-03,\n",
      "         -9.0663e-03, -5.2918e-03,  4.9099e-04, -9.3980e-04,  2.2645e-04,\n",
      "          1.5507e-04,  6.9198e-03, -3.7980e-04,  8.6049e-04, -4.3406e-05,\n",
      "          5.5442e-03,  3.9898e-04, -5.9038e-05, -1.5858e-03,  0.0000e+00,\n",
      "         -9.6698e-04, -7.5200e-03,  5.1060e-03, -8.3490e-03, -8.4632e-03,\n",
      "         -8.9511e-04, -2.0784e-03,  2.1685e-03, -6.2409e-04,  8.6599e-05,\n",
      "          3.9776e-05, -2.7989e-04, -4.1097e-03, -1.2793e-02,  5.7148e-05,\n",
      "         -2.0208e-03,  0.0000e+00,  1.2078e-02,  3.2235e-04,  5.1964e-03],\n",
      "        [ 8.6649e-05,  0.0000e+00,  1.2519e-04, -6.5067e-04,  1.7116e-04,\n",
      "         -1.7482e-03,  6.9342e-03,  7.4345e-03,  3.1028e-03,  0.0000e+00,\n",
      "          1.4431e-04,  7.1410e-04,  0.0000e+00,  1.2217e-03,  0.0000e+00,\n",
      "          1.0291e-02,  8.5994e-03,  1.7285e-05,  1.6244e-03,  6.9597e-03,\n",
      "          3.0695e-04,  0.0000e+00,  1.3869e-03,  7.6597e-03,  3.5203e-03,\n",
      "          2.9022e-03,  4.0539e-03,  9.4790e-03,  1.5819e-03,  4.1057e-03,\n",
      "          1.3416e-03,  5.2895e-03,  1.8679e-04,  1.1073e-03,  1.1136e-02,\n",
      "          3.8062e-04,  1.5652e-03,  3.9715e-03,  0.0000e+00,  4.5392e-04,\n",
      "          1.3252e-02,  8.2561e-05,  7.0960e-03, -3.1304e-04,  3.6143e-03,\n",
      "          1.0078e-03,  1.0535e-03,  4.2559e-04,  3.1616e-04,  4.0137e-03,\n",
      "         -5.1244e-04,  2.9579e-03,  1.7229e-04,  2.2183e-06, -8.8281e-04,\n",
      "          1.3235e-03,  3.4475e-04,  4.4839e-03,  1.4085e-02,  7.7815e-03,\n",
      "          4.3157e-03,  1.0668e-04,  0.0000e+00,  3.6402e-03,  1.9617e-03,\n",
      "          1.1398e-03,  1.5878e-03,  3.1476e-03,  3.2409e-03,  2.1155e-04,\n",
      "          1.4651e-04,  8.4984e-03,  4.2710e-04, -1.8201e-03,  1.1817e-04,\n",
      "          4.9646e-03,  5.0256e-04,  6.2744e-06, -2.0318e-03,  0.0000e+00,\n",
      "          2.6495e-03,  3.3469e-03,  6.0567e-03,  9.0845e-04,  1.7786e-03,\n",
      "         -2.1966e-05,  4.8001e-04,  1.4462e-03,  4.9505e-04,  8.0238e-05,\n",
      "          3.7247e-05,  3.0214e-05,  7.3166e-03,  5.2839e-03,  5.2736e-05,\n",
      "          5.0913e-04,  0.0000e+00,  1.1593e-02,  1.0411e-03,  2.3256e-03],\n",
      "        [ 8.7609e-05,  0.0000e+00,  1.3117e-04,  2.1346e-03,  1.7370e-04,\n",
      "          3.2279e-03,  7.1166e-03,  7.6967e-03,  9.0560e-03,  0.0000e+00,\n",
      "          1.4493e-04,  7.1804e-04,  0.0000e+00,  1.2527e-03,  0.0000e+00,\n",
      "          1.7601e-02,  8.9923e-03,  1.7304e-05,  2.2849e-03,  1.3086e-02,\n",
      "          3.0742e-04,  0.0000e+00,  7.8977e-03,  1.9741e-02,  3.6260e-03,\n",
      "          4.3776e-03,  5.0110e-03,  9.7388e-03,  1.6254e-03,  1.0955e-02,\n",
      "          1.3434e-03,  5.4874e-03,  1.8746e-04,  1.1203e-03,  1.2756e-02,\n",
      "          3.8920e-04,  1.5906e-03,  4.1008e-03,  0.0000e+00,  4.5592e-04,\n",
      "          1.9367e-02,  8.5213e-05,  1.1954e-02,  1.5362e-03,  4.9014e-03,\n",
      "          1.0375e-03,  1.0883e-03,  4.2892e-04,  3.2813e-04,  7.6996e-03,\n",
      "          1.0213e-03,  1.1228e-02,  1.6993e-04,  2.2207e-06,  2.9373e-03,\n",
      "          2.8563e-03,  3.3974e-04,  7.8326e-03,  2.5346e-02,  1.3492e-02,\n",
      "          5.1231e-03,  1.0819e-04,  0.0000e+00,  4.0508e-03,  3.1663e-03,\n",
      "          1.1307e-03,  1.5863e-03,  3.2058e-03,  3.2855e-03,  2.1162e-04,\n",
      "          1.4618e-04,  1.1054e-02,  4.2939e-04,  4.3974e-03,  1.1981e-04,\n",
      "          5.1331e-03,  5.1981e-04,  6.2131e-06,  1.4909e-03,  0.0000e+00,\n",
      "          4.2049e-03,  8.9789e-03,  1.1426e-02,  3.3951e-03,  2.0599e-03,\n",
      "          1.7138e-03,  4.8374e-04,  5.0652e-03,  4.9812e-04,  8.2464e-05,\n",
      "          3.7957e-05,  2.9283e-05,  1.3317e-02,  1.5075e-02,  5.3459e-05,\n",
      "          4.9950e-04,  0.0000e+00,  2.1171e-02,  5.8869e-03,  6.3398e-03]])\n",
      "linear_03.bias.grad: tensor([ 0.0416, -0.0525, -0.0564,  0.0615, -0.1776,  0.0680, -0.0205, -0.0221,\n",
      "         0.0622,  0.0957])\n"
     ]
    }
   ],
   "source": [
    "print(\"After backward():\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}.grad: {param.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64cc9c",
   "metadata": {
    "papermill": {
     "duration": 0.012467,
     "end_time": "2025-08-30T17:33:23.809469",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.797002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating an Optimizer\n",
    "\n",
    "* PyTorch’s `torch.optim` provides various optimizer classes.\n",
    "* When creating an optimizer, you pass the model’s parameters and a learning rate as arguments.\n",
    "* The `zero_grad()` method resets (initializes) the gradient values of the trainable parameters.\n",
    "* The `step()` method updates the trainable parameters.\n",
    "* [https://pytorch.org/docs/stable/optim.html](https://pytorch.org/docs/stable/optim.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7f10e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.836102Z",
     "iopub.status.busy": "2025-08-30T17:33:23.835364Z",
     "iopub.status.idle": "2025-08-30T17:33:23.841195Z",
     "shell.execute_reply": "2025-08-30T17:33:23.840591Z"
    },
    "papermill": {
     "duration": 0.020347,
     "end_time": "2025-08-30T17:33:23.842270",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.821923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adagrad, RMSprop, Adam\n",
    "\n",
    "sgd_optim = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "ada_grad_optim = Adagrad(model.parameters(), lr=0.001, eps=1e-9) \n",
    "rmsprop_optim = RMSprop(model.parameters(), lr=0.001, alpha=0.99, eps=1e-9) \n",
    "adam_optim = Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97125e45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.868847Z",
     "iopub.status.busy": "2025-08-30T17:33:23.868336Z",
     "iopub.status.idle": "2025-08-30T17:33:23.889123Z",
     "shell.execute_reply": "2025-08-30T17:33:23.888358Z"
    },
    "papermill": {
     "duration": 0.03531,
     "end_time": "2025-08-30T17:33:23.890331",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.855021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### gradients in initial state: None\n",
      "### gradient after loss.backward(): tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.9558e-04,\n",
      "          1.5074e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.7755e-05,\n",
      "         -4.0737e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.9539e-05,\n",
      "          3.1147e-05,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.0065e-05,\n",
      "          2.7214e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "### gradient after optimizer.zero_grad(): None\n"
     ]
    }
   ],
   "source": [
    "model = create_simple_linear_model(input_size=28, num_classes=10)\n",
    "# output is logit\n",
    "output = model(images) # feed forward \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(output, labels) # calculate loss \n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "params = list(model.parameters())\n",
    "print('### gradients in initial state:', params[0].grad)\n",
    "# print('### params[0] in initial state:', params[0])\n",
    "\n",
    "loss.backward() # back propagation \n",
    "print('### gradient after loss.backward():', params[0].grad)\n",
    "# print('### params[0] after loss.backward():', params[0])\n",
    "\n",
    "optimizer.step() # update w (W ← W - lr × grad)\n",
    "# print(\"### params[0] after optimizer.step():\", params[0])\n",
    "\n",
    "optimizer.zero_grad() # clears the gradients so that they don't accumulate\n",
    "print('### gradient after optimizer.zero_grad():', params[0].grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d01d5f",
   "metadata": {
    "papermill": {
     "duration": 0.012322,
     "end_time": "2025-08-30T17:33:23.915674",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.903352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setting the Device\n",
    "\n",
    "* In PyTorch, you must explicitly specify whether to use the GPU or CPU. If not specified, PyTorch defaults to using the CPU for model training and inference.\n",
    "* To do this, PyTorch uses the `torch.device` object. You need to assign the device to both the model and the tensors that are passed into the model and loss function. (In some cases, such as when using `torchemetrics`, you also need to specify the device for the metrics, but by default, you should at least set the device for the model itself and the tensors fed into it.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78b7b434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:23.942412Z",
     "iopub.status.busy": "2025-08-30T17:33:23.941641Z",
     "iopub.status.idle": "2025-08-30T17:33:24.061604Z",
     "shell.execute_reply": "2025-08-30T17:33:24.060649Z"
    },
    "papermill": {
     "duration": 0.134596,
     "end_time": "2025-08-30T17:33:24.062748",
     "exception": false,
     "start_time": "2025-08-30T17:33:23.928152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> cpu <class 'torch.Tensor'> cpu\n"
     ]
    }
   ],
   "source": [
    "# The device of tensor is cpu by default \n",
    "images, labels = next(iter(train_loader))\n",
    "print(type(images), images.device, type(labels), labels.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5abd8ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:24.089596Z",
     "iopub.status.busy": "2025-08-30T17:33:24.089348Z",
     "iopub.status.idle": "2025-08-30T17:33:24.208829Z",
     "shell.execute_reply": "2025-08-30T17:33:24.207870Z"
    },
    "papermill": {
     "duration": 0.134148,
     "end_time": "2025-08-30T17:33:24.210156",
     "exception": false,
     "start_time": "2025-08-30T17:33:24.076008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 <class 'torch.device'>\n",
      "<class 'torch.Tensor'> cpu <class 'torch.Tensor'> cpu\n",
      "<class 'torch.Tensor'> cuda:0 <class 'torch.Tensor'> cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Before running the following codes, you need to set the accelerator to GPU \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device, type(device))\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "print(type(images), images.device, type(labels), labels.device)\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "print(type(images), images.device, type(labels), labels.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431bff9c",
   "metadata": {
    "papermill": {
     "duration": 0.012409,
     "end_time": "2025-08-30T17:33:24.235858",
     "exception": false,
     "start_time": "2025-08-30T17:33:24.223449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### It is important that both the model and the input tensors are on the same device. If they are on different devices, an error will occur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c7b17c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:24.262654Z",
     "iopub.status.busy": "2025-08-30T17:33:24.262342Z",
     "iopub.status.idle": "2025-08-30T17:33:24.387603Z",
     "shell.execute_reply": "2025-08-30T17:33:24.386565Z"
    },
    "papermill": {
     "duration": 0.140326,
     "end_time": "2025-08-30T17:33:24.388999",
     "exception": false,
     "start_time": "2025-08-30T17:33:24.248673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image tensor device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Extract images and labels from the training data in batches of batch_size\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = create_simple_linear_model(input_size=28, num_classes=10)\n",
    "model = model.to(device)\n",
    "# The model is on device cuda:0, but images are still on CPU.\n",
    "print('image tensor device:', images.device) \n",
    "# The device of the model can be checked with the parameters, e.g., next(model.parameters()).device\n",
    "\n",
    "# To avoid errors, images must also be moved to the same device as the model using to('cuda').\n",
    "#images = images.to(device)\n",
    "#print(images.device)\n",
    "\n",
    "# The following code will cause an error because the model is on cuda, \n",
    "# but the input tensor (images) is still on CPU. \n",
    "# pred = model(images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb65f4",
   "metadata": {
    "papermill": {
     "duration": 0.013025,
     "end_time": "2025-08-30T17:33:24.415281",
     "exception": false,
     "start_time": "2025-08-30T17:33:24.402256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Creating the Training Logic (Loop)\n",
    "\n",
    "* In PyTorch, the creation of neural network models and the training logic are **loosely coupled**.\n",
    "* The model takes a batch of input training data tensors, transforms them according to its structure, and returns the output tensors — with a focus on **building the computational graph**.\n",
    "* The training logic uses the model’s output tensors together with a loss function and an optimizer to update the model’s weight parameters through backpropagation. This is repeated for each batch of training data, and the process is run for the number of epochs specified.\n",
    "* Before training begins, the model must be set to training mode (`model.train()`). This is important because when using techniques such as **Batch Normalization** or **Dropout**, the model behaves differently in training mode compared to validation or inference mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f674f6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:24.442063Z",
     "iopub.status.busy": "2025-08-30T17:33:24.441720Z",
     "iopub.status.idle": "2025-08-30T17:33:24.559950Z",
     "shell.execute_reply": "2025-08-30T17:33:24.558702Z"
    },
    "papermill": {
     "duration": 0.133609,
     "end_time": "2025-08-30T17:33:24.561709",
     "exception": false,
     "start_time": "2025-08-30T17:33:24.428100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.float32, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract images and labels from the training data in batches of BATCH_SIZE\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "# Check the shapes and data types of the batch tensors\n",
    "images.shape, images.dtype, labels.shape, labels.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8b9ea35",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:24.590018Z",
     "iopub.status.busy": "2025-08-30T17:33:24.589226Z",
     "iopub.status.idle": "2025-08-30T17:33:31.204521Z",
     "shell.execute_reply": "2025-08-30T17:33:31.203788Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 6.630798,
     "end_time": "2025-08-30T17:33:31.205938",
     "exception": false,
     "start_time": "2025-08-30T17:33:24.575140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 1th gradient update, current loss: 2.3128795623779297\n",
      "Performing 101th gradient update, current loss: 0.7146307826042175\n",
      "Performing 201th gradient update, current loss: 0.540241539478302\n",
      "Performing 301th gradient update, current loss: 0.6614893674850464\n",
      "Performing 401th gradient update, current loss: 0.7271491885185242\n",
      "Performing 501th gradient update, current loss: 0.4488963782787323\n",
      "Performing 601th gradient update, current loss: 0.4240359365940094\n",
      "Performing 701th gradient update, current loss: 0.35440120100975037\n",
      "Performing 801th gradient update, current loss: 0.2861812114715576\n",
      "Performing 901th gradient update, current loss: 0.4208143353462219\n",
      "Performing 1001th gradient update, current loss: 0.2932419776916504\n",
      "Performing 1101th gradient update, current loss: 0.36761555075645447\n",
      "Performing 1201th gradient update, current loss: 0.7389582991600037\n",
      "Performing 1301th gradient update, current loss: 0.40139853954315186\n",
      "Performing 1401th gradient update, current loss: 0.38816365599632263\n",
      "Performing 1501th gradient update, current loss: 0.6047376394271851\n",
      "Performing 1601th gradient update, current loss: 0.2645728886127472\n",
      "Performing 1701th gradient update, current loss: 0.39658409357070923\n",
      "Performing 1801th gradient update, current loss: 0.254840612411499\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# It is recommended to move the model to the device before entering the training loop\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "# Perform training loop in mini-batches. The training dataset has 60,000 samples\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    # Move input data to the same device as the model\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Pass the image tensor through the model to get the output tensor (logits)\n",
    "    pred = model(images)\n",
    "   \n",
    "    # Compute loss. CrossEntropyLoss applies softmax internally, so do NOT apply softmax to the model's output\n",
    "    loss = loss_fn(pred, labels)\n",
    "\n",
    "    # Initialize optimizer gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Compute gradients via backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update model parameters using the optimizer\n",
    "    optimizer.step()\n",
    "    \n",
    "    if batch_idx % 100 == 0:\n",
    "        print(f'Performing {batch_idx+1}th gradient update, current loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d13a4b",
   "metadata": {
    "papermill": {
     "duration": 0.013832,
     "end_time": "2025-08-30T17:33:31.234465",
     "exception": false,
     "start_time": "2025-08-30T17:33:31.220633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Making it as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aee3b95e",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:31.262703Z",
     "iopub.status.busy": "2025-08-30T17:33:31.262404Z",
     "iopub.status.idle": "2025-08-30T17:33:37.520534Z",
     "shell.execute_reply": "2025-08-30T17:33:37.519700Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 6.274079,
     "end_time": "2025-08-30T17:33:37.522040",
     "exception": false,
     "start_time": "2025-08-30T17:33:31.247961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying gradient for batch 1, current loss: 0.32917433977127075\n",
      "Applying gradient for batch 101, current loss: 0.33505311608314514\n",
      "Applying gradient for batch 201, current loss: 0.1745051145553589\n",
      "Applying gradient for batch 301, current loss: 0.2757560908794403\n",
      "Applying gradient for batch 401, current loss: 0.2841458022594452\n",
      "Applying gradient for batch 501, current loss: 0.30647942423820496\n",
      "Applying gradient for batch 601, current loss: 0.5381497740745544\n",
      "Applying gradient for batch 701, current loss: 0.361266553401947\n",
      "Applying gradient for batch 801, current loss: 0.2536719739437103\n",
      "Applying gradient for batch 901, current loss: 0.6475058794021606\n",
      "Applying gradient for batch 1001, current loss: 0.2673327624797821\n",
      "Applying gradient for batch 1101, current loss: 0.24537798762321472\n",
      "Applying gradient for batch 1201, current loss: 0.3880641460418701\n",
      "Applying gradient for batch 1301, current loss: 0.6502519845962524\n",
      "Applying gradient for batch 1401, current loss: 0.16738982498645782\n",
      "Applying gradient for batch 1501, current loss: 0.25807395577430725\n",
      "Applying gradient for batch 1601, current loss: 0.550507128238678\n",
      "Applying gradient for batch 1701, current loss: 0.23492416739463806\n",
      "Applying gradient for batch 1801, current loss: 0.2839922308921814\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training dataset in mini-batches for 1 epoch\n",
    "def train_step():\n",
    "    # Perform training loop in mini-batches. The training dataset has 60,000 samples\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # Move input data to the same device as the model\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Pass the image tensor through the model to get the output tensor (logits)\n",
    "        pred = model(images)\n",
    "        \n",
    "        # Compute loss. CrossEntropyLoss applies softmax internally, so do NOT apply softmax to the model output\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        # Initialize optimizer gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients via backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model parameters using the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print loss every 100 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Applying gradient for batch {batch_idx+1}, current loss: {loss.item()}')\n",
    "\n",
    "train_step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa8407",
   "metadata": {
    "papermill": {
     "duration": 0.013994,
     "end_time": "2025-08-30T17:33:37.551556",
     "exception": false,
     "start_time": "2025-08-30T17:33:37.537562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Repeat the training loop for multiple epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7277c7b",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-30T17:33:37.581764Z",
     "iopub.status.busy": "2025-08-30T17:33:37.581009Z",
     "iopub.status.idle": "2025-08-30T17:34:40.084544Z",
     "shell.execute_reply": "2025-08-30T17:34:40.083589Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 62.520317,
     "end_time": "2025-08-30T17:34:40.085990",
     "exception": false,
     "start_time": "2025-08-30T17:33:37.565673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Starting training epoch 1\n",
      "Applying gradient for batch 1, current loss: 0.3970460891723633\n",
      "Applying gradient for batch 101, current loss: 0.4268745183944702\n",
      "Applying gradient for batch 201, current loss: 0.15417563915252686\n",
      "Applying gradient for batch 301, current loss: 0.3786919414997101\n",
      "Applying gradient for batch 401, current loss: 0.28827956318855286\n",
      "Applying gradient for batch 501, current loss: 0.34847432374954224\n",
      "Applying gradient for batch 601, current loss: 0.32767096161842346\n",
      "Applying gradient for batch 701, current loss: 0.17305293679237366\n",
      "Applying gradient for batch 801, current loss: 0.2164413034915924\n",
      "Applying gradient for batch 901, current loss: 0.7466790676116943\n",
      "Applying gradient for batch 1001, current loss: 0.41108080744743347\n",
      "Applying gradient for batch 1101, current loss: 0.3551371991634369\n",
      "Applying gradient for batch 1201, current loss: 0.41207751631736755\n",
      "Applying gradient for batch 1301, current loss: 0.2977469265460968\n",
      "Applying gradient for batch 1401, current loss: 0.16021129488945007\n",
      "Applying gradient for batch 1501, current loss: 0.40671348571777344\n",
      "Applying gradient for batch 1601, current loss: 0.7408224940299988\n",
      "Applying gradient for batch 1701, current loss: 0.299973726272583\n",
      "Applying gradient for batch 1801, current loss: 0.11238443851470947\n",
      "######## Starting training epoch 2\n",
      "Applying gradient for batch 1, current loss: 0.27408722043037415\n",
      "Applying gradient for batch 101, current loss: 0.2889068126678467\n",
      "Applying gradient for batch 201, current loss: 0.4253491461277008\n",
      "Applying gradient for batch 301, current loss: 0.5373435616493225\n",
      "Applying gradient for batch 401, current loss: 0.1608765870332718\n",
      "Applying gradient for batch 501, current loss: 0.26638472080230713\n",
      "Applying gradient for batch 601, current loss: 0.5991149544715881\n",
      "Applying gradient for batch 701, current loss: 0.5776280164718628\n",
      "Applying gradient for batch 801, current loss: 0.3943893015384674\n",
      "Applying gradient for batch 901, current loss: 0.4366913139820099\n",
      "Applying gradient for batch 1001, current loss: 0.2393760234117508\n",
      "Applying gradient for batch 1101, current loss: 0.06228943169116974\n",
      "Applying gradient for batch 1201, current loss: 0.4542645514011383\n",
      "Applying gradient for batch 1301, current loss: 0.16861611604690552\n",
      "Applying gradient for batch 1401, current loss: 0.340777188539505\n",
      "Applying gradient for batch 1501, current loss: 0.22614532709121704\n",
      "Applying gradient for batch 1601, current loss: 0.24218568205833435\n",
      "Applying gradient for batch 1701, current loss: 0.3424850404262543\n",
      "Applying gradient for batch 1801, current loss: 0.4496232271194458\n",
      "######## Starting training epoch 3\n",
      "Applying gradient for batch 1, current loss: 0.2969338297843933\n",
      "Applying gradient for batch 101, current loss: 0.13206888735294342\n",
      "Applying gradient for batch 201, current loss: 0.258295476436615\n",
      "Applying gradient for batch 301, current loss: 0.3477102518081665\n",
      "Applying gradient for batch 401, current loss: 0.23796996474266052\n",
      "Applying gradient for batch 501, current loss: 0.431173712015152\n",
      "Applying gradient for batch 601, current loss: 0.4540453553199768\n",
      "Applying gradient for batch 701, current loss: 0.0816488116979599\n",
      "Applying gradient for batch 801, current loss: 0.5400153994560242\n",
      "Applying gradient for batch 901, current loss: 0.14579668641090393\n",
      "Applying gradient for batch 1001, current loss: 0.12973076105117798\n",
      "Applying gradient for batch 1101, current loss: 0.26182711124420166\n",
      "Applying gradient for batch 1201, current loss: 0.5358805060386658\n",
      "Applying gradient for batch 1301, current loss: 0.12154942005872726\n",
      "Applying gradient for batch 1401, current loss: 0.2599807381629944\n",
      "Applying gradient for batch 1501, current loss: 0.21937856078147888\n",
      "Applying gradient for batch 1601, current loss: 0.432721883058548\n",
      "Applying gradient for batch 1701, current loss: 0.22892822325229645\n",
      "Applying gradient for batch 1801, current loss: 0.039676763117313385\n",
      "######## Starting training epoch 4\n",
      "Applying gradient for batch 1, current loss: 0.21718426048755646\n",
      "Applying gradient for batch 101, current loss: 0.33098432421684265\n",
      "Applying gradient for batch 201, current loss: 0.138353168964386\n",
      "Applying gradient for batch 301, current loss: 0.3491152226924896\n",
      "Applying gradient for batch 401, current loss: 0.22218017280101776\n",
      "Applying gradient for batch 501, current loss: 0.1749589592218399\n",
      "Applying gradient for batch 601, current loss: 0.10890401899814606\n",
      "Applying gradient for batch 701, current loss: 0.21782197058200836\n",
      "Applying gradient for batch 801, current loss: 0.1784626841545105\n",
      "Applying gradient for batch 901, current loss: 0.3152386546134949\n",
      "Applying gradient for batch 1001, current loss: 0.4374432861804962\n",
      "Applying gradient for batch 1101, current loss: 0.22357603907585144\n",
      "Applying gradient for batch 1201, current loss: 0.34418052434921265\n",
      "Applying gradient for batch 1301, current loss: 0.42419078946113586\n",
      "Applying gradient for batch 1401, current loss: 0.17889124155044556\n",
      "Applying gradient for batch 1501, current loss: 0.1452367603778839\n",
      "Applying gradient for batch 1601, current loss: 0.20425906777381897\n",
      "Applying gradient for batch 1701, current loss: 0.31245937943458557\n",
      "Applying gradient for batch 1801, current loss: 0.2827639579772949\n",
      "######## Starting training epoch 5\n",
      "Applying gradient for batch 1, current loss: 0.3050384521484375\n",
      "Applying gradient for batch 101, current loss: 0.5342928767204285\n",
      "Applying gradient for batch 201, current loss: 0.25330546498298645\n",
      "Applying gradient for batch 301, current loss: 0.3268295228481293\n",
      "Applying gradient for batch 401, current loss: 0.24146102368831635\n",
      "Applying gradient for batch 501, current loss: 0.24004487693309784\n",
      "Applying gradient for batch 601, current loss: 0.5223995447158813\n",
      "Applying gradient for batch 701, current loss: 0.2657867968082428\n",
      "Applying gradient for batch 801, current loss: 0.17570699751377106\n",
      "Applying gradient for batch 901, current loss: 0.12340495735406876\n",
      "Applying gradient for batch 1001, current loss: 0.1631392538547516\n",
      "Applying gradient for batch 1101, current loss: 0.166398823261261\n",
      "Applying gradient for batch 1201, current loss: 0.19121651351451874\n",
      "Applying gradient for batch 1301, current loss: 0.30988743901252747\n",
      "Applying gradient for batch 1401, current loss: 0.31284385919570923\n",
      "Applying gradient for batch 1501, current loss: 0.3223344385623932\n",
      "Applying gradient for batch 1601, current loss: 0.1582322120666504\n",
      "Applying gradient for batch 1701, current loss: 0.20484797656536102\n",
      "Applying gradient for batch 1801, current loss: 0.21105080842971802\n",
      "######## Starting training epoch 6\n",
      "Applying gradient for batch 1, current loss: 0.17035484313964844\n",
      "Applying gradient for batch 101, current loss: 0.38280513882637024\n",
      "Applying gradient for batch 201, current loss: 0.5809364318847656\n",
      "Applying gradient for batch 301, current loss: 0.23046356439590454\n",
      "Applying gradient for batch 401, current loss: 0.2459385097026825\n",
      "Applying gradient for batch 501, current loss: 0.10486854612827301\n",
      "Applying gradient for batch 601, current loss: 0.2568776607513428\n",
      "Applying gradient for batch 701, current loss: 0.4717199504375458\n",
      "Applying gradient for batch 801, current loss: 0.3195553719997406\n",
      "Applying gradient for batch 901, current loss: 0.24460993707180023\n",
      "Applying gradient for batch 1001, current loss: 0.1154961884021759\n",
      "Applying gradient for batch 1101, current loss: 0.19729773700237274\n",
      "Applying gradient for batch 1201, current loss: 0.40016984939575195\n",
      "Applying gradient for batch 1301, current loss: 0.4152389168739319\n",
      "Applying gradient for batch 1401, current loss: 0.3420068025588989\n",
      "Applying gradient for batch 1501, current loss: 0.6446639895439148\n",
      "Applying gradient for batch 1601, current loss: 0.2300856113433838\n",
      "Applying gradient for batch 1701, current loss: 0.1513073742389679\n",
      "Applying gradient for batch 1801, current loss: 0.2826138734817505\n",
      "######## Starting training epoch 7\n",
      "Applying gradient for batch 1, current loss: 0.21980202198028564\n",
      "Applying gradient for batch 101, current loss: 0.15896138548851013\n",
      "Applying gradient for batch 201, current loss: 0.13254733383655548\n",
      "Applying gradient for batch 301, current loss: 0.21010971069335938\n",
      "Applying gradient for batch 401, current loss: 0.2650916874408722\n",
      "Applying gradient for batch 501, current loss: 0.34042593836784363\n",
      "Applying gradient for batch 601, current loss: 0.2544052004814148\n",
      "Applying gradient for batch 701, current loss: 0.34198108315467834\n",
      "Applying gradient for batch 801, current loss: 0.45064854621887207\n",
      "Applying gradient for batch 901, current loss: 0.23398226499557495\n",
      "Applying gradient for batch 1001, current loss: 0.24093292653560638\n",
      "Applying gradient for batch 1101, current loss: 0.16591708362102509\n",
      "Applying gradient for batch 1201, current loss: 0.26147109270095825\n",
      "Applying gradient for batch 1301, current loss: 0.11386760324239731\n",
      "Applying gradient for batch 1401, current loss: 0.3893837332725525\n",
      "Applying gradient for batch 1501, current loss: 0.1647845208644867\n",
      "Applying gradient for batch 1601, current loss: 0.18590210378170013\n",
      "Applying gradient for batch 1701, current loss: 0.16405880451202393\n",
      "Applying gradient for batch 1801, current loss: 0.17807236313819885\n",
      "######## Starting training epoch 8\n",
      "Applying gradient for batch 1, current loss: 0.26452744007110596\n",
      "Applying gradient for batch 101, current loss: 0.20613984763622284\n",
      "Applying gradient for batch 201, current loss: 0.13603171706199646\n",
      "Applying gradient for batch 301, current loss: 0.24769213795661926\n",
      "Applying gradient for batch 401, current loss: 0.20074808597564697\n",
      "Applying gradient for batch 501, current loss: 0.28010475635528564\n",
      "Applying gradient for batch 601, current loss: 0.08786850422620773\n",
      "Applying gradient for batch 701, current loss: 0.15315452218055725\n",
      "Applying gradient for batch 801, current loss: 0.06939538568258286\n",
      "Applying gradient for batch 901, current loss: 0.22347111999988556\n",
      "Applying gradient for batch 1001, current loss: 0.29969197511672974\n",
      "Applying gradient for batch 1101, current loss: 0.06453923135995865\n",
      "Applying gradient for batch 1201, current loss: 0.16696856915950775\n",
      "Applying gradient for batch 1301, current loss: 0.10921008139848709\n",
      "Applying gradient for batch 1401, current loss: 0.2041691094636917\n",
      "Applying gradient for batch 1501, current loss: 0.2366512566804886\n",
      "Applying gradient for batch 1601, current loss: 0.14220143854618073\n",
      "Applying gradient for batch 1701, current loss: 0.4632430374622345\n",
      "Applying gradient for batch 1801, current loss: 0.23132909834384918\n",
      "######## Starting training epoch 9\n",
      "Applying gradient for batch 1, current loss: 0.2275838404893875\n",
      "Applying gradient for batch 101, current loss: 0.16350296139717102\n",
      "Applying gradient for batch 201, current loss: 0.2519148588180542\n",
      "Applying gradient for batch 301, current loss: 0.1630723476409912\n",
      "Applying gradient for batch 401, current loss: 0.21153533458709717\n",
      "Applying gradient for batch 501, current loss: 0.15801526606082916\n",
      "Applying gradient for batch 601, current loss: 0.11311766505241394\n",
      "Applying gradient for batch 701, current loss: 0.08910682052373886\n",
      "Applying gradient for batch 801, current loss: 0.2057931125164032\n",
      "Applying gradient for batch 901, current loss: 0.08964676409959793\n",
      "Applying gradient for batch 1001, current loss: 0.15371787548065186\n",
      "Applying gradient for batch 1101, current loss: 0.26709434390068054\n",
      "Applying gradient for batch 1201, current loss: 0.5911636352539062\n",
      "Applying gradient for batch 1301, current loss: 0.2925300598144531\n",
      "Applying gradient for batch 1401, current loss: 0.5131397247314453\n",
      "Applying gradient for batch 1501, current loss: 0.19822894036769867\n",
      "Applying gradient for batch 1601, current loss: 0.22689175605773926\n",
      "Applying gradient for batch 1701, current loss: 0.5259696841239929\n",
      "Applying gradient for batch 1801, current loss: 0.21111899614334106\n",
      "######## Starting training epoch 10\n",
      "Applying gradient for batch 1, current loss: 0.12872308492660522\n",
      "Applying gradient for batch 101, current loss: 0.051230575889348984\n",
      "Applying gradient for batch 201, current loss: 0.12054935842752457\n",
      "Applying gradient for batch 301, current loss: 0.1998603641986847\n",
      "Applying gradient for batch 401, current loss: 0.17277048528194427\n",
      "Applying gradient for batch 501, current loss: 0.10857215523719788\n",
      "Applying gradient for batch 601, current loss: 0.11376344412565231\n",
      "Applying gradient for batch 701, current loss: 0.31849583983421326\n",
      "Applying gradient for batch 801, current loss: 0.31826817989349365\n",
      "Applying gradient for batch 901, current loss: 0.055978186428546906\n",
      "Applying gradient for batch 1001, current loss: 0.11654609441757202\n",
      "Applying gradient for batch 1101, current loss: 0.14271734654903412\n",
      "Applying gradient for batch 1201, current loss: 0.14357449114322662\n",
      "Applying gradient for batch 1301, current loss: 0.20437213778495789\n",
      "Applying gradient for batch 1401, current loss: 0.35225215554237366\n",
      "Applying gradient for batch 1501, current loss: 0.16311782598495483\n",
      "Applying gradient for batch 1601, current loss: 0.37563931941986084\n",
      "Applying gradient for batch 1701, current loss: 0.1323872208595276\n",
      "Applying gradient for batch 1801, current loss: 0.09619065374135971\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Move the model to the specified device\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"######## Starting training epoch {epoch+1}\")\n",
    "    train_step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a911a3",
   "metadata": {
    "papermill": {
     "duration": 0.022418,
     "end_time": "2025-08-30T17:34:40.131684",
     "exception": false,
     "start_time": "2025-08-30T17:34:40.109266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Perform evaluation using validation data\n",
    "\n",
    "* Evaluate the model on batch-wise validation data during or after the training loop to check the model’s loss and performance metrics.\n",
    "* Compare performance metrics on training data and validation data to monitor the extent of overfitting.\n",
    "* Set the model to evaluation mode (`model.eval()`) before starting evaluation. This ensures layers like Batch Normalization or Dropout behave differently than in training mode.\n",
    "* Evaluation is based on the model’s output, so backpropagation or gradient tracking is not required. By default, PyTorch tracks gradients for tensors with `requires_grad=True` during the forward pass, so to improve evaluation speed, gradient tracking is disabled using the `with torch.no_grad()` context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4533cee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:34:40.177389Z",
     "iopub.status.busy": "2025-08-30T17:34:40.177078Z",
     "iopub.status.idle": "2025-08-30T17:34:41.089417Z",
     "shell.execute_reply": "2025-08-30T17:34:41.088324Z"
    },
    "papermill": {
     "duration": 0.936636,
     "end_time": "2025-08-30T17:34:41.090557",
     "exception": false,
     "start_time": "2025-08-30T17:34:40.153921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at batch 0: 0.6612581014633179\n",
      "Validation loss at batch 100: 0.5522692203521729\n",
      "Validation loss at batch 200: 0.3506075441837311\n",
      "Validation loss at batch 300: 0.27856364846229553\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# No need to shuffle validation data. Usually, batch size can be larger than in training for speed improvement.\n",
    "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# loss function for evaluation\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# move model to the specified device\n",
    "model = model.to(device)\n",
    "\n",
    "# set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# apply torch.no_grad() context to disable gradient tracking for all tensors\n",
    "with torch.no_grad():\n",
    "# iterate over validation data in mini-batches\n",
    "    for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "        # move input tensors to the same device as the model\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass through the model\n",
    "        pred = model(images)\n",
    "    \n",
    "        # compute loss for comparison with training loss; no backpropagation performed\n",
    "        loss = loss_fn(pred, labels)\n",
    "\n",
    "        # print every 100 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Validation loss at batch {batch_idx}: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "978a6ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:34:41.137334Z",
     "iopub.status.busy": "2025-08-30T17:34:41.137024Z",
     "iopub.status.idle": "2025-08-30T17:34:41.142167Z",
     "shell.execute_reply": "2025-08-30T17:34:41.141466Z"
    },
    "papermill": {
     "duration": 0.029771,
     "end_time": "2025-08-30T17:34:41.143322",
     "exception": false,
     "start_time": "2025-08-30T17:34:41.113551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_step():\n",
    "    with torch.no_grad():\n",
    "    # iterate over validation data in mini-batches\n",
    "        for batch_idx, (images, labels) in enumerate(val_loader):\n",
    "            # move input tensors to the same device as the model\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # forward pass through the model\n",
    "            pred = model(images)\n",
    "    \n",
    "            # compute loss for comparison with training loss; no backpropagation performed\n",
    "            loss = loss_fn(pred, labels)\n",
    "\n",
    "            # print every 100 batches\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Validation loss at batch {batch_idx}: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a038ef",
   "metadata": {
    "papermill": {
     "duration": 0.022205,
     "end_time": "2025-08-30T17:34:41.187624",
     "exception": false,
     "start_time": "2025-08-30T17:34:41.165419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Training Loop with Validation Data Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99b895a9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-30T17:34:41.233395Z",
     "iopub.status.busy": "2025-08-30T17:34:41.233116Z",
     "iopub.status.idle": "2025-08-30T17:35:51.764392Z",
     "shell.execute_reply": "2025-08-30T17:35:51.763336Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 70.555633,
     "end_time": "2025-08-30T17:35:51.765601",
     "exception": false,
     "start_time": "2025-08-30T17:34:41.209968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Starting train epoch 1\n",
      "Applying gradient for batch 1, current loss: 0.10308381915092468\n",
      "Applying gradient for batch 101, current loss: 0.0332147441804409\n",
      "Applying gradient for batch 201, current loss: 0.23480479419231415\n",
      "Applying gradient for batch 301, current loss: 0.29505935311317444\n",
      "Applying gradient for batch 401, current loss: 0.16447153687477112\n",
      "Applying gradient for batch 501, current loss: 0.20250576734542847\n",
      "Applying gradient for batch 601, current loss: 0.11963443458080292\n",
      "Applying gradient for batch 701, current loss: 0.23377621173858643\n",
      "Applying gradient for batch 801, current loss: 0.3336952030658722\n",
      "Applying gradient for batch 901, current loss: 0.20074661076068878\n",
      "Applying gradient for batch 1001, current loss: 0.1644068956375122\n",
      "Applying gradient for batch 1101, current loss: 0.3539550304412842\n",
      "Applying gradient for batch 1201, current loss: 0.2739941477775574\n",
      "Applying gradient for batch 1301, current loss: 0.09637360274791718\n",
      "Applying gradient for batch 1401, current loss: 0.26260480284690857\n",
      "Applying gradient for batch 1501, current loss: 0.3845294415950775\n",
      "Applying gradient for batch 1601, current loss: 0.1395488977432251\n",
      "Applying gradient for batch 1701, current loss: 0.15630720555782318\n",
      "Applying gradient for batch 1801, current loss: 0.19846631586551666\n",
      "######## Starting validation epoch 1\n",
      "Validation loss at batch 0: 0.6120340824127197\n",
      "Validation loss at batch 100: 0.5120735764503479\n",
      "Validation loss at batch 200: 0.30005502700805664\n",
      "Validation loss at batch 300: 0.3241957128047943\n",
      "######## Starting train epoch 2\n",
      "Applying gradient for batch 1, current loss: 0.16285106539726257\n",
      "Applying gradient for batch 101, current loss: 0.13366833329200745\n",
      "Applying gradient for batch 201, current loss: 0.3325459361076355\n",
      "Applying gradient for batch 301, current loss: 0.13592515885829926\n",
      "Applying gradient for batch 401, current loss: 0.28470054268836975\n",
      "Applying gradient for batch 501, current loss: 0.13197803497314453\n",
      "Applying gradient for batch 601, current loss: 0.32960689067840576\n",
      "Applying gradient for batch 701, current loss: 0.17801430821418762\n",
      "Applying gradient for batch 801, current loss: 0.18004091084003448\n",
      "Applying gradient for batch 901, current loss: 0.21131181716918945\n",
      "Applying gradient for batch 1001, current loss: 0.10261131823062897\n",
      "Applying gradient for batch 1101, current loss: 0.24786338210105896\n",
      "Applying gradient for batch 1201, current loss: 0.19122694432735443\n",
      "Applying gradient for batch 1301, current loss: 0.14095598459243774\n",
      "Applying gradient for batch 1401, current loss: 0.2972802519798279\n",
      "Applying gradient for batch 1501, current loss: 0.15408092737197876\n",
      "Applying gradient for batch 1601, current loss: 0.44846975803375244\n",
      "Applying gradient for batch 1701, current loss: 0.25225329399108887\n",
      "Applying gradient for batch 1801, current loss: 0.11921177804470062\n",
      "######## Starting validation epoch 2\n",
      "Validation loss at batch 0: 1.1669539213180542\n",
      "Validation loss at batch 100: 0.4809516966342926\n",
      "Validation loss at batch 200: 0.3554699122905731\n",
      "Validation loss at batch 300: 0.15782102942466736\n",
      "######## Starting train epoch 3\n",
      "Applying gradient for batch 1, current loss: 0.14043128490447998\n",
      "Applying gradient for batch 101, current loss: 0.25044065713882446\n",
      "Applying gradient for batch 201, current loss: 0.24316731095314026\n",
      "Applying gradient for batch 301, current loss: 0.2873820662498474\n",
      "Applying gradient for batch 401, current loss: 0.4494292140007019\n",
      "Applying gradient for batch 501, current loss: 0.1738092303276062\n",
      "Applying gradient for batch 601, current loss: 0.211945578455925\n",
      "Applying gradient for batch 701, current loss: 0.18744944036006927\n",
      "Applying gradient for batch 801, current loss: 0.17927898466587067\n",
      "Applying gradient for batch 901, current loss: 0.1933252066373825\n",
      "Applying gradient for batch 1001, current loss: 0.2112334668636322\n",
      "Applying gradient for batch 1101, current loss: 0.1676209270954132\n",
      "Applying gradient for batch 1201, current loss: 0.12450917810201645\n",
      "Applying gradient for batch 1301, current loss: 0.2485683411359787\n",
      "Applying gradient for batch 1401, current loss: 0.16225209832191467\n",
      "Applying gradient for batch 1501, current loss: 0.2693367302417755\n",
      "Applying gradient for batch 1601, current loss: 0.3542473018169403\n",
      "Applying gradient for batch 1701, current loss: 0.09523437917232513\n",
      "Applying gradient for batch 1801, current loss: 0.11775578558444977\n",
      "######## Starting validation epoch 3\n",
      "Validation loss at batch 0: 0.7283235192298889\n",
      "Validation loss at batch 100: 0.4406743049621582\n",
      "Validation loss at batch 200: 0.3124043047428131\n",
      "Validation loss at batch 300: 0.2630629539489746\n",
      "######## Starting train epoch 4\n",
      "Applying gradient for batch 1, current loss: 0.20861321687698364\n",
      "Applying gradient for batch 101, current loss: 0.1751316636800766\n",
      "Applying gradient for batch 201, current loss: 0.28010568022727966\n",
      "Applying gradient for batch 301, current loss: 0.1096208319067955\n",
      "Applying gradient for batch 401, current loss: 0.2117367386817932\n",
      "Applying gradient for batch 501, current loss: 0.4957963824272156\n",
      "Applying gradient for batch 601, current loss: 0.18869122862815857\n",
      "Applying gradient for batch 701, current loss: 0.07413382828235626\n",
      "Applying gradient for batch 801, current loss: 0.026958899572491646\n",
      "Applying gradient for batch 901, current loss: 0.14809775352478027\n",
      "Applying gradient for batch 1001, current loss: 0.353363037109375\n",
      "Applying gradient for batch 1101, current loss: 0.20313358306884766\n",
      "Applying gradient for batch 1201, current loss: 0.06924232095479965\n",
      "Applying gradient for batch 1301, current loss: 0.20429019629955292\n",
      "Applying gradient for batch 1401, current loss: 0.15754958987236023\n",
      "Applying gradient for batch 1501, current loss: 0.2550585865974426\n",
      "Applying gradient for batch 1601, current loss: 0.12616252899169922\n",
      "Applying gradient for batch 1701, current loss: 0.19757606089115143\n",
      "Applying gradient for batch 1801, current loss: 0.14150701463222504\n",
      "######## Starting validation epoch 4\n",
      "Validation loss at batch 0: 0.7675971984863281\n",
      "Validation loss at batch 100: 0.5430128574371338\n",
      "Validation loss at batch 200: 0.2527083456516266\n",
      "Validation loss at batch 300: 0.2735538184642792\n",
      "######## Starting train epoch 5\n",
      "Applying gradient for batch 1, current loss: 0.3386082351207733\n",
      "Applying gradient for batch 101, current loss: 0.10161209851503372\n",
      "Applying gradient for batch 201, current loss: 0.12740540504455566\n",
      "Applying gradient for batch 301, current loss: 0.24173489212989807\n",
      "Applying gradient for batch 401, current loss: 0.11115670949220657\n",
      "Applying gradient for batch 501, current loss: 0.10665890574455261\n",
      "Applying gradient for batch 601, current loss: 0.08404357731342316\n",
      "Applying gradient for batch 701, current loss: 0.1486070156097412\n",
      "Applying gradient for batch 801, current loss: 0.09802132099866867\n",
      "Applying gradient for batch 901, current loss: 0.12120822817087173\n",
      "Applying gradient for batch 1001, current loss: 0.1663399040699005\n",
      "Applying gradient for batch 1101, current loss: 0.24140676856040955\n",
      "Applying gradient for batch 1201, current loss: 0.13069428503513336\n",
      "Applying gradient for batch 1301, current loss: 0.178758442401886\n",
      "Applying gradient for batch 1401, current loss: 0.19459423422813416\n",
      "Applying gradient for batch 1501, current loss: 0.1288241147994995\n",
      "Applying gradient for batch 1601, current loss: 0.11753669381141663\n",
      "Applying gradient for batch 1701, current loss: 0.11523399502038956\n",
      "Applying gradient for batch 1801, current loss: 0.14231611788272858\n",
      "######## Starting validation epoch 5\n",
      "Validation loss at batch 0: 0.49573010206222534\n",
      "Validation loss at batch 100: 0.5802713632583618\n",
      "Validation loss at batch 200: 0.27637824416160583\n",
      "Validation loss at batch 300: 0.29622915387153625\n",
      "######## Starting train epoch 6\n",
      "Applying gradient for batch 1, current loss: 0.48220178484916687\n",
      "Applying gradient for batch 101, current loss: 0.08303866535425186\n",
      "Applying gradient for batch 201, current loss: 0.10522883385419846\n",
      "Applying gradient for batch 301, current loss: 0.08425763249397278\n",
      "Applying gradient for batch 401, current loss: 0.08008822053670883\n",
      "Applying gradient for batch 501, current loss: 0.11113888025283813\n",
      "Applying gradient for batch 601, current loss: 0.30391353368759155\n",
      "Applying gradient for batch 701, current loss: 0.047811221331357956\n",
      "Applying gradient for batch 801, current loss: 0.041109565645456314\n",
      "Applying gradient for batch 901, current loss: 0.10450749844312668\n",
      "Applying gradient for batch 1001, current loss: 0.16583237051963806\n",
      "Applying gradient for batch 1101, current loss: 0.08897393941879272\n",
      "Applying gradient for batch 1201, current loss: 0.20265540480613708\n",
      "Applying gradient for batch 1301, current loss: 0.14701054990291595\n",
      "Applying gradient for batch 1401, current loss: 0.26225998997688293\n",
      "Applying gradient for batch 1501, current loss: 0.1644315868616104\n",
      "Applying gradient for batch 1601, current loss: 0.18469037115573883\n",
      "Applying gradient for batch 1701, current loss: 0.11397090554237366\n",
      "Applying gradient for batch 1801, current loss: 0.1955309808254242\n",
      "######## Starting validation epoch 6\n",
      "Validation loss at batch 0: 0.9378989934921265\n",
      "Validation loss at batch 100: 0.4122399389743805\n",
      "Validation loss at batch 200: 0.24008134007453918\n",
      "Validation loss at batch 300: 0.31696346402168274\n",
      "######## Starting train epoch 7\n",
      "Applying gradient for batch 1, current loss: 0.22561213374137878\n",
      "Applying gradient for batch 101, current loss: 0.13290739059448242\n",
      "Applying gradient for batch 201, current loss: 0.1556071639060974\n",
      "Applying gradient for batch 301, current loss: 0.06659052520990372\n",
      "Applying gradient for batch 401, current loss: 0.23660236597061157\n",
      "Applying gradient for batch 501, current loss: 0.04444633796811104\n",
      "Applying gradient for batch 601, current loss: 0.08704165369272232\n",
      "Applying gradient for batch 701, current loss: 0.08500813692808151\n",
      "Applying gradient for batch 801, current loss: 0.08125923573970795\n",
      "Applying gradient for batch 901, current loss: 0.2498849332332611\n",
      "Applying gradient for batch 1001, current loss: 0.23282718658447266\n",
      "Applying gradient for batch 1101, current loss: 0.21599537134170532\n",
      "Applying gradient for batch 1201, current loss: 0.22818619012832642\n",
      "Applying gradient for batch 1301, current loss: 0.23801277577877045\n",
      "Applying gradient for batch 1401, current loss: 0.09587740153074265\n",
      "Applying gradient for batch 1501, current loss: 0.20811603963375092\n",
      "Applying gradient for batch 1601, current loss: 0.14669586718082428\n",
      "Applying gradient for batch 1701, current loss: 0.2157794088125229\n",
      "Applying gradient for batch 1801, current loss: 0.062437769025564194\n",
      "######## Starting validation epoch 7\n",
      "Validation loss at batch 0: 0.5074944496154785\n",
      "Validation loss at batch 100: 0.568252444267273\n",
      "Validation loss at batch 200: 0.2680917978286743\n",
      "Validation loss at batch 300: 0.4621424376964569\n",
      "######## Starting train epoch 8\n",
      "Applying gradient for batch 1, current loss: 0.2085571438074112\n",
      "Applying gradient for batch 101, current loss: 0.3272492289543152\n",
      "Applying gradient for batch 201, current loss: 0.0974159985780716\n",
      "Applying gradient for batch 301, current loss: 0.11900968104600906\n",
      "Applying gradient for batch 401, current loss: 0.05378834903240204\n",
      "Applying gradient for batch 501, current loss: 0.06579646468162537\n",
      "Applying gradient for batch 601, current loss: 0.28397390246391296\n",
      "Applying gradient for batch 701, current loss: 0.1661646068096161\n",
      "Applying gradient for batch 801, current loss: 0.12382534891366959\n",
      "Applying gradient for batch 901, current loss: 0.24511393904685974\n",
      "Applying gradient for batch 1001, current loss: 0.04037667438387871\n",
      "Applying gradient for batch 1101, current loss: 0.1672600507736206\n",
      "Applying gradient for batch 1201, current loss: 0.1429690420627594\n",
      "Applying gradient for batch 1301, current loss: 0.15276871621608734\n",
      "Applying gradient for batch 1401, current loss: 0.12375504523515701\n",
      "Applying gradient for batch 1501, current loss: 0.3023635745048523\n",
      "Applying gradient for batch 1601, current loss: 0.15486551821231842\n",
      "Applying gradient for batch 1701, current loss: 0.20188118517398834\n",
      "Applying gradient for batch 1801, current loss: 0.06317490339279175\n",
      "######## Starting validation epoch 8\n",
      "Validation loss at batch 0: 1.0389158725738525\n",
      "Validation loss at batch 100: 0.523423433303833\n",
      "Validation loss at batch 200: 0.22736328840255737\n",
      "Validation loss at batch 300: 0.452957421541214\n",
      "######## Starting train epoch 9\n",
      "Applying gradient for batch 1, current loss: 0.1508055180311203\n",
      "Applying gradient for batch 101, current loss: 0.20744220912456512\n",
      "Applying gradient for batch 201, current loss: 0.27955299615859985\n",
      "Applying gradient for batch 301, current loss: 0.3169267177581787\n",
      "Applying gradient for batch 401, current loss: 0.13732744753360748\n",
      "Applying gradient for batch 501, current loss: 0.06636904925107956\n",
      "Applying gradient for batch 601, current loss: 0.08194466680288315\n",
      "Applying gradient for batch 701, current loss: 0.3239469826221466\n",
      "Applying gradient for batch 801, current loss: 0.2709037661552429\n",
      "Applying gradient for batch 901, current loss: 0.19231313467025757\n",
      "Applying gradient for batch 1001, current loss: 0.21038255095481873\n",
      "Applying gradient for batch 1101, current loss: 0.093239925801754\n",
      "Applying gradient for batch 1201, current loss: 0.40368184447288513\n",
      "Applying gradient for batch 1301, current loss: 0.07155882567167282\n",
      "Applying gradient for batch 1401, current loss: 0.2936073839664459\n",
      "Applying gradient for batch 1501, current loss: 0.12058529257774353\n",
      "Applying gradient for batch 1601, current loss: 0.05943764001131058\n",
      "Applying gradient for batch 1701, current loss: 0.08200673758983612\n",
      "Applying gradient for batch 1801, current loss: 0.22529760003089905\n",
      "######## Starting validation epoch 9\n",
      "Validation loss at batch 0: 0.5361230373382568\n",
      "Validation loss at batch 100: 0.6450384855270386\n",
      "Validation loss at batch 200: 0.2714538872241974\n",
      "Validation loss at batch 300: 0.4700838327407837\n",
      "######## Starting train epoch 10\n",
      "Applying gradient for batch 1, current loss: 0.1906525194644928\n",
      "Applying gradient for batch 101, current loss: 0.24197524785995483\n",
      "Applying gradient for batch 201, current loss: 0.08719667047262192\n",
      "Applying gradient for batch 301, current loss: 0.10836340487003326\n",
      "Applying gradient for batch 401, current loss: 0.12920227646827698\n",
      "Applying gradient for batch 501, current loss: 0.2618243992328644\n",
      "Applying gradient for batch 601, current loss: 0.15428805351257324\n",
      "Applying gradient for batch 701, current loss: 0.13640613853931427\n",
      "Applying gradient for batch 801, current loss: 0.33364108204841614\n",
      "Applying gradient for batch 901, current loss: 0.09389549493789673\n",
      "Applying gradient for batch 1001, current loss: 0.14863044023513794\n",
      "Applying gradient for batch 1101, current loss: 0.22615335881710052\n",
      "Applying gradient for batch 1201, current loss: 0.23160386085510254\n",
      "Applying gradient for batch 1301, current loss: 0.04701388254761696\n",
      "Applying gradient for batch 1401, current loss: 0.09761451929807663\n",
      "Applying gradient for batch 1501, current loss: 0.12762236595153809\n",
      "Applying gradient for batch 1601, current loss: 0.15680623054504395\n",
      "Applying gradient for batch 1701, current loss: 0.24572691321372986\n",
      "Applying gradient for batch 1801, current loss: 0.27729374170303345\n",
      "######## Starting validation epoch 10\n",
      "Validation loss at batch 0: 0.95600426197052\n",
      "Validation loss at batch 100: 0.5612298250198364\n",
      "Validation loss at batch 200: 0.35148900747299194\n",
      "Validation loss at batch 300: 0.47488194704055786\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    print(f\"######## Starting train epoch {epoch+1}\")\n",
    "    train_step()\n",
    "\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    print(f\"######## Starting validation epoch {epoch+1}\")\n",
    "    val_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c0987",
   "metadata": {
    "papermill": {
     "duration": 0.03025,
     "end_time": "2025-08-30T17:35:51.827758",
     "exception": false,
     "start_time": "2025-08-30T17:35:51.797508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1️⃣ Training loss\n",
    "\n",
    "The training loss per batch is generally decreasing.\n",
    "\n",
    "Some batches even reach 0.018, which is extremely low.\n",
    "\n",
    "→ This means the model is fitting the training data very well.\n",
    "\n",
    "2️⃣ Validation loss\n",
    "\n",
    "Validation loss is irregular and sometimes quite high.\n",
    "\n",
    "Example: batch 0 → 0.598, batch 200 → 0.225, batch 300 → 0.387\n",
    "\n",
    "On average, validation loss is higher than training loss.\n",
    "\n",
    "→ The model is not generalizing as well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30698e4",
   "metadata": {
    "papermill": {
     "duration": 0.030384,
     "end_time": "2025-08-30T17:35:51.889031",
     "exception": false,
     "start_time": "2025-08-30T17:35:51.858647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Predicting Images with a Trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8476abb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:35:51.952187Z",
     "iopub.status.busy": "2025-08-30T17:35:51.951519Z",
     "iopub.status.idle": "2025-08-30T17:35:51.960946Z",
     "shell.execute_reply": "2025-08-30T17:35:51.960401Z"
    },
    "papermill": {
     "duration": 0.042295,
     "end_time": "2025-08-30T17:35:51.962022",
     "exception": false,
     "start_time": "2025-08-30T17:35:51.919727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Reuse the val_data for test\n",
    "test_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "images, labels = next(iter(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d209aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:35:52.026661Z",
     "iopub.status.busy": "2025-08-30T17:35:52.026039Z",
     "iopub.status.idle": "2025-08-30T17:35:52.096869Z",
     "shell.execute_reply": "2025-08-30T17:35:52.096044Z"
    },
    "papermill": {
     "duration": 0.105188,
     "end_time": "2025-08-30T17:35:52.098181",
     "exception": false,
     "start_time": "2025-08-30T17:35:51.992993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output shape: torch.Size([32, 10])\n",
      "predicted class: tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 5, 3, 4, 1, 2, 2, 8, 0, 2, 5, 7, 5,\n",
      "        1, 2, 6, 0, 9, 3, 8, 8], device='cuda:0') torch.Size([32])\n",
      "targets: tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5, 7, 9,\n",
      "        1, 4, 6, 0, 9, 3, 8, 8], device='cuda:0') torch.Size([32])\n",
      "Out of 32 samples, 28 predictions are correct\n"
     ]
    }
   ],
   "source": [
    "# Here, `model` should be a trained model. The model's device is 'cuda:0'.\n",
    "# Set the model to evaluation mode.\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Move images and labels to the same device as the model.\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Forward pass: get logits from the model\n",
    "    pred_logit = model(images)\n",
    "    # Apply softmax to get probabilities and get the predicted class index\n",
    "    pred_class = F.softmax(pred_logit, dim=-1).argmax(-1)\n",
    "    \n",
    "print('model output shape:', pred_logit.shape)\n",
    "print('predicted class:', pred_class, pred_class.shape)\n",
    "print('targets:', labels, labels.shape)\n",
    "\n",
    "# Optional debugging:\n",
    "# print('pred_logit[0]:', pred_logit[0])\n",
    "# print('after softmax:', F.softmax(pred_logit[0], -1))\n",
    "# print('after tensor argmax:', F.softmax(pred_logit[0], dim=-1).argmax(-1))\n",
    "\n",
    "# Count the number of correct predictions\n",
    "num_correct = (pred_class == labels).sum().item()\n",
    "# print(pred_class == targets)\n",
    "print(f'Out of {images.size()[0]} samples, {num_correct} predictions are correct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1cf4524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:35:52.162303Z",
     "iopub.status.busy": "2025-08-30T17:35:52.162025Z",
     "iopub.status.idle": "2025-08-30T17:35:52.168416Z",
     "shell.execute_reply": "2025-08-30T17:35:52.167762Z"
    },
    "papermill": {
     "duration": 0.039737,
     "end_time": "2025-08-30T17:35:52.169506",
     "exception": false,
     "start_time": "2025-08-30T17:35:52.129769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) torch.Size([])\n",
      "target class:9, predicted class: tensor([9], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Predict a single image\n",
    "s_image = images[0] #.unsqueeze(0)\n",
    "s_label = labels[0] #.unsqueeze(0)\n",
    "print(s_image.shape, s_label.shape)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    s_image = s_image.to(device)\n",
    "    s_label = s_label.to(device)\n",
    "\n",
    "    pred_logit = model(s_image)\n",
    "    pred_class = F.softmax(pred_logit, dim=-1).argmax(-1)\n",
    "\n",
    "print(f'target class:{s_label}, predicted class: {pred_class}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "791adebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-30T17:35:52.233498Z",
     "iopub.status.busy": "2025-08-30T17:35:52.232925Z",
     "iopub.status.idle": "2025-08-30T17:35:52.405166Z",
     "shell.execute_reply": "2025-08-30T17:35:52.404463Z"
    },
    "papermill": {
     "duration": 0.205308,
     "end_time": "2025-08-30T17:35:52.406515",
     "exception": false,
     "start_time": "2025-08-30T17:35:52.201207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ankle boot')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "#tensor to PIL\n",
    "to_pil = ToPILImage()\n",
    "pil_image = to_pil(images[0])\n",
    "\n",
    "plt.imshow(pil_image, cmap='gray')\n",
    "plt.title(class_names[pred_class.item()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48628dcd",
   "metadata": {
    "papermill": {
     "duration": 0.030648,
     "end_time": "2025-08-30T17:35:52.469739",
     "exception": false,
     "start_time": "2025-08-30T17:35:52.439091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 181.152239,
   "end_time": "2025-08-30T17:35:54.323732",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-30T17:32:53.171493",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
