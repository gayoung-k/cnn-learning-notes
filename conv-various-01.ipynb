{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef16ee1",
   "metadata": {
    "papermill": {
     "duration": 0.004591,
     "end_time": "2025-08-31T04:09:12.115531",
     "exception": false,
     "start_time": "2025-08-31T04:09:12.110940",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Weight Initialization\n",
    "\n",
    "* In PyTorch, layers like `nn.Linear` and `nn.Conv2d` use **He Uniform** initialization by default for weights.\n",
    "* You can explicitly initialize weights using functions like `nn.init.kaiming_uniform_()` or `nn.init.kaiming_normal_()`.\n",
    "\n",
    "**Why weight initialization matters:**\n",
    "\n",
    "* Proper initialization helps the network **converge faster** during training.\n",
    "* It prevents **vanishing or exploding gradients**, especially in deep networks.\n",
    "* Good initialization ensures that signals (activations) and gradients maintain a reasonable scale across layers, improving **training stability** and final performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df344eeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:12.124183Z",
     "iopub.status.busy": "2025-08-31T04:09:12.123924Z",
     "iopub.status.idle": "2025-08-31T04:09:15.901774Z",
     "shell.execute_reply": "2025-08-31T04:09:15.900944Z"
    },
    "papermill": {
     "duration": 3.783535,
     "end_time": "2025-08-31T04:09:15.902941",
     "exception": false,
     "start_time": "2025-08-31T04:09:12.119406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight boundary: -0.2870391011238098 ~ 0.2778533101081848\n",
      "bound: 0.2886751345948129\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "torch.manual_seed(2025) \n",
    "\n",
    "linear_01 = nn.Linear(in_features=12, out_features=6)\n",
    "print(f'weight boundary: {linear_01.weight.min().item()} ~ {linear_01.weight.max().item()}')\n",
    "\n",
    "# pytorch weight = 1/sqrt(fan_in)\n",
    "fan_in = linear_01.in_features  \n",
    "bound = 1 / math.sqrt(fan_in)\n",
    "print('bound:', bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def2daca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:15.911809Z",
     "iopub.status.busy": "2025-08-31T04:09:15.911513Z",
     "iopub.status.idle": "2025-08-31T04:09:15.950055Z",
     "shell.execute_reply": "2025-08-31T04:09:15.949429Z"
    },
    "papermill": {
     "duration": 0.044061,
     "end_time": "2025-08-31T04:09:15.951188",
     "exception": false,
     "start_time": "2025-08-31T04:09:15.907127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0659, -0.2521,  0.2000, -0.1711,  0.2313,  0.2874, -0.1012,  0.2303,\n",
       "          0.0141,  0.1053, -0.0433,  0.0949],\n",
       "        [-0.2482, -0.2393,  0.1905,  0.1161, -0.2317, -0.0941,  0.2304, -0.0812,\n",
       "          0.2458,  0.2154, -0.2783, -0.1832],\n",
       "        [-0.1151, -0.1292,  0.0518, -0.0755,  0.1770,  0.1658,  0.2855,  0.0584,\n",
       "         -0.2340, -0.2408,  0.0152,  0.0131],\n",
       "        [ 0.2644, -0.2522, -0.1562, -0.2101,  0.1018,  0.1315, -0.0366,  0.1072,\n",
       "         -0.0036,  0.1219, -0.1012, -0.1467],\n",
       "        [-0.1274, -0.1332,  0.1563, -0.2631,  0.1822,  0.0242, -0.1544, -0.1338,\n",
       "         -0.0272,  0.0235,  0.2836, -0.2072],\n",
       "        [-0.1529,  0.2757, -0.1078,  0.0923, -0.2552,  0.2812, -0.1020,  0.2624,\n",
       "         -0.1282,  0.1250,  0.0238,  0.1085]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(in_features=12, out_features=6).weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "130eba83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:15.959873Z",
     "iopub.status.busy": "2025-08-31T04:09:15.959641Z",
     "iopub.status.idle": "2025-08-31T04:09:15.965430Z",
     "shell.execute_reply": "2025-08-31T04:09:15.964875Z"
    },
    "papermill": {
     "duration": 0.011209,
     "end_time": "2025-08-31T04:09:15.966381",
     "exception": false,
     "start_time": "2025-08-31T04:09:15.955172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight boundary: -0.09610466659069061 ~ 0.0962221547961235\n",
      "bound: 0.09622504486493763\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2025)\n",
    "\n",
    "conv_01 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3)\n",
    "print(f'weight boundary: {conv_01.weight.min().item()} ~ {conv_01.weight.max().item()}')\n",
    "\n",
    "# pytorch weight = 1/sqrt(fan_in). Conv2d fan_in is in_channels * kernel_height * kernel_width\n",
    "fan_in = conv_01.in_channels * 3 * 3\n",
    "bound = 1 / math.sqrt(fan_in)\n",
    "print('bound:', bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5863883e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:15.975216Z",
     "iopub.status.busy": "2025-08-31T04:09:15.974650Z",
     "iopub.status.idle": "2025-08-31T04:09:15.980296Z",
     "shell.execute_reply": "2025-08-31T04:09:15.979813Z"
    },
    "papermill": {
     "duration": 0.010969,
     "end_time": "2025-08-31T04:09:15.981281",
     "exception": false,
     "start_time": "2025-08-31T04:09:15.970312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN_01(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        # First Conv2d layer: input channels 3, output channels 32, kernel size 3x3, stride 1\n",
    "        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1)\n",
    "        # Second Conv2d layer: input channels 32, output channels 64, kernel size 3x3, stride 1\n",
    "        self.conv_2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
    "        # Max pooling layer with kernel size 2x2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        # Flatten layer to convert 3D feature map to 1D vector\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Fully connected classification layer\n",
    "        self.classifier = nn.Linear(in_features=12544, out_features=num_classes)\n",
    "\n",
    "        # Weight initialization for all Conv2d layers\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                print('kaiming normal initialization applied')\n",
    "                # Default Conv2d uses kaiming_uniform; here we replace with kaiming_normal\n",
    "                # Note the trailing underscore (_) in nn.init.kaiming_normal_ to modify in-place\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first conv layer followed by ReLU activation\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        # Apply second conv layer followed by ReLU activation\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        # Apply max pooling\n",
    "        x = self.pool(x)\n",
    "        # Flatten the feature map\n",
    "        x = self.flatten(x)\n",
    "        # Pass through classifier to get final output\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adad459b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:15.989594Z",
     "iopub.status.busy": "2025-08-31T04:09:15.989419Z",
     "iopub.status.idle": "2025-08-31T04:09:15.995184Z",
     "shell.execute_reply": "2025-08-31T04:09:15.994599Z"
    },
    "papermill": {
     "duration": 0.011061,
     "end_time": "2025-08-31T04:09:15.996155",
     "exception": false,
     "start_time": "2025-08-31T04:09:15.985094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kaiming normal initialization applied\n",
      "kaiming normal initialization applied\n"
     ]
    }
   ],
   "source": [
    "simple_cnn_01 = SimpleCNN_01(num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78046546",
   "metadata": {
    "papermill": {
     "duration": 0.003565,
     "end_time": "2025-08-31T04:09:16.003492",
     "exception": false,
     "start_time": "2025-08-31T04:09:15.999927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Applying Batch Normalization\n",
    "\n",
    "* After a Linear layer, use `BatchNorm1d(num_features)`, where `num_features` equals the Linear layer's `out_features`.\n",
    "* After a Conv2d layer, use `BatchNorm2d(num_features)`, where `num_features` equals the Conv2d layer's `out_channels`.\n",
    "* In an existing network, replace `Conv -> Activation` with `Conv -> BatchNorm -> Activation`.\n",
    "\n",
    "**Why Batch Normalization?**\n",
    "Batch Normalization normalizes the activations of each layer to have zero mean and unit variance. This stabilizes and accelerates training, helps prevent vanishing/exploding gradients, and can provide slight regularization to reduce overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d972a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:16.012320Z",
     "iopub.status.busy": "2025-08-31T04:09:16.012126Z",
     "iopub.status.idle": "2025-08-31T04:09:28.029122Z",
     "shell.execute_reply": "2025-08-31T04:09:28.028198Z"
    },
    "papermill": {
     "duration": 12.022495,
     "end_time": "2025-08-31T04:09:28.030447",
     "exception": false,
     "start_time": "2025-08-31T04:09:16.007952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:03<00:00, 48.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr: 42500 valid: 7500\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "tr_size = int(0.85 * len(train_dataset))\n",
    "val_size = len(train_dataset) - tr_size\n",
    "tr_dataset, val_dataset = random_split(train_dataset, [tr_size, val_size])\n",
    "print('tr:', len(tr_dataset), 'valid:', len(val_dataset))\n",
    "\n",
    "tr_loader = DataLoader(tr_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a6535a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:28.042755Z",
     "iopub.status.busy": "2025-08-31T04:09:28.042430Z",
     "iopub.status.idle": "2025-08-31T04:09:28.055300Z",
     "shell.execute_reply": "2025-08-31T04:09:28.054609Z"
    },
    "papermill": {
     "duration": 0.020047,
     "end_time": "2025-08-31T04:09:28.056397",
     "exception": false,
     "start_time": "2025-08-31T04:09:28.036350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, device=None):\n",
    "        self.model = model.to(device)  # Move model to specified device\n",
    "        self.loss_fn = loss_fn          # Loss function\n",
    "        self.optimizer = optimizer      # Optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device\n",
    "    \n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()  # Set model to training mode\n",
    "        \n",
    "        # Initialize running loss and accuracy metrics\n",
    "        accu_loss = 0.0\n",
    "        running_avg_loss = 0.0\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "        \n",
    "        # Use tqdm to visualize training progress\n",
    "        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n",
    "                # Move inputs and targets to the specified device\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "                \n",
    "                # Backward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Update running average loss\n",
    "                accu_loss += loss.item()\n",
    "                running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                # Calculate accuracy\n",
    "                # Compare predicted class (argmax) with targets\n",
    "                num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                num_total += inputs.shape[0]\n",
    "                accu_num_correct += num_correct\n",
    "                accuracy = accu_num_correct / num_total\n",
    "\n",
    "                # Update tqdm progress bar with loss and accuracy\n",
    "                progress_bar.update(1)\n",
    "                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:\n",
    "                    progress_bar.set_postfix({\"Loss\": running_avg_loss, \n",
    "                                              \"Accuracy\": accuracy})\n",
    "        \n",
    "        return running_avg_loss, accuracy\n",
    "                \n",
    "    def validate_epoch(self, epoch):\n",
    "        if not self.val_loader:\n",
    "            return None\n",
    "            \n",
    "        self.model.eval()  # Set model to evaluation mode\n",
    "\n",
    "        # Initialize running loss and accuracy metrics\n",
    "        accu_loss = 0\n",
    "        running_avg_loss = 0\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "\n",
    "        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n",
    "            with torch.no_grad():  # Disable gradient computation for validation\n",
    "                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = targets.to(self.device)\n",
    "                    \n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "                    # Update running average loss\n",
    "                    accu_loss += loss.item()\n",
    "                    running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                    # Calculate accuracy\n",
    "                    num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                    num_total += inputs.shape[0]\n",
    "                    accu_num_correct += num_correct\n",
    "                    accuracy = accu_num_correct / num_total\n",
    "\n",
    "                    # Update tqdm progress bar with loss and accuracy\n",
    "                    progress_bar.update(1)\n",
    "                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:\n",
    "                        progress_bar.set_postfix({\"Loss\": running_avg_loss, \n",
    "                                                  \"Accuracy\":accuracy})\n",
    "        return running_avg_loss, accuracy\n",
    "    \n",
    "    def fit(self, epochs):\n",
    "        # Initialize history dict to store train/validation loss and accuracy\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self.train_epoch(epoch)\n",
    "            val_loss, val_acc = self.validate_epoch(epoch)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n",
    "                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\")\n",
    "            \n",
    "            # Record metrics for this epoch\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            \n",
    "        return history \n",
    "    \n",
    "    # Return the trained model\n",
    "    def get_trained_model(self):\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec97b8d",
   "metadata": {
    "papermill": {
     "duration": 0.004964,
     "end_time": "2025-08-31T04:09:28.066438",
     "exception": false,
     "start_time": "2025-08-31T04:09:28.061474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Applying Batch Normalization to the Model and Evaluating Performance\n",
    "\n",
    "* Modify the original network so that each Conv -> Activation block becomes Conv -> BatchNorm -> Activation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e36078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:28.077471Z",
     "iopub.status.busy": "2025-08-31T04:09:28.077251Z",
     "iopub.status.idle": "2025-08-31T04:09:28.769921Z",
     "shell.execute_reply": "2025-08-31T04:09:28.769187Z"
    },
    "papermill": {
     "duration": 0.699663,
     "end_time": "2025-08-31T04:09:28.771174",
     "exception": false,
     "start_time": "2025-08-31T04:09:28.071511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "SimpleCNNWithBN (SimpleCNNWithBN)        [1, 3, 32, 32]            [1, 10]                   --\n",
       "├─Sequential (conv_block_1)              [1, 3, 32, 32]            [1, 32, 16, 16]           --\n",
       "│    └─Conv2d (0)                        [1, 3, 32, 32]            [1, 32, 32, 32]           896\n",
       "│    └─BatchNorm2d (1)                   [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU (2)                          [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─Conv2d (3)                        [1, 32, 32, 32]           [1, 32, 32, 32]           9,248\n",
       "│    └─BatchNorm2d (4)                   [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU (5)                          [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─MaxPool2d (6)                     [1, 32, 32, 32]           [1, 32, 16, 16]           --\n",
       "├─Sequential (conv_block_2)              [1, 32, 16, 16]           [1, 64, 8, 8]             --\n",
       "│    └─Conv2d (0)                        [1, 32, 16, 16]           [1, 64, 16, 16]           18,496\n",
       "│    └─BatchNorm2d (1)                   [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU (2)                          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─Conv2d (3)                        [1, 64, 16, 16]           [1, 64, 16, 16]           36,928\n",
       "│    └─BatchNorm2d (4)                   [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU (5)                          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─MaxPool2d (6)                     [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
       "├─Sequential (conv_block_3)              [1, 64, 8, 8]             [1, 128, 4, 4]            --\n",
       "│    └─Conv2d (0)                        [1, 64, 8, 8]             [1, 128, 8, 8]            73,856\n",
       "│    └─BatchNorm2d (1)                   [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU (2)                          [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─Conv2d (3)                        [1, 128, 8, 8]            [1, 128, 8, 8]            147,584\n",
       "│    └─BatchNorm2d (4)                   [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU (5)                          [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─MaxPool2d (6)                     [1, 128, 8, 8]            [1, 128, 4, 4]            --\n",
       "├─Sequential (classifier_block)          [1, 128, 4, 4]            [1, 10]                   --\n",
       "│    └─AdaptiveAvgPool2d (0)             [1, 128, 4, 4]            [1, 128, 1, 1]            --\n",
       "│    └─Flatten (1)                       [1, 128, 1, 1]            [1, 128]                  --\n",
       "│    └─Linear (2)                        [1, 128]                  [1, 10]                   1,290\n",
       "===================================================================================================================\n",
       "Total params: 289,194\n",
       "Trainable params: 289,194\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 38.75\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.84\n",
       "Params size (MB): 1.16\n",
       "Estimated Total Size (MB): 3.00\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "NUM_INPUT_CHANNELS = 3\n",
    "\n",
    "class SimpleCNNWithBN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Conv block 1: Two Conv2d layers with 32 filters, followed by BatchNorm and ReLU, then MaxPooling\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=NUM_INPUT_CHANNELS, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # Conv block 2: Two Conv2d layers with 64 filters, followed by BatchNorm and ReLU, then MaxPooling\n",
    "        # padding='same' ensures output size remains the same (introduced in PyTorch 1.8)\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding='same'),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Conv block 3: Two Conv2d layers with 128 filters, followed by BatchNorm and ReLU, then MaxPooling\n",
    "        self.conv_block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        # Classifier block: Global Average Pooling -> Flatten -> Linear layer for final classification\n",
    "        self.classifier_block = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128, out_features=num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = self.classifier_block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate the model with Batch Normalization\n",
    "simple_cnn = SimpleCNNWithBN(num_classes=10)\n",
    "\n",
    "# Print model summary: shows input/output sizes and number of parameters per layer\n",
    "summary(model=simple_cnn, input_size=(1, 3, 32, 32), \n",
    "        col_names=['input_size', 'output_size', 'num_params'], \n",
    "        row_settings=['var_names'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c222f",
   "metadata": {
    "papermill": {
     "duration": 0.005167,
     "end_time": "2025-08-31T04:09:28.782141",
     "exception": false,
     "start_time": "2025-08-31T04:09:28.776974",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Apply a function to create repeated Sequential Container blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "622b9748",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:28.794037Z",
     "iopub.status.busy": "2025-08-31T04:09:28.793487Z",
     "iopub.status.idle": "2025-08-31T04:09:28.814146Z",
     "shell.execute_reply": "2025-08-31T04:09:28.813572Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.027769,
     "end_time": "2025-08-31T04:09:28.815192",
     "exception": false,
     "start_time": "2025-08-31T04:09:28.787423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "SimpleCNNWithBN (SimpleCNNWithBN)        [1, 3, 32, 32]            [1, 10]                   --\n",
       "├─Sequential (conv_block_1)              [1, 3, 32, 32]            [1, 32, 16, 16]           --\n",
       "│    └─Conv2d (0)                        [1, 3, 32, 32]            [1, 32, 32, 32]           896\n",
       "│    └─BatchNorm2d (1)                   [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU (2)                          [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─Conv2d (3)                        [1, 32, 32, 32]           [1, 32, 32, 32]           9,248\n",
       "│    └─BatchNorm2d (4)                   [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU (5)                          [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─MaxPool2d (6)                     [1, 32, 32, 32]           [1, 32, 16, 16]           --\n",
       "├─Sequential (conv_block_2)              [1, 32, 16, 16]           [1, 64, 8, 8]             --\n",
       "│    └─Conv2d (0)                        [1, 32, 16, 16]           [1, 64, 16, 16]           18,496\n",
       "│    └─BatchNorm2d (1)                   [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU (2)                          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─Conv2d (3)                        [1, 64, 16, 16]           [1, 64, 16, 16]           36,928\n",
       "│    └─BatchNorm2d (4)                   [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU (5)                          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─MaxPool2d (6)                     [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
       "├─Sequential (conv_block_3)              [1, 64, 8, 8]             [1, 128, 4, 4]            --\n",
       "│    └─Conv2d (0)                        [1, 64, 8, 8]             [1, 128, 8, 8]            73,856\n",
       "│    └─BatchNorm2d (1)                   [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU (2)                          [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─Conv2d (3)                        [1, 128, 8, 8]            [1, 128, 8, 8]            147,584\n",
       "│    └─BatchNorm2d (4)                   [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU (5)                          [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─MaxPool2d (6)                     [1, 128, 8, 8]            [1, 128, 4, 4]            --\n",
       "├─Sequential (classifier_block)          [1, 128, 4, 4]            [1, 10]                   --\n",
       "│    └─AdaptiveAvgPool2d (0)             [1, 128, 4, 4]            [1, 128, 1, 1]            --\n",
       "│    └─Flatten (1)                       [1, 128, 1, 1]            [1, 128]                  --\n",
       "│    └─Linear (2)                        [1, 128]                  [1, 10]                   1,290\n",
       "===================================================================================================================\n",
       "Total params: 289,194\n",
       "Trainable params: 289,194\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 38.75\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.84\n",
       "Params size (MB): 1.16\n",
       "Estimated Total Size (MB): 3.00\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "NUM_INPUT_CHANNELS = 3\n",
    "\n",
    "class SimpleCNNWithBN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Maintain the same output spatial size as input by using padding=1 in conv.\n",
    "        self.conv_block_1 = self.create_convbn_block(first_channels=3, middle_channels=32, last_channels=32)        \n",
    "        \n",
    "        # Two Conv2d layers with out_channels=64. stride=1 is default, padding='same' introduced in v1.8.\n",
    "        self.conv_block_2 = self.create_convbn_block(first_channels=32, middle_channels=64, last_channels=64)\n",
    "        \n",
    "        # Two Conv2d layers with 128 filters followed by Max Pooling.\n",
    "        self.conv_block_3 = self.create_convbn_block(first_channels=64, middle_channels=128, last_channels=128)\n",
    "        \n",
    "        # Global Average Pooling (GAP) and final classifier layer.\n",
    "        self.classifier_block = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),  # GAP converts feature map to 1x1 per channel\n",
    "            nn.Flatten(),                               # Flatten to feed into Linear layer\n",
    "            nn.Linear(in_features=128, out_features=num_classes)  # Final classification\n",
    "        )\n",
    "\n",
    "    # Function to create repeated Conv -> BatchNorm -> ReLU -> Conv -> BatchNorm -> ReLU -> MaxPool blocks\n",
    "    def create_convbn_block(self, first_channels, middle_channels, last_channels):\n",
    "        conv_bn_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=first_channels, out_channels=middle_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(middle_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=middle_channels, out_channels=last_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(last_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        return conv_bn_block\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x = self.conv_block_3(x)\n",
    "        x = self.classifier_block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Instantiate model and summarize architecture\n",
    "simple_cnn = SimpleCNNWithBN(num_classes=10)\n",
    "\n",
    "summary(model=simple_cnn, input_size=(1, 3, 32, 32), \n",
    "        col_names=['input_size', 'output_size', 'num_params'], \n",
    "        row_settings=['var_names'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd985e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:09:28.826870Z",
     "iopub.status.busy": "2025-08-31T04:09:28.826650Z",
     "iopub.status.idle": "2025-08-31T04:14:41.740919Z",
     "shell.execute_reply": "2025-08-31T04:14:41.739861Z"
    },
    "papermill": {
     "duration": 312.921511,
     "end_time": "2025-08-31T04:14:41.742184",
     "exception": false,
     "start_time": "2025-08-31T04:09:28.820673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.34it/s, Loss=1.23, Accuracy=0.553]\n",
      "Epoch 1 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 249.82it/s, Loss=1.14, Accuracy=0.595]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 1.2296 Train Accuracy: 0.5535 , Val Loss: 1.1428 Val Accuracy: 0.5952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 139.91it/s, Loss=0.822, Accuracy=0.71]\n",
      "Epoch 2 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 251.97it/s, Loss=0.785, Accuracy=0.728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.8223 Train Accuracy: 0.7104 , Val Loss: 0.7853 Val Accuracy: 0.7279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 141.04it/s, Loss=0.665, Accuracy=0.769]\n",
      "Epoch 3 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 240.69it/s, Loss=0.699, Accuracy=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.6648 Train Accuracy: 0.7692 , Val Loss: 0.6990 Val Accuracy: 0.7528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.15it/s, Loss=0.57, Accuracy=0.805]\n",
      "Epoch 4 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 252.80it/s, Loss=0.591, Accuracy=0.792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.5704 Train Accuracy: 0.8051 , Val Loss: 0.5911 Val Accuracy: 0.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 141.66it/s, Loss=0.493, Accuracy=0.829]\n",
      "Epoch 5 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 255.78it/s, Loss=0.597, Accuracy=0.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.4928 Train Accuracy: 0.8291 , Val Loss: 0.5969 Val Accuracy: 0.7915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.98it/s, Loss=0.432, Accuracy=0.85]\n",
      "Epoch 6 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 252.31it/s, Loss=0.51, Accuracy=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.4324 Train Accuracy: 0.8501 , Val Loss: 0.5095 Val Accuracy: 0.8249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 141.35it/s, Loss=0.382, Accuracy=0.868]\n",
      "Epoch 7 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 255.03it/s, Loss=0.707, Accuracy=0.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.3818 Train Accuracy: 0.8677 , Val Loss: 0.7074 Val Accuracy: 0.7659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 141.35it/s, Loss=0.33, Accuracy=0.884]\n",
      "Epoch 8 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 252.08it/s, Loss=0.658, Accuracy=0.79]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.3302 Train Accuracy: 0.8838 , Val Loss: 0.6581 Val Accuracy: 0.7903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.21it/s, Loss=0.288, Accuracy=0.899]\n",
      "Epoch 9 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 246.66it/s, Loss=0.59, Accuracy=0.805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.2885 Train Accuracy: 0.8993 , Val Loss: 0.5899 Val Accuracy: 0.8055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 139.59it/s, Loss=0.247, Accuracy=0.914]\n",
      "Epoch 10 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 255.67it/s, Loss=0.57, Accuracy=0.822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.2470 Train Accuracy: 0.9138 , Val Loss: 0.5698 Val Accuracy: 0.8220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.13it/s, Loss=0.211, Accuracy=0.926]\n",
      "Epoch 11 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 249.11it/s, Loss=0.647, Accuracy=0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.2113 Train Accuracy: 0.9261 , Val Loss: 0.6471 Val Accuracy: 0.8119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 142.45it/s, Loss=0.187, Accuracy=0.935]\n",
      "Epoch 12 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 251.44it/s, Loss=0.565, Accuracy=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.1871 Train Accuracy: 0.9350 , Val Loss: 0.5655 Val Accuracy: 0.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 142.55it/s, Loss=0.157, Accuracy=0.947]\n",
      "Epoch 13 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 251.74it/s, Loss=0.593, Accuracy=0.827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.1570 Train Accuracy: 0.9468 , Val Loss: 0.5934 Val Accuracy: 0.8265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 142.02it/s, Loss=0.142, Accuracy=0.95]\n",
      "Epoch 14 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 236.76it/s, Loss=0.588, Accuracy=0.828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.1417 Train Accuracy: 0.9505 , Val Loss: 0.5876 Val Accuracy: 0.8279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.81it/s, Loss=0.124, Accuracy=0.957]\n",
      "Epoch 15 [Validating]: 100%|██████████| 235/235 [00:01<00:00, 228.28it/s, Loss=0.708, Accuracy=0.809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.1238 Train Accuracy: 0.9569 , Val Loss: 0.7076 Val Accuracy: 0.8093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 141.43it/s, Loss=0.113, Accuracy=0.961]\n",
      "Epoch 16 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 247.86it/s, Loss=0.727, Accuracy=0.812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.1132 Train Accuracy: 0.9611 , Val Loss: 0.7273 Val Accuracy: 0.8117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.82it/s, Loss=0.0952, Accuracy=0.967]\n",
      "Epoch 17 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 251.25it/s, Loss=0.784, Accuracy=0.803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.0952 Train Accuracy: 0.9668 , Val Loss: 0.7845 Val Accuracy: 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 139.83it/s, Loss=0.0901, Accuracy=0.969]\n",
      "Epoch 18 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 248.40it/s, Loss=0.7, Accuracy=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.0901 Train Accuracy: 0.9693 , Val Loss: 0.6999 Val Accuracy: 0.8247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 139.01it/s, Loss=0.084, Accuracy=0.971]\n",
      "Epoch 19 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 240.61it/s, Loss=0.629, Accuracy=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.0840 Train Accuracy: 0.9712 , Val Loss: 0.6292 Val Accuracy: 0.8364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 138.88it/s, Loss=0.0763, Accuracy=0.974]\n",
      "Epoch 20 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 250.70it/s, Loss=0.674, Accuracy=0.829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.0763 Train Accuracy: 0.9736 , Val Loss: 0.6739 Val Accuracy: 0.8293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 136.03it/s, Loss=0.0775, Accuracy=0.973]\n",
      "Epoch 21 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 253.20it/s, Loss=0.798, Accuracy=0.813]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.0775 Train Accuracy: 0.9726 , Val Loss: 0.7978 Val Accuracy: 0.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.69it/s, Loss=0.0673, Accuracy=0.978]\n",
      "Epoch 22 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 249.87it/s, Loss=0.71, Accuracy=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.0673 Train Accuracy: 0.9776 , Val Loss: 0.7105 Val Accuracy: 0.8393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.06it/s, Loss=0.0677, Accuracy=0.977]\n",
      "Epoch 23 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 251.64it/s, Loss=0.746, Accuracy=0.829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.0677 Train Accuracy: 0.9766 , Val Loss: 0.7465 Val Accuracy: 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 139.54it/s, Loss=0.0629, Accuracy=0.978]\n",
      "Epoch 24 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 247.69it/s, Loss=0.679, Accuracy=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.0629 Train Accuracy: 0.9780 , Val Loss: 0.6788 Val Accuracy: 0.8351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 141.55it/s, Loss=0.0499, Accuracy=0.984]\n",
      "Epoch 25 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 246.13it/s, Loss=0.738, Accuracy=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.0499 Train Accuracy: 0.9840 , Val Loss: 0.7376 Val Accuracy: 0.8252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.04it/s, Loss=0.0636, Accuracy=0.978]\n",
      "Epoch 26 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 247.59it/s, Loss=0.81, Accuracy=0.815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.0636 Train Accuracy: 0.9780 , Val Loss: 0.8104 Val Accuracy: 0.8145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 140.28it/s, Loss=0.0557, Accuracy=0.981]\n",
      "Epoch 27 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 247.36it/s, Loss=0.675, Accuracy=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.0557 Train Accuracy: 0.9807 , Val Loss: 0.6746 Val Accuracy: 0.8391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 141.65it/s, Loss=0.0475, Accuracy=0.984]\n",
      "Epoch 28 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 246.58it/s, Loss=0.726, Accuracy=0.836]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.0475 Train Accuracy: 0.9841 , Val Loss: 0.7265 Val Accuracy: 0.8357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 141.58it/s, Loss=0.0543, Accuracy=0.981]\n",
      "Epoch 29 [Validating]: 100%|██████████| 235/235 [00:01<00:00, 229.58it/s, Loss=0.73, Accuracy=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.0543 Train Accuracy: 0.9810 , Val Loss: 0.7295 Val Accuracy: 0.8401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 139.46it/s, Loss=0.0457, Accuracy=0.984]\n",
      "Epoch 30 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 247.82it/s, Loss=0.771, Accuracy=0.83]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.0457 Train Accuracy: 0.9844 , Val Loss: 0.7710 Val Accuracy: 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "NUM_INPUT_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "model = SimpleCNNWithBN(num_classes=NUM_CLASSES)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "       train_loader=tr_loader, val_loader=val_loader, device=device)\n",
    "\n",
    "history = trainer.fit(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd01074",
   "metadata": {
    "papermill": {
     "duration": 0.219661,
     "end_time": "2025-08-31T04:14:42.181632",
     "exception": false,
     "start_time": "2025-08-31T04:14:41.961971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Predict with Predictor class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d315c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:14:42.623472Z",
     "iopub.status.busy": "2025-08-31T04:14:42.623173Z",
     "iopub.status.idle": "2025-08-31T04:14:42.630908Z",
     "shell.execute_reply": "2025-08-31T04:14:42.630354Z"
    },
    "papermill": {
     "duration": 0.232453,
     "end_time": "2025-08-31T04:14:42.631987",
     "exception": false,
     "start_time": "2025-08-31T04:14:42.399534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        eval_metric = 0.0\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "\n",
    "        with tqdm(total=len(loader), desc=f\"[Evaluating]\", leave=True) as progress_bar:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = targets.to(self.device)\n",
    "                    pred = self.model(inputs)\n",
    "\n",
    "                    num_correct = (pred.argmax(-1) == targets).sum().item()\n",
    "                    num_total += inputs.shape[0]\n",
    "                    accu_num_correct += num_correct\n",
    "                    eval_metric = accu_num_correct / num_total\n",
    "\n",
    "                    progress_bar.update(1)\n",
    "                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:\n",
    "                        progress_bar.set_postfix({\"Accuracy\": eval_metric})\n",
    "        \n",
    "        return eval_metric\n",
    "\n",
    "    def predict_proba(self, inputs):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs = inputs.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            pred_proba = F.softmax(outputs, dim=-1) \n",
    "\n",
    "        return pred_proba\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        pred_proba = self.predict_proba(inputs)\n",
    "        pred_class = torch.argmax(pred_proba, dim=-1)\n",
    "\n",
    "        return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53619e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:14:43.126390Z",
     "iopub.status.busy": "2025-08-31T04:14:43.126129Z",
     "iopub.status.idle": "2025-08-31T04:14:44.385716Z",
     "shell.execute_reply": "2025-08-31T04:14:44.384591Z"
    },
    "papermill": {
     "duration": 1.482276,
     "end_time": "2025-08-31T04:14:44.387570",
     "exception": false,
     "start_time": "2025-08-31T04:14:42.905294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Evaluating]: 100%|██████████| 313/313 [00:01<00:00, 250.71it/s, Accuracy=0.828]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset evaluation:0.8279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model = trainer.get_trained_model()\n",
    "\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3d32c",
   "metadata": {
    "papermill": {
     "duration": 0.220244,
     "end_time": "2025-08-31T04:14:44.843551",
     "exception": false,
     "start_time": "2025-08-31T04:14:44.623307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dropout\n",
    "\n",
    "* PyTorch provides `nn.Dropout(p)` layer for implementing dropout.\n",
    "* `nn.Dropout(p)` randomly sets elements of the input tensor to 0 with probability `p`. The remaining elements are scaled by a factor of `1/(1-p)` to maintain the expected sum of activations.\n",
    "\n",
    "**Why use Dropout:**\n",
    "Dropout is a regularization technique that helps prevent overfitting by randomly \"dropping\" units during training. This forces the network to not rely too heavily on any single neuron, promoting redundancy and improving generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbdd8a10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:14:45.338031Z",
     "iopub.status.busy": "2025-08-31T04:14:45.337704Z",
     "iopub.status.idle": "2025-08-31T04:14:45.357117Z",
     "shell.execute_reply": "2025-08-31T04:14:45.356251Z"
    },
    "papermill": {
     "duration": 0.296493,
     "end_time": "2025-08-31T04:14:45.358248",
     "exception": false,
     "start_time": "2025-08-31T04:14:45.061755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Tensor:\n",
      "tensor([[ 0.5081, -0.5714,  0.3153,  0.1583,  0.3019,  0.7540,  0.2886,  0.0384,\n",
      "         -0.3487, -0.8386],\n",
      "        [-0.4652, -1.4711,  0.5225, -1.7037,  0.1465, -0.8918, -0.3246, -0.4334,\n",
      "          0.8285,  0.8772],\n",
      "        [-1.0809, -1.2962,  1.5066, -1.0503,  1.5361,  0.4981, -1.1635, -0.8305,\n",
      "         -1.8033, -0.7408],\n",
      "        [-1.1327,  0.1192, -1.1528,  0.4611,  0.3449, -0.7675, -1.0406, -0.1629,\n",
      "          0.3756,  0.7246]])\n",
      "Number of zeros in input_tensor: 0\n",
      "Output Tensor:\n",
      "tensor([[ 0.0000, -0.7618,  0.4203,  0.2111,  0.4025,  0.0000,  0.3848,  0.0512,\n",
      "         -0.4649, -1.1181],\n",
      "        [-0.6203, -1.9614,  0.6967, -2.2716,  0.1953, -0.0000, -0.4328, -0.0000,\n",
      "          1.1047,  1.1696],\n",
      "        [-1.4413, -1.7282,  0.0000, -0.0000,  2.0481,  0.6641, -1.5513, -1.1074,\n",
      "         -0.0000, -0.9878],\n",
      "        [-1.5103,  0.1589, -1.5371,  0.6148,  0.4599, -0.0000, -1.3874, -0.2172,\n",
      "          0.0000,  0.9662]])\n",
      "Number of zeros in output tensor: 9\n",
      "Percentage of zeros: 22.50%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "input_tensor = torch.randn(4, 10)\n",
    "print(f\"input Tensor:\\n{input_tensor}\")\n",
    "\n",
    "# Count the number of zeros in the original input tensor\n",
    "num_zeros = torch.sum(input_tensor == 0).item()\n",
    "print(f\"Number of zeros in input_tensor: {num_zeros}\")\n",
    "\n",
    "# Define a Dropout layer with p=0.25\n",
    "dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "# Apply the Dropout layer\n",
    "output_tensor = dropout(input_tensor)\n",
    "\n",
    "# Count the number of elements that became zero after applying Dropout\n",
    "num_zeros = torch.sum(output_tensor == 0).item()\n",
    "\n",
    "# Get the total number of elements in the output tensor\n",
    "total_elements = output_tensor.numel()\n",
    "\n",
    "# Calculate the percentage of zeros in the output tensor\n",
    "percentage_zeros = (num_zeros / total_elements) * 100\n",
    "\n",
    "print(f\"Output Tensor:\\n{output_tensor}\")\n",
    "print(f\"Number of zeros in output tensor: {num_zeros}\")\n",
    "print(f\"Percentage of zeros: {percentage_zeros:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d07e0",
   "metadata": {
    "papermill": {
     "duration": 0.218142,
     "end_time": "2025-08-31T04:14:45.799071",
     "exception": false,
     "start_time": "2025-08-31T04:14:45.580929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Connecting the Classifier with Dropout and Linear Layer\n",
    "\n",
    "* PyTorch allows modifying a model dynamically by connecting only specific submodules of an existing model.\n",
    "* The model structure can be modified so that only the classification block applies Dropout before the Linear layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac7fbf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:14:46.274897Z",
     "iopub.status.busy": "2025-08-31T04:14:46.274591Z",
     "iopub.status.idle": "2025-08-31T04:14:46.285971Z",
     "shell.execute_reply": "2025-08-31T04:14:46.285304Z"
    },
    "papermill": {
     "duration": 0.265999,
     "end_time": "2025-08-31T04:14:46.287085",
     "exception": false,
     "start_time": "2025-08-31T04:14:46.021086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (1): Flatten(start_dim=1, end_dim=-1)\n",
       "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "simple_cnnbn_base = SimpleCNNWithBN(num_classes=NUM_CLASSES)\n",
    "simple_cnnbn_base.classifier_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8378cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:14:46.786509Z",
     "iopub.status.busy": "2025-08-31T04:14:46.786261Z",
     "iopub.status.idle": "2025-08-31T04:14:46.797032Z",
     "shell.execute_reply": "2025-08-31T04:14:46.796224Z"
    },
    "papermill": {
     "duration": 0.235851,
     "end_time": "2025-08-31T04:14:46.798165",
     "exception": false,
     "start_time": "2025-08-31T04:14:46.562314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Dropout(p=0.5, inplace=False)\n",
      "  (2): Linear(in_features=2048, out_features=300, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Dropout(p=0.3, inplace=False)\n",
      "  (5): Linear(in_features=300, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "do_classifier_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=128*4*4, out_features=300),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(in_features=300, out_features=10),\n",
    "        )\n",
    "simple_cnnbn_base.classifier_block = do_classifier_block\n",
    "print(simple_cnnbn_base.classifier_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c34a68e2",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-31T04:14:47.250143Z",
     "iopub.status.busy": "2025-08-31T04:14:47.249900Z",
     "iopub.status.idle": "2025-08-31T04:14:47.263990Z",
     "shell.execute_reply": "2025-08-31T04:14:47.263370Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.242645,
     "end_time": "2025-08-31T04:14:47.265132",
     "exception": false,
     "start_time": "2025-08-31T04:14:47.022487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "SimpleCNNWithBN (SimpleCNNWithBN)        [1, 3, 32, 32]            [1, 10]                   --\n",
       "├─Sequential (conv_block_1)              [1, 3, 32, 32]            [1, 32, 16, 16]           --\n",
       "│    └─Conv2d (0)                        [1, 3, 32, 32]            [1, 32, 32, 32]           896\n",
       "│    └─BatchNorm2d (1)                   [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU (2)                          [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─Conv2d (3)                        [1, 32, 32, 32]           [1, 32, 32, 32]           9,248\n",
       "│    └─BatchNorm2d (4)                   [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU (5)                          [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─MaxPool2d (6)                     [1, 32, 32, 32]           [1, 32, 16, 16]           --\n",
       "├─Sequential (conv_block_2)              [1, 32, 16, 16]           [1, 64, 8, 8]             --\n",
       "│    └─Conv2d (0)                        [1, 32, 16, 16]           [1, 64, 16, 16]           18,496\n",
       "│    └─BatchNorm2d (1)                   [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU (2)                          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─Conv2d (3)                        [1, 64, 16, 16]           [1, 64, 16, 16]           36,928\n",
       "│    └─BatchNorm2d (4)                   [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU (5)                          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─MaxPool2d (6)                     [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
       "├─Sequential (conv_block_3)              [1, 64, 8, 8]             [1, 128, 4, 4]            --\n",
       "│    └─Conv2d (0)                        [1, 64, 8, 8]             [1, 128, 8, 8]            73,856\n",
       "│    └─BatchNorm2d (1)                   [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU (2)                          [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─Conv2d (3)                        [1, 128, 8, 8]            [1, 128, 8, 8]            147,584\n",
       "│    └─BatchNorm2d (4)                   [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU (5)                          [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─MaxPool2d (6)                     [1, 128, 8, 8]            [1, 128, 4, 4]            --\n",
       "├─Sequential (classifier_block)          [1, 128, 4, 4]            [1, 10]                   --\n",
       "│    └─Flatten (0)                       [1, 128, 4, 4]            [1, 2048]                 --\n",
       "│    └─Dropout (1)                       [1, 2048]                 [1, 2048]                 --\n",
       "│    └─Linear (2)                        [1, 2048]                 [1, 300]                  614,700\n",
       "│    └─ReLU (3)                          [1, 300]                  [1, 300]                  --\n",
       "│    └─Dropout (4)                       [1, 300]                  [1, 300]                  --\n",
       "│    └─Linear (5)                        [1, 300]                  [1, 10]                   3,010\n",
       "===================================================================================================================\n",
       "Total params: 905,614\n",
       "Trainable params: 905,614\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 39.37\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.84\n",
       "Params size (MB): 3.62\n",
       "Estimated Total Size (MB): 5.47\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=simple_cnnbn_base, input_size=(1, 3, 32, 32), \n",
    "        col_names=['input_size', 'output_size', 'num_params'], \n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37e7e24a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:14:47.770596Z",
     "iopub.status.busy": "2025-08-31T04:14:47.770330Z",
     "iopub.status.idle": "2025-08-31T04:14:47.795175Z",
     "shell.execute_reply": "2025-08-31T04:14:47.794407Z"
    },
    "papermill": {
     "duration": 0.308713,
     "end_time": "2025-08-31T04:14:47.796418",
     "exception": false,
     "start_time": "2025-08-31T04:14:47.487705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "SimpleCNNWithBN (SimpleCNNWithBN)        [1, 3, 32, 32]            [1, 10]                   --\n",
       "├─Sequential (conv_block_1)              [1, 3, 32, 32]            [1, 32, 16, 16]           --\n",
       "│    └─Conv2d (0)                        [1, 3, 32, 32]            [1, 32, 32, 32]           896\n",
       "│    └─BatchNorm2d (1)                   [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU (2)                          [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─Conv2d (3)                        [1, 32, 32, 32]           [1, 32, 32, 32]           9,248\n",
       "│    └─BatchNorm2d (4)                   [1, 32, 32, 32]           [1, 32, 32, 32]           64\n",
       "│    └─ReLU (5)                          [1, 32, 32, 32]           [1, 32, 32, 32]           --\n",
       "│    └─MaxPool2d (6)                     [1, 32, 32, 32]           [1, 32, 16, 16]           --\n",
       "├─Sequential (conv_block_2)              [1, 32, 16, 16]           [1, 64, 8, 8]             --\n",
       "│    └─Conv2d (0)                        [1, 32, 16, 16]           [1, 64, 16, 16]           18,496\n",
       "│    └─BatchNorm2d (1)                   [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU (2)                          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─Conv2d (3)                        [1, 64, 16, 16]           [1, 64, 16, 16]           36,928\n",
       "│    └─BatchNorm2d (4)                   [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
       "│    └─ReLU (5)                          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
       "│    └─MaxPool2d (6)                     [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
       "├─Sequential (conv_block_3)              [1, 64, 8, 8]             [1, 128, 4, 4]            --\n",
       "│    └─Conv2d (0)                        [1, 64, 8, 8]             [1, 128, 8, 8]            73,856\n",
       "│    └─BatchNorm2d (1)                   [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU (2)                          [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─Conv2d (3)                        [1, 128, 8, 8]            [1, 128, 8, 8]            147,584\n",
       "│    └─BatchNorm2d (4)                   [1, 128, 8, 8]            [1, 128, 8, 8]            256\n",
       "│    └─ReLU (5)                          [1, 128, 8, 8]            [1, 128, 8, 8]            --\n",
       "│    └─MaxPool2d (6)                     [1, 128, 8, 8]            [1, 128, 4, 4]            --\n",
       "├─Sequential (classifier_block)          [1, 128, 4, 4]            [1, 10]                   --\n",
       "│    └─Flatten (0)                       [1, 128, 4, 4]            [1, 2048]                 --\n",
       "│    └─Dropout (1)                       [1, 2048]                 [1, 2048]                 --\n",
       "│    └─Linear (2)                        [1, 2048]                 [1, 300]                  614,700\n",
       "│    └─ReLU (3)                          [1, 300]                  [1, 300]                  --\n",
       "│    └─Dropout (4)                       [1, 300]                  [1, 300]                  --\n",
       "│    └─Linear (5)                        [1, 300]                  [1, 10]                   3,010\n",
       "===================================================================================================================\n",
       "Total params: 905,614\n",
       "Trainable params: 905,614\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 39.37\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.84\n",
       "Params size (MB): 3.62\n",
       "Estimated Total Size (MB): 5.47\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_do_classifier_block(first_features, second_features, first_dos, second_dos, num_classes=10):\n",
    "    return nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(p=first_dos),\n",
    "            nn.Linear(in_features=first_features, out_features=second_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=second_dos),\n",
    "            nn.Linear(in_features=second_features, out_features=num_classes),\n",
    "        )\n",
    "\n",
    "simple_cnnbn_base = SimpleCNNWithBN(num_classes=NUM_CLASSES)\n",
    "do_classifier_block = create_do_classifier_block(first_features=128*4*4, second_features=300,\n",
    "                                                 first_dos=0.5, second_dos=0.3, num_classes=10)\n",
    "simple_cnnbn_base.classifier_block = do_classifier_block\n",
    "\n",
    "summary(model=simple_cnnbn_base, input_size=(1, 3, 32, 32), \n",
    "        col_names=['input_size', 'output_size', 'num_params'], \n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fe5d1ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:14:48.248229Z",
     "iopub.status.busy": "2025-08-31T04:14:48.247963Z",
     "iopub.status.idle": "2025-08-31T04:20:15.052174Z",
     "shell.execute_reply": "2025-08-31T04:20:15.051061Z"
    },
    "papermill": {
     "duration": 327.030331,
     "end_time": "2025-08-31T04:20:15.053618",
     "exception": false,
     "start_time": "2025-08-31T04:14:48.023287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Training..]: 100%|██████████| 1329/1329 [00:10<00:00, 132.59it/s, Loss=1.37, Accuracy=0.506]\n",
      "Epoch 1 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 244.22it/s, Loss=1.03, Accuracy=0.618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 1.3663 Train Accuracy: 0.5058 , Val Loss: 1.0258 Val Accuracy: 0.6177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.45it/s, Loss=0.972, Accuracy=0.662]\n",
      "Epoch 2 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 245.14it/s, Loss=0.89, Accuracy=0.685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.9719 Train Accuracy: 0.6621 , Val Loss: 0.8900 Val Accuracy: 0.6855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Training..]: 100%|██████████| 1329/1329 [00:10<00:00, 132.50it/s, Loss=0.83, Accuracy=0.71]\n",
      "Epoch 3 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 243.10it/s, Loss=0.752, Accuracy=0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.8301 Train Accuracy: 0.7103 , Val Loss: 0.7519 Val Accuracy: 0.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.78it/s, Loss=0.743, Accuracy=0.745]\n",
      "Epoch 4 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 246.09it/s, Loss=0.767, Accuracy=0.735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.7426 Train Accuracy: 0.7453 , Val Loss: 0.7667 Val Accuracy: 0.7347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 135.10it/s, Loss=0.665, Accuracy=0.772]\n",
      "Epoch 5 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 248.96it/s, Loss=0.642, Accuracy=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.6646 Train Accuracy: 0.7724 , Val Loss: 0.6424 Val Accuracy: 0.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.87it/s, Loss=0.6, Accuracy=0.793]\n",
      "Epoch 6 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 247.63it/s, Loss=0.599, Accuracy=0.793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.6004 Train Accuracy: 0.7934 , Val Loss: 0.5989 Val Accuracy: 0.7935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.72it/s, Loss=0.55, Accuracy=0.812]\n",
      "Epoch 7 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 236.38it/s, Loss=0.573, Accuracy=0.803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.5501 Train Accuracy: 0.8116 , Val Loss: 0.5727 Val Accuracy: 0.8035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Training..]: 100%|██████████| 1329/1329 [00:10<00:00, 132.06it/s, Loss=0.504, Accuracy=0.83]\n",
      "Epoch 8 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 245.70it/s, Loss=0.523, Accuracy=0.821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.5040 Train Accuracy: 0.8300 , Val Loss: 0.5232 Val Accuracy: 0.8215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 132.92it/s, Loss=0.466, Accuracy=0.841]\n",
      "Epoch 9 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 248.49it/s, Loss=0.543, Accuracy=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.4657 Train Accuracy: 0.8409 , Val Loss: 0.5428 Val Accuracy: 0.8171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 134.29it/s, Loss=0.425, Accuracy=0.856]\n",
      "Epoch 10 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 248.23it/s, Loss=0.54, Accuracy=0.814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.4253 Train Accuracy: 0.8557 , Val Loss: 0.5402 Val Accuracy: 0.8139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 134.05it/s, Loss=0.399, Accuracy=0.864]\n",
      "Epoch 11 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 245.90it/s, Loss=0.505, Accuracy=0.829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.3994 Train Accuracy: 0.8636 , Val Loss: 0.5050 Val Accuracy: 0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.56it/s, Loss=0.366, Accuracy=0.874]\n",
      "Epoch 12 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 250.94it/s, Loss=0.522, Accuracy=0.832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.3661 Train Accuracy: 0.8744 , Val Loss: 0.5222 Val Accuracy: 0.8323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 134.89it/s, Loss=0.344, Accuracy=0.882]\n",
      "Epoch 13 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 249.33it/s, Loss=0.5, Accuracy=0.833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.3437 Train Accuracy: 0.8820 , Val Loss: 0.5004 Val Accuracy: 0.8327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.80it/s, Loss=0.325, Accuracy=0.888]\n",
      "Epoch 14 [Validating]: 100%|██████████| 235/235 [00:01<00:00, 229.02it/s, Loss=0.539, Accuracy=0.825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.3252 Train Accuracy: 0.8876 , Val Loss: 0.5385 Val Accuracy: 0.8255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 135.18it/s, Loss=0.301, Accuracy=0.898]\n",
      "Epoch 15 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 238.78it/s, Loss=0.511, Accuracy=0.838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.3009 Train Accuracy: 0.8975 , Val Loss: 0.5109 Val Accuracy: 0.8377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.95it/s, Loss=0.279, Accuracy=0.904]\n",
      "Epoch 16 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 245.03it/s, Loss=0.499, Accuracy=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.2792 Train Accuracy: 0.9044 , Val Loss: 0.4989 Val Accuracy: 0.8399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.89it/s, Loss=0.262, Accuracy=0.908]\n",
      "Epoch 17 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 244.30it/s, Loss=0.493, Accuracy=0.843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.2620 Train Accuracy: 0.9085 , Val Loss: 0.4932 Val Accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.45it/s, Loss=0.249, Accuracy=0.914]\n",
      "Epoch 18 [Validating]: 100%|██████████| 235/235 [00:01<00:00, 232.58it/s, Loss=0.498, Accuracy=0.841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.2491 Train Accuracy: 0.9140 , Val Loss: 0.4979 Val Accuracy: 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 134.22it/s, Loss=0.236, Accuracy=0.919]\n",
      "Epoch 19 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 244.52it/s, Loss=0.478, Accuracy=0.851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.2359 Train Accuracy: 0.9194 , Val Loss: 0.4782 Val Accuracy: 0.8515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [Training..]: 100%|██████████| 1329/1329 [00:10<00:00, 132.89it/s, Loss=0.218, Accuracy=0.925]\n",
      "Epoch 20 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 244.74it/s, Loss=0.55, Accuracy=0.845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.2182 Train Accuracy: 0.9249 , Val Loss: 0.5497 Val Accuracy: 0.8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.96it/s, Loss=0.213, Accuracy=0.925]\n",
      "Epoch 21 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 242.98it/s, Loss=0.571, Accuracy=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.2132 Train Accuracy: 0.9251 , Val Loss: 0.5712 Val Accuracy: 0.8309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 134.76it/s, Loss=0.204, Accuracy=0.93]\n",
      "Epoch 22 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 243.06it/s, Loss=0.525, Accuracy=0.848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.2039 Train Accuracy: 0.9304 , Val Loss: 0.5253 Val Accuracy: 0.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.54it/s, Loss=0.2, Accuracy=0.932]\n",
      "Epoch 23 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 246.84it/s, Loss=0.547, Accuracy=0.842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.1998 Train Accuracy: 0.9319 , Val Loss: 0.5466 Val Accuracy: 0.8417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.33it/s, Loss=0.186, Accuracy=0.935]\n",
      "Epoch 24 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 247.36it/s, Loss=0.55, Accuracy=0.845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.1861 Train Accuracy: 0.9355 , Val Loss: 0.5500 Val Accuracy: 0.8451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 134.29it/s, Loss=0.178, Accuracy=0.938]\n",
      "Epoch 25 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 245.37it/s, Loss=0.57, Accuracy=0.844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.1778 Train Accuracy: 0.9380 , Val Loss: 0.5696 Val Accuracy: 0.8441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 133.82it/s, Loss=0.171, Accuracy=0.942]\n",
      "Epoch 26 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 239.33it/s, Loss=0.55, Accuracy=0.848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.1713 Train Accuracy: 0.9423 , Val Loss: 0.5501 Val Accuracy: 0.8483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 136.02it/s, Loss=0.163, Accuracy=0.944]\n",
      "Epoch 27 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 246.23it/s, Loss=0.574, Accuracy=0.846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.1632 Train Accuracy: 0.9445 , Val Loss: 0.5741 Val Accuracy: 0.8457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 134.76it/s, Loss=0.153, Accuracy=0.947]\n",
      "Epoch 28 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 236.27it/s, Loss=0.55, Accuracy=0.853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.1534 Train Accuracy: 0.9474 , Val Loss: 0.5497 Val Accuracy: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 134.75it/s, Loss=0.152, Accuracy=0.948]\n",
      "Epoch 29 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 242.08it/s, Loss=0.593, Accuracy=0.841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.1521 Train Accuracy: 0.9482 , Val Loss: 0.5933 Val Accuracy: 0.8405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 [Training..]: 100%|██████████| 1329/1329 [00:09<00:00, 135.24it/s, Loss=0.147, Accuracy=0.951]\n",
      "Epoch 30 [Validating]: 100%|██████████| 235/235 [00:00<00:00, 237.64it/s, Loss=0.588, Accuracy=0.843]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.1465 Train Accuracy: 0.9507 , Val Loss: 0.5881 Val Accuracy: 0.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "NUM_INPUT_CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "model = SimpleCNNWithBN(num_classes=NUM_CLASSES)\n",
    "do_classifier_block = create_do_classifier_block(first_features=128*4*4, second_features=300,\n",
    "                                                 first_dos=0.5, second_dos=0.3, num_classes=10)\n",
    "model.classifier_block = do_classifier_block\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "       train_loader=tr_loader, val_loader=val_loader, device=device)\n",
    " \n",
    "history = trainer.fit(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94e9fdbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T04:20:16.004602Z",
     "iopub.status.busy": "2025-08-31T04:20:16.004306Z",
     "iopub.status.idle": "2025-08-31T04:20:17.264725Z",
     "shell.execute_reply": "2025-08-31T04:20:17.263655Z"
    },
    "papermill": {
     "duration": 1.765512,
     "end_time": "2025-08-31T04:20:17.266019",
     "exception": false,
     "start_time": "2025-08-31T04:20:15.500507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Evaluating]: 100%|██████████| 313/313 [00:01<00:00, 250.20it/s, Accuracy=0.844]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset evaluation:0.8442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model = trainer.get_trained_model()\n",
    "\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f38ab55",
   "metadata": {
    "papermill": {
     "duration": 0.443301,
     "end_time": "2025-08-31T04:20:18.154412",
     "exception": false,
     "start_time": "2025-08-31T04:20:17.711111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 672.067992,
   "end_time": "2025-08-31T04:20:20.272909",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-31T04:09:08.204917",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
