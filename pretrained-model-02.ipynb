{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1265ecac",
   "metadata": {
    "papermill": {
     "duration": 0.003434,
     "end_time": "2025-08-31T18:41:27.699660",
     "exception": false,
     "start_time": "2025-08-31T18:41:27.696226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Using timm (torch image model)\n",
    "\n",
    "* It can be installed with `pip install timm`.\n",
    "* Already installed in Kaggle kernels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67fa4ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:27.705777Z",
     "iopub.status.busy": "2025-08-31T18:41:27.705556Z",
     "iopub.status.idle": "2025-08-31T18:41:40.386162Z",
     "shell.execute_reply": "2025-08-31T18:41:40.385487Z"
    },
    "papermill": {
     "duration": 12.684916,
     "end_time": "2025-08-31T18:41:40.387347",
     "exception": false,
     "start_time": "2025-08-31T18:41:27.702431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet50.a1_in1k',\n",
       " 'resnet50.a1h_in1k',\n",
       " 'resnet50.a2_in1k',\n",
       " 'resnet50.a3_in1k',\n",
       " 'resnet50.am_in1k',\n",
       " 'resnet50.b1k_in1k',\n",
       " 'resnet50.b2k_in1k',\n",
       " 'resnet50.bt_in1k',\n",
       " 'resnet50.c1_in1k',\n",
       " 'resnet50.c2_in1k',\n",
       " 'resnet50.d_in1k',\n",
       " 'resnet50.fb_ssl_yfcc100m_ft_in1k',\n",
       " 'resnet50.fb_swsl_ig1b_ft_in1k',\n",
       " 'resnet50.gluon_in1k',\n",
       " 'resnet50.ra_in1k',\n",
       " 'resnet50.ram_in1k',\n",
       " 'resnet50.tv2_in1k',\n",
       " 'resnet50.tv_in1k']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "timm.list_models(filter='resnet50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661e702b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:40.394475Z",
     "iopub.status.busy": "2025-08-31T18:41:40.393781Z",
     "iopub.status.idle": "2025-08-31T18:41:41.456501Z",
     "shell.execute_reply": "2025-08-31T18:41:41.455864Z"
    },
    "papermill": {
     "duration": 1.067722,
     "end_time": "2025-08-31T18:41:41.458186",
     "exception": false,
     "start_time": "2025-08-31T18:41:40.390464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577f9e08821e4c4eba9864914390636f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# timm includes model names with model_name.tag, where the tag indicates which dataset the model was trained on (roughly).\n",
    "# In timm.create_model(), pass the desired model as the model_name argument. If pretrained=True, pretrained weights are loaded.\n",
    "# Additionally, if num_classes is specified, the final classifier layer's output is automatically adjusted to match num_classes.\n",
    "timm_model_01 = timm.create_model(model_name='resnet50.a1_in1k', pretrained=True, num_classes=10)\n",
    "print(timm_model_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc77e8d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:41.466178Z",
     "iopub.status.busy": "2025-08-31T18:41:41.465968Z",
     "iopub.status.idle": "2025-08-31T18:41:41.470470Z",
     "shell.execute_reply": "2025-08-31T18:41:41.469864Z"
    },
    "papermill": {
     "duration": 0.009338,
     "end_time": "2025-08-31T18:41:41.471507",
     "exception": false,
     "start_time": "2025-08-31T18:41:41.462169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth',\n",
       " 'hf_hub_id': 'timm/resnet50.a1_in1k',\n",
       " 'architecture': 'resnet50',\n",
       " 'tag': 'a1_in1k',\n",
       " 'custom_load': False,\n",
       " 'input_size': (3, 224, 224),\n",
       " 'test_input_size': (3, 288, 288),\n",
       " 'fixed_input_size': False,\n",
       " 'interpolation': 'bicubic',\n",
       " 'crop_pct': 0.95,\n",
       " 'test_crop_pct': 1.0,\n",
       " 'crop_mode': 'center',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'num_classes': 1000,\n",
       " 'pool_size': (7, 7),\n",
       " 'first_conv': 'conv1',\n",
       " 'classifier': 'fc',\n",
       " 'origin_url': 'https://github.com/huggingface/pytorch-image-models',\n",
       " 'paper_ids': 'arXiv:2110.00476'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm_model_01.pretrained_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef66ab6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:41.478663Z",
     "iopub.status.busy": "2025-08-31T18:41:41.478455Z",
     "iopub.status.idle": "2025-08-31T18:41:41.943008Z",
     "shell.execute_reply": "2025-08-31T18:41:41.942184Z"
    },
    "papermill": {
     "duration": 0.469365,
     "end_time": "2025-08-31T18:41:41.944273",
     "exception": false,
     "start_time": "2025-08-31T18:41:41.474908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet50_a1_0-14fe96d1.pth', 'hf_hub_id': 'timm/resnet50.a1_in1k', 'architecture': 'resnet50', 'tag': 'a1_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'test_input_size': (3, 288, 288), 'fixed_input_size': False, 'interpolation': 'bicubic', 'crop_pct': 0.95, 'test_crop_pct': 1.0, 'crop_mode': 'center', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'num_classes': 1000, 'pool_size': (7, 7), 'first_conv': 'conv1', 'classifier': 'fc', 'origin_url': 'https://github.com/huggingface/pytorch-image-models', 'paper_ids': 'arXiv:2110.00476'}\n"
     ]
    }
   ],
   "source": [
    "# You can also set the model_name without a tag value. \n",
    "# Using pretrained_cfg, you can check exactly which pretrained model configuration was applied.\n",
    "timm_model_02 = timm.create_model(model_name='resnet50', pretrained=True, num_classes=10)\n",
    "print(timm_model_02.pretrained_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2648f15c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:41.952005Z",
     "iopub.status.busy": "2025-08-31T18:41:41.951759Z",
     "iopub.status.idle": "2025-08-31T18:41:41.955896Z",
     "shell.execute_reply": "2025-08-31T18:41:41.955358Z"
    },
    "papermill": {
     "duration": 0.009096,
     "end_time": "2025-08-31T18:41:41.956945",
     "exception": false,
     "start_time": "2025-08-31T18:41:41.947849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=10, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm_model_02.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab3e9b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:41.964449Z",
     "iopub.status.busy": "2025-08-31T18:41:41.964225Z",
     "iopub.status.idle": "2025-08-31T18:41:41.968557Z",
     "shell.execute_reply": "2025-08-31T18:41:41.967846Z"
    },
    "papermill": {
     "duration": 0.009305,
     "end_time": "2025-08-31T18:41:41.969637",
     "exception": false,
     "start_time": "2025-08-31T18:41:41.960332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2048, out_features=10, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm_model_02.get_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f9959",
   "metadata": {
    "papermill": {
     "duration": 0.003185,
     "end_time": "2025-08-31T18:41:41.976265",
     "exception": false,
     "start_time": "2025-08-31T18:41:41.973080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Extract only the Feature Extractor part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1371a1b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:41.983890Z",
     "iopub.status.busy": "2025-08-31T18:41:41.983632Z",
     "iopub.status.idle": "2025-08-31T18:41:41.989605Z",
     "shell.execute_reply": "2025-08-31T18:41:41.988722Z"
    },
    "papermill": {
     "duration": 0.011558,
     "end_time": "2025-08-31T18:41:41.991137",
     "exception": false,
     "start_time": "2025-08-31T18:41:41.979579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "num_in_features = timm_model_02.fc.in_features\n",
    "timm_model_02.fc = nn.Linear(in_features=num_in_features, out_features=NUM_CLASSES)\n",
    "print(timm_model_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155df7db",
   "metadata": {
    "papermill": {
     "duration": 0.003409,
     "end_time": "2025-08-31T18:41:41.999189",
     "exception": false,
     "start_time": "2025-08-31T18:41:41.995780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training a timm Pretrained Model with Dog and Cat Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f4abafc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:42.007320Z",
     "iopub.status.busy": "2025-08-31T18:41:42.007107Z",
     "iopub.status.idle": "2025-08-31T18:41:52.160520Z",
     "shell.execute_reply": "2025-08-31T18:41:52.159765Z"
    },
    "papermill": {
     "duration": 10.158823,
     "end_time": "2025-08-31T18:41:52.161706",
     "exception": false,
     "start_time": "2025-08-31T18:41:42.002883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10028, 4) (8005, 4) (6804, 4) (1201, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "paths = [] # list of image file paths\n",
    "dataset_gubuns = [] # list for train/test split\n",
    "label_gubuns = [] # list for dog/cat labels\n",
    "\n",
    "# Use os.walk() to scan all subdirectories under a specific directory. \n",
    "# Under cat-and-dog, all files with the .jpg extension are image files. \n",
    "# The cat-and-dog directory contains /train/ and /test/ subdirectories (holding training and test image files).\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        # There may be non-image files in the directory as well.\n",
    "        if '.jpg' in filename:\n",
    "            # Assign the absolute path of the file to the file_path variable. \n",
    "            file_path = dirname+'/'+ filename\n",
    "            paths.append(file_path)\n",
    "            # If the absolute path contains training_set or test_set, classify the dataset as 'train' or 'test'.\n",
    "            if '/training_set/' in file_path:\n",
    "                dataset_gubuns.append('train')  \n",
    "            elif '/test_set/' in file_path:\n",
    "                dataset_gubuns.append('test')\n",
    "            else: dataset_gubuns.append('N/A')\n",
    "            \n",
    "            # If the absolute path contains dogs, the file is a dog image; if it contains cats, it is a cat image. \n",
    "            if 'dogs' in file_path:\n",
    "                label_gubuns.append('DOG')\n",
    "            elif 'cats' in file_path:\n",
    "                label_gubuns.append('CAT')\n",
    "            else: label_gubuns.append('N/A')\n",
    "\n",
    "# Create a DataFrame for metadata. \n",
    "data_df = pd.DataFrame({'path':paths, \n",
    "                        'dataset':dataset_gubuns, \n",
    "                        'label':label_gubuns})\n",
    "\n",
    "# Convert target values to 0 and 1\n",
    "label_mapping = {'DOG': 0, 'CAT': 1}\n",
    "data_df['target'] = data_df['label'].map(label_mapping)\n",
    "\n",
    "# Create metadata DataFrames for training and test sets from the entire dataset. \n",
    "train_df = data_df[data_df['dataset']=='train']\n",
    "test_df = data_df[data_df['dataset']=='test']\n",
    "\n",
    "# Split the training DataFrame into training and validation sets. 85% training, 15% validation. \n",
    "tr_df, val_df = train_test_split(train_df, test_size=0.15, stratify=train_df['target'], random_state=2025)\n",
    "\n",
    "print(data_df.shape, train_df.shape, tr_df.shape, val_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d9cda",
   "metadata": {
    "papermill": {
     "duration": 0.003721,
     "end_time": "2025-08-31T18:41:52.169559",
     "exception": false,
     "start_time": "2025-08-31T18:41:52.165838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a171075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:52.178213Z",
     "iopub.status.busy": "2025-08-31T18:41:52.177646Z",
     "iopub.status.idle": "2025-08-31T18:41:52.183259Z",
     "shell.execute_reply": "2025-08-31T18:41:52.182513Z"
    },
    "papermill": {
     "duration": 0.011138,
     "end_time": "2025-08-31T18:41:52.184399",
     "exception": false,
     "start_time": "2025-08-31T18:41:52.173261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "class CnD_Dataset(Dataset):\n",
    "    # Takes image file list, target file list, transforms, etc. as inputs for processing images and target data\n",
    "    def __init__(self, image_paths, targets=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "    \n",
    "    # Returns the total number of samples\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "        \n",
    "    # Returns a single image and label as tensors for the given idx\n",
    "    def __getitem__(self, idx):    \n",
    "        # Load image using PIL and return a PIL Image object\n",
    "        pil_image = Image.open(self.image_paths[idx])\n",
    "        # Usually, transform is not None (at least a Tensor conversion should be applied)\n",
    "        image = self.transform(pil_image)\n",
    "\n",
    "        if self.targets is not None:\n",
    "            # Convert individual target value to a tensor\n",
    "            target = torch.tensor(self.targets[idx])\n",
    "            return image, target\n",
    "        # For test data, targets may not be provided, so handle this case\n",
    "        else:\n",
    "            return image, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03a1714",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:52.192686Z",
     "iopub.status.busy": "2025-08-31T18:41:52.192482Z",
     "iopub.status.idle": "2025-08-31T18:41:52.198726Z",
     "shell.execute_reply": "2025-08-31T18:41:52.198230Z"
    },
    "papermill": {
     "duration": 0.011553,
     "end_time": "2025-08-31T18:41:52.199735",
     "exception": false,
     "start_time": "2025-08-31T18:41:52.188182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 224\n",
    "IMG_MEANS = [0.485, 0.456, 0.406]\n",
    "IMG_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "def create_tr_val_loader(tr_df, val_df, transform):\n",
    "    tr_dataset = CnD_Dataset(image_paths=tr_df['path'].to_list(), \n",
    "                            targets=tr_df['target'].to_list(), transform=transform)\n",
    "    val_dataset = CnD_Dataset(image_paths=val_df['path'].to_list(), \n",
    "                            targets=val_df['target'].to_list(), transform=transform)\n",
    "    tr_loader = DataLoader(tr_dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=2*BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    return tr_loader, val_loader\n",
    "\n",
    "transform_01 = T.Compose([\n",
    "            T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n",
    "            T.ToTensor(), T.Normalize(mean=IMG_MEANS, std=IMG_STD)\n",
    "])\n",
    "\n",
    "tr_loader, val_loader = create_tr_val_loader(tr_df=tr_df, val_df=val_df, transform=transform_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed183847",
   "metadata": {
    "papermill": {
     "duration": 0.003637,
     "end_time": "2025-08-31T18:41:52.207121",
     "exception": false,
     "start_time": "2025-08-31T18:41:52.203484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b6a8047",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:52.215764Z",
     "iopub.status.busy": "2025-08-31T18:41:52.215562Z",
     "iopub.status.idle": "2025-08-31T18:41:52.230227Z",
     "shell.execute_reply": "2025-08-31T18:41:52.229524Z"
    },
    "papermill": {
     "duration": 0.020374,
     "end_time": "2025-08-31T18:41:52.231349",
     "exception": false,
     "start_time": "2025-08-31T18:41:52.210975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loss_fn, optimizer, train_loader, val_loader, scheduler=None, device=None):\n",
    "        self.model = model.to(device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        # add scheduler\n",
    "        self.scheduler = scheduler\n",
    "        self.device = device\n",
    "        # add current learning rate variable\n",
    "        self.current_lr = self.optimizer.param_groups[0]['lr']\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        # calculate running average loss\n",
    "        accu_loss = 0.0\n",
    "        running_avg_loss = 0.0\n",
    "        # accuracy, total count and accumulated correct count for accuracy calculation\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "        # visualize real-time training loop progress with tqdm\n",
    "        with tqdm(total=len(self.train_loader), desc=f\"Epoch {epoch+1} [Training..]\", leave=True) as progress_bar:\n",
    "            for batch_idx, (inputs, targets) in enumerate(self.train_loader):\n",
    "                # must be to(self.device). not to(device).\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.loss_fn(outputs, targets)\n",
    "\n",
    "                # Backward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # accumulate loss and divide by batch count to get running average loss\n",
    "                accu_loss += loss.item()\n",
    "                running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                # calculate accuracy metric\n",
    "                # get count of matches between output predicted class values and target values\n",
    "                num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                # calculate accuracy using accumulated total count and accumulated correct count per batch\n",
    "                num_total += inputs.shape[0]\n",
    "                accu_num_correct += num_correct\n",
    "                accuracy = accu_num_correct / num_total\n",
    "\n",
    "                # show progress and running average loss and accuracy on tqdm progress_bar\n",
    "                progress_bar.update(1)\n",
    "                if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # update every 20 batches or on the last batch\n",
    "                    progress_bar.set_postfix({\"Loss\": running_avg_loss,\n",
    "                                              \"Accuracy\": accuracy})\n",
    "\n",
    "        if not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            self.scheduler.step()\n",
    "            self.current_lr = self.scheduler.get_last_lr()[0]\n",
    "\n",
    "        return running_avg_loss, accuracy\n",
    "\n",
    "    def validate_epoch(self, epoch):\n",
    "        if not self.val_loader:\n",
    "            return None\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        # calculate running average loss\n",
    "        accu_loss = 0\n",
    "        running_avg_loss = 0\n",
    "        # accuracy, total count and accumulated correct count for accuracy calculation\n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "        accuracy = 0.0\n",
    "        \n",
    "        with tqdm(total=len(self.val_loader), desc=f\"Epoch {epoch+1} [Validating]\", leave=True) as progress_bar:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(self.val_loader):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = targets.to(self.device)\n",
    "\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                    loss = self.loss_fn(outputs, targets)\n",
    "                    # accumulate loss and divide by batch count to get running average loss\n",
    "                    accu_loss += loss.item()\n",
    "                    running_avg_loss = accu_loss /(batch_idx + 1)\n",
    "\n",
    "                    # calculate accuracy metric\n",
    "                    # get count of matches between output predicted class values and target values\n",
    "                    num_correct = (outputs.argmax(-1) == targets).sum().item()\n",
    "                    # calculate accuracy using accumulated total count and accumulated correct count per batch\n",
    "                    num_total += inputs.shape[0]\n",
    "                    accu_num_correct += num_correct\n",
    "                    accuracy = accu_num_correct / num_total\n",
    "\n",
    "                    # show progress and running average loss and accuracy on tqdm progress_bar\n",
    "                    progress_bar.update(1)\n",
    "                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:  # update every 20 batches or on the last batch\n",
    "                        progress_bar.set_postfix({\"Loss\": running_avg_loss,\n",
    "                                                  \"Accuracy\":accuracy})\n",
    "        # input epoch-level loss calculated from validation data into scheduler\n",
    "        if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            self.scheduler.step(running_avg_loss)\n",
    "            self.current_lr = self.scheduler.get_last_lr()[0]\n",
    "\n",
    "        return running_avg_loss, accuracy\n",
    "\n",
    "    def fit(self, epochs):\n",
    "        # create a history dict to record training/validation results per epoch, including learning rate\n",
    "        history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = self.train_epoch(epoch)\n",
    "            val_loss, val_acc = self.validate_epoch(epoch)\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f} Train Accuracy: {train_acc:.4f}\",\n",
    "                  f\", Val Loss: {val_loss:.4f} Val Accuracy: {val_acc:.4f}\" if val_loss is not None else \"\",\n",
    "                  f\", Current lr:{self.current_lr:.6f}\")\n",
    "            # record training/validation results and learning rate per epoch\n",
    "            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
    "            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
    "            history['lr'].append(self.current_lr)\n",
    "\n",
    "        return history\n",
    "\n",
    "    # return the trained model\n",
    "    def get_trained_model(self):\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf7fd7c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T18:41:52.239981Z",
     "iopub.status.busy": "2025-08-31T18:41:52.239427Z",
     "iopub.status.idle": "2025-08-31T19:03:02.087342Z",
     "shell.execute_reply": "2025-08-31T19:03:02.086309Z"
    },
    "papermill": {
     "duration": 1269.8535,
     "end_time": "2025-08-31T19:03:02.088692",
     "exception": false,
     "start_time": "2025-08-31T18:41:52.235192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Training..]: 100%|██████████| 426/426 [00:40<00:00, 10.40it/s, Loss=0.115, Accuracy=0.957]\n",
      "Epoch 1 [Validating]: 100%|██████████| 38/38 [00:03<00:00, 11.88it/s, Loss=0.0597, Accuracy=0.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 0.1148 Train Accuracy: 0.9571 , Val Loss: 0.0597 Val Accuracy: 0.9792 , Current lr:0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.76it/s, Loss=0.0665, Accuracy=0.977]\n",
      "Epoch 2 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.44it/s, Loss=0.0982, Accuracy=0.962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30, Train Loss: 0.0665 Train Accuracy: 0.9774 , Val Loss: 0.0982 Val Accuracy: 0.9617 , Current lr:0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.74it/s, Loss=0.0472, Accuracy=0.982]\n",
      "Epoch 3 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 13.79it/s, Loss=0.072, Accuracy=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30, Train Loss: 0.0472 Train Accuracy: 0.9822 , Val Loss: 0.0720 Val Accuracy: 0.9742 , Current lr:0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.76it/s, Loss=0.0325, Accuracy=0.99]\n",
      "Epoch 4 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.36it/s, Loss=0.134, Accuracy=0.958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30, Train Loss: 0.0325 Train Accuracy: 0.9904 , Val Loss: 0.1344 Val Accuracy: 0.9575 , Current lr:0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.76it/s, Loss=0.0494, Accuracy=0.983]\n",
      "Epoch 5 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.30it/s, Loss=0.102, Accuracy=0.964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30, Train Loss: 0.0494 Train Accuracy: 0.9827 , Val Loss: 0.1021 Val Accuracy: 0.9642 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.75it/s, Loss=0.0119, Accuracy=0.997]\n",
      "Epoch 6 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.47it/s, Loss=0.0654, Accuracy=0.975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30, Train Loss: 0.0119 Train Accuracy: 0.9966 , Val Loss: 0.0654 Val Accuracy: 0.9750 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.76it/s, Loss=0.00229, Accuracy=1]\n",
      "Epoch 7 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 13.80it/s, Loss=0.0433, Accuracy=0.984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30, Train Loss: 0.0023 Train Accuracy: 0.9996 , Val Loss: 0.0433 Val Accuracy: 0.9842 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.76it/s, Loss=0.00255, Accuracy=0.999]\n",
      "Epoch 8 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.31it/s, Loss=0.0674, Accuracy=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30, Train Loss: 0.0026 Train Accuracy: 0.9990 , Val Loss: 0.0674 Val Accuracy: 0.9808 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=0.00805, Accuracy=0.997]\n",
      "Epoch 9 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.46it/s, Loss=0.0587, Accuracy=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30, Train Loss: 0.0080 Train Accuracy: 0.9971 , Val Loss: 0.0587 Val Accuracy: 0.9817 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=0.00253, Accuracy=0.999]\n",
      "Epoch 10 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.35it/s, Loss=0.0347, Accuracy=0.985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30, Train Loss: 0.0025 Train Accuracy: 0.9991 , Val Loss: 0.0347 Val Accuracy: 0.9850 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=0.00172, Accuracy=0.999]\n",
      "Epoch 11 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.13it/s, Loss=0.07, Accuracy=0.985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30, Train Loss: 0.0017 Train Accuracy: 0.9994 , Val Loss: 0.0700 Val Accuracy: 0.9850 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=0.0148, Accuracy=0.995]\n",
      "Epoch 12 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.32it/s, Loss=0.056, Accuracy=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30, Train Loss: 0.0148 Train Accuracy: 0.9953 , Val Loss: 0.0560 Val Accuracy: 0.9800 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.75it/s, Loss=0.00602, Accuracy=0.998]\n",
      "Epoch 13 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.23it/s, Loss=0.107, Accuracy=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30, Train Loss: 0.0060 Train Accuracy: 0.9984 , Val Loss: 0.1074 Val Accuracy: 0.9725 , Current lr:0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=0.0087, Accuracy=0.997]\n",
      "Epoch 14 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.15it/s, Loss=0.0802, Accuracy=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30, Train Loss: 0.0087 Train Accuracy: 0.9972 , Val Loss: 0.0802 Val Accuracy: 0.9800 , Current lr:0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=0.0031, Accuracy=0.999]\n",
      "Epoch 15 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 13.91it/s, Loss=0.0843, Accuracy=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30, Train Loss: 0.0031 Train Accuracy: 0.9991 , Val Loss: 0.0843 Val Accuracy: 0.9734 , Current lr:0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=0.00119, Accuracy=1]\n",
      "Epoch 16 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.17it/s, Loss=0.0814, Accuracy=0.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30, Train Loss: 0.0012 Train Accuracy: 0.9997 , Val Loss: 0.0814 Val Accuracy: 0.9792 , Current lr:0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.78it/s, Loss=0.000426, Accuracy=1]\n",
      "Epoch 17 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.44it/s, Loss=0.107, Accuracy=0.978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30, Train Loss: 0.0004 Train Accuracy: 0.9999 , Val Loss: 0.1072 Val Accuracy: 0.9775 , Current lr:0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=0.00172, Accuracy=1]\n",
      "Epoch 18 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.44it/s, Loss=0.0682, Accuracy=0.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30, Train Loss: 0.0017 Train Accuracy: 0.9996 , Val Loss: 0.0682 Val Accuracy: 0.9800 , Current lr:0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.78it/s, Loss=0.000109, Accuracy=1]\n",
      "Epoch 19 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.73it/s, Loss=0.0676, Accuracy=0.983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30, Train Loss: 0.0001 Train Accuracy: 1.0000 , Val Loss: 0.0676 Val Accuracy: 0.9825 , Current lr:0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.78it/s, Loss=0.0004, Accuracy=1]\n",
      "Epoch 20 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.01it/s, Loss=0.0625, Accuracy=0.983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30, Train Loss: 0.0004 Train Accuracy: 0.9999 , Val Loss: 0.0625 Val Accuracy: 0.9833 , Current lr:0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=8.47e-5, Accuracy=1]\n",
      "Epoch 21 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.15it/s, Loss=0.0661, Accuracy=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30, Train Loss: 0.0001 Train Accuracy: 1.0000 , Val Loss: 0.0661 Val Accuracy: 0.9817 , Current lr:0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.78it/s, Loss=0.000283, Accuracy=1]\n",
      "Epoch 22 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.47it/s, Loss=0.0766, Accuracy=0.978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30, Train Loss: 0.0003 Train Accuracy: 1.0000 , Val Loss: 0.0766 Val Accuracy: 0.9784 , Current lr:0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.78it/s, Loss=9.56e-5, Accuracy=1]\n",
      "Epoch 23 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.54it/s, Loss=0.0796, Accuracy=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30, Train Loss: 0.0001 Train Accuracy: 1.0000 , Val Loss: 0.0796 Val Accuracy: 0.9817 , Current lr:0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.78it/s, Loss=0.00411, Accuracy=1]\n",
      "Epoch 24 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.32it/s, Loss=0.0802, Accuracy=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30, Train Loss: 0.0041 Train Accuracy: 0.9999 , Val Loss: 0.0802 Val Accuracy: 0.9808 , Current lr:0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.78it/s, Loss=0.000289, Accuracy=1]\n",
      "Epoch 25 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.24it/s, Loss=0.0874, Accuracy=0.979]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30, Train Loss: 0.0003 Train Accuracy: 0.9999 , Val Loss: 0.0874 Val Accuracy: 0.9792 , Current lr:0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.78it/s, Loss=6.58e-5, Accuracy=1]\n",
      "Epoch 26 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.44it/s, Loss=0.08, Accuracy=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30, Train Loss: 0.0001 Train Accuracy: 1.0000 , Val Loss: 0.0800 Val Accuracy: 0.9808 , Current lr:0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=3.89e-5, Accuracy=1]\n",
      "Epoch 27 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.24it/s, Loss=0.0793, Accuracy=0.982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30, Train Loss: 0.0000 Train Accuracy: 1.0000 , Val Loss: 0.0793 Val Accuracy: 0.9817 , Current lr:0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=3.84e-5, Accuracy=1]\n",
      "Epoch 28 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 13.32it/s, Loss=0.0784, Accuracy=0.983]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30, Train Loss: 0.0000 Train Accuracy: 1.0000 , Val Loss: 0.0784 Val Accuracy: 0.9825 , Current lr:0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=2.72e-5, Accuracy=1]\n",
      "Epoch 29 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 14.17it/s, Loss=0.0779, Accuracy=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30, Train Loss: 0.0000 Train Accuracy: 1.0000 , Val Loss: 0.0779 Val Accuracy: 0.9808 , Current lr:0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 [Training..]: 100%|██████████| 426/426 [00:39<00:00, 10.77it/s, Loss=3.35e-5, Accuracy=1]\n",
      "Epoch 30 [Validating]: 100%|██████████| 38/38 [00:02<00:00, 13.83it/s, Loss=0.0767, Accuracy=0.982]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30, Train Loss: 0.0000 Train Accuracy: 1.0000 , Val Loss: 0.0767 Val Accuracy: 0.9817 , Current lr:0.000016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "NUM_INPUT_CHANNELS = 3\n",
    "# Two classes: Dog (target value 0) and Cat (target value 1)\n",
    "NUM_CLASSES = 2\n",
    "# Create pretrained model from timm with resnet50.a1_in1k\n",
    "model = timm.create_model(model_name='resnet50.a1_in1k', pretrained=True, \n",
    "                                  num_classes=NUM_CLASSES) # resnet50, resnet101\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(\n",
    "            optimizer=optimizer, mode='min', factor=0.5, patience=3, threshold=0.01, min_lr=0.00001)\n",
    "\n",
    "trainer = Trainer(model=model, loss_fn=loss_fn, optimizer=optimizer,\n",
    "       train_loader=tr_loader, val_loader=val_loader, scheduler=scheduler, device=device)\n",
    "# Training and evaluation\n",
    "history = trainer.fit(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43c314f",
   "metadata": {
    "papermill": {
     "duration": 0.357205,
     "end_time": "2025-08-31T19:03:02.752461",
     "exception": false,
     "start_time": "2025-08-31T19:03:02.395256",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Predictor class and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "227903f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T19:03:03.361688Z",
     "iopub.status.busy": "2025-08-31T19:03:03.361379Z",
     "iopub.status.idle": "2025-08-31T19:03:03.369692Z",
     "shell.execute_reply": "2025-08-31T19:03:03.368930Z"
    },
    "papermill": {
     "duration": 0.310704,
     "end_time": "2025-08-31T19:03:03.370893",
     "exception": false,
     "start_time": "2025-08-31T19:03:03.060189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        eval_metric = 0.0\n",
    "        \n",
    "        num_total = 0.0\n",
    "        accu_num_correct = 0.0\n",
    "\n",
    "        with tqdm(total=len(loader), desc=f\"[Evaluating]\", leave=True) as progress_bar:\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "                    inputs = inputs.to(self.device)\n",
    "                    targets = targets.to(self.device)\n",
    "                    pred = self.model(inputs)\n",
    "\n",
    "                    num_correct = (pred.argmax(-1) == targets).sum().item()\n",
    "                    num_total += inputs.shape[0]\n",
    "                    accu_num_correct += num_correct\n",
    "                    eval_metric = accu_num_correct / num_total\n",
    "\n",
    "                    progress_bar.update(1)\n",
    "                    if batch_idx % 20 == 0 or (batch_idx + 1) == progress_bar.total:\n",
    "                        progress_bar.set_postfix({\"Accuracy\": eval_metric})\n",
    "        \n",
    "        return eval_metric\n",
    "\n",
    "    def predict_proba(self, inputs):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs = inputs.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            pred_proba = F.softmax(outputs, dim=-1) #또는 dim=1\n",
    "\n",
    "        return pred_proba\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        pred_proba = self.predict_proba(inputs)\n",
    "        pred_class = torch.argmax(pred_proba, dim=-1)\n",
    "\n",
    "        return pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb27156e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T19:03:04.027264Z",
     "iopub.status.busy": "2025-08-31T19:03:04.026990Z",
     "iopub.status.idle": "2025-08-31T19:03:11.409670Z",
     "shell.execute_reply": "2025-08-31T19:03:11.408653Z"
    },
    "papermill": {
     "duration": 7.685982,
     "end_time": "2025-08-31T19:03:11.411002",
     "exception": false,
     "start_time": "2025-08-31T19:03:03.725020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Evaluating]: 100%|██████████| 64/64 [00:07<00:00,  8.69it/s, Accuracy=0.985]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset evaluation:0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = data_df[data_df['dataset']=='test']\n",
    "test_image_paths = test_df['path'].to_list()\n",
    "test_targets = test_df['target'].to_list()\n",
    "\n",
    "IMG_SIZE=224\n",
    "transform_02 = T.Compose([\n",
    "                        T.Resize(size=(IMG_SIZE, IMG_SIZE)),\n",
    "                        T.ToTensor(), \n",
    "                        T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = CnD_Dataset(image_paths=test_image_paths, \n",
    "                            targets=test_targets, transform=transform_02)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "trained_model = trainer.get_trained_model()\n",
    "\n",
    "predictor = Predictor(model=trained_model, device=device)\n",
    "eval_metric = predictor.evaluate(test_loader)\n",
    "print(f'test dataset evaluation:{eval_metric:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 23777,
     "sourceId": 30378,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1310.974211,
   "end_time": "2025-08-31T19:03:14.580370",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-31T18:41:23.606159",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "051c6563b2ad4ee2b2f33f6eb4d29d3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e74ea65b0874096b19b97b6915da2ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "251ada4faa2c4a53b6729a6160398770": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "56c5b5be6f0843bdad0cb003b7e95891": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "577f9e08821e4c4eba9864914390636f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a48c2fde97424ebcb8651d882a76592d",
        "IPY_MODEL_72b24e6aec024f5fa05ee6144b4b142d",
        "IPY_MODEL_ababd5f578274cb8b195ea0ff6721d28"
       ],
       "layout": "IPY_MODEL_1e74ea65b0874096b19b97b6915da2ba",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7256027f50ed4d88aa1cabe9473b77b1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "72b24e6aec024f5fa05ee6144b4b142d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_56c5b5be6f0843bdad0cb003b7e95891",
       "max": 102469840.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7256027f50ed4d88aa1cabe9473b77b1",
       "tabbable": null,
       "tooltip": null,
       "value": 102469840.0
      }
     },
     "9e1cf43bf94c49f29c5e74f4733939df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a48c2fde97424ebcb8651d882a76592d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9e1cf43bf94c49f29c5e74f4733939df",
       "placeholder": "​",
       "style": "IPY_MODEL_d50eecb458464ef8b5b38069775e5eae",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "ababd5f578274cb8b195ea0ff6721d28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_051c6563b2ad4ee2b2f33f6eb4d29d3c",
       "placeholder": "​",
       "style": "IPY_MODEL_251ada4faa2c4a53b6729a6160398770",
       "tabbable": null,
       "tooltip": null,
       "value": " 102M/102M [00:00&lt;00:00, 222MB/s]"
      }
     },
     "d50eecb458464ef8b5b38069775e5eae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
